,,,Origin,,,,,,,,,,,,,,,Data,,,,,,,,,,,EEG processing,,,,,,Methodology,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Results and discussion,,,,,,,,,,,,,Reviewed by,,,
,Title,Year,Authors,Journal / Origin,Arxiv,Lab / School / Company,Pages,,Domain 1,Domain 2,Domain 3,Domain 4,High-level Goal,Practical Goal,Task/Paradigm,Motivation for DL,,EEG Hardware,Invasive,Neural response pattern,Dataset name,Dataset accessibility,Nb Subjects,Nb Channels,Sampling rate,Nb EEG Epochs,Offline / Online,,Preprocessing,Artefact handling,Features,Features (clean),Normalization,,Software,Architecture,Architecture (clean),Design peculiarities,EEG-specific design,Network Schema/Graph/Table,Input format,Layers,Activation function,Regularization,Nb Classes,Classes,Output format,Nb Parameters,Training procedure,Optimizer,Optim parameters,Minibatch size,Hyperparameter optim,Data augmentation,Loss,Intra/Inter subject,Cross validation,Data split,Data (YR),Performance metrics,Performance metrics (clean),Training hardware,,Training time,Results,Benchmarks,Baseline model type,Statistical analysis of performance,Analysis of learned parameters,Discussion,Limitations,Code available,Code hosted on,Limited data,Others & Comments,,First Reader,Second Reader,,Citation
,EEG-signals based cognitive workload detection of vehicle driver using deep learning,2018,"Almogbel, Dang & Kameyama",IEEE Conference on Advanced Communication Technology,No,Waseda University,4,,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art,,Driving Game (GTA),,,Muse,No,Raw EEG,Internal Recordings,Private,1,4,256Hz,N/M*,,,None,No,Raw EEG,Raw EEG,z-score,,N/M*,CNN,CNN,,,Yes,"38400x4
(38400 = 150s @ 256Hz)","7 Conv
+ 3 FC",ReLU,Dropout: 50%,,,2 (Softmax),N/M*,,"RMSProp
",lr=0.002,64,N/M,No,Binary cross-entropy,Intra,"All sessions but last for training.
Last session for evaluation.","Train: 6 million samples
Valid: 460 thousand
Test: N/A

(for each of the 4 channels)","Each of the two types of session was recorded for an interval
of 15 to 30 minutes on a span of one month. The number of sessions for the experiments is 24 where 12 is for high workload and 12 is for low workload. Hence, the data in one second consist of 256 samples, and that of 15 to 30 minutes session consist of 230,000 to 460,000 samples for each of the 4 channels. Thus, over 6 million samples for each of the 4 channels are used for the training and 460 thousand for the evaluation. The slicing windows are overlapped with 1/256[sec] step",Accuracy,accuracy,N/M,,N/M,95.31%,No,None,,No,"""This study does not impose in any way a direct comparison with the distinguished previous works because the used data, experimental conditions, classification targets are different in each, but rather explore and introduce the potential of using deep CNN architecture in classifying raw EEG signals without any pre-processing.""",,No,N/A,No,24 sessions of 15 to 30 minutes over 1 month on 1 subject. Balanced dataset / classes. (is that important to report?),,Yannick,Isabela,,Almogbel2018
,Automatic ocular artifacts removal in EEG using deep learning,2018,"Yang, Duan, Fan, Hu & Wang",Biomedical Signal Processing and Control,No,"Key Laboratory of Power Station Automation Technology, Shanghai University",11,,Improvement of processing tools,Signal cleaning,Artifact handling,,Novel,,Motor Imagery,,,Neuracle Wireless 32,No,Clean EEG / Ocular artefacts,"BCI Competition IV - I;
Internal Recordings",Public,"4 (of 7 in public dataset)
+ 3 (internal)","59
32",100Hz,200 per subject * 7 = 1400,,,1) Band-Pass Filter: 0.05-200Hz,,Raw EEG,Raw EEG,min-max,,MATLAB,SAE,AE,N/M*,,Yes,100x1,3,,,,,100x1,N/M*,Greedy Layer-wise training,N/M*,,,,No,RMSE,Inter,No,"16520 training samples
15458 test samples","Each subject has 200 trails of motor imagery and each trail lasts for more than 6 s. EEG signals were recorded from 59 channels. In this paper, we selected Subject 1, 2, 6 and 7. (from BCI Comp. dataset)
They also recorded internal recordings: 3 individuals also has 200 trials of motor imagery and each trial also lasts for more than 6 s. (each participant)","RMSE of reconstructions
Accuracy on surrogate MI task ","RMSE, accuracy",Not mentioned,,N/M*,"RMSE is lower for proposed approach than for benchmarks, as is the accuracy on the surrogate MI task","Shallow SAE, ICA, K-ICA, SOBI",Traditional pipeline,,,"""Compared with the classical OAs removal methods, the proposed method has many highlights. [...] In the future work, we are going to improve the training method of DLN or try replacing the SAE with other neural networks such as convolutional neural networks (CNN) to strengthen its fitting ability for the details of EEG.""",,No,N/A,No,Poorly written... :( The way some elements are explained shows the authors do not really understand the methods they are using.,,Yannick,Hubert,,Yang2018
,An end-to-end framework for real-time automatic sleep stage classification,2018,"Patanaik, Ong, Gooley, Ancoli-Israel & Chee",Sleep,No,"Duke-NUS Medical School, Singapore
University of California, San Diego",11,,Classification of EEG signals,Clinical,Sleep,Staging,"Improve State-of-the-Art: DL for Sleep
(CNN + MLP)",Reduce the time necessary to stage sleep recordings by using DL,Sleep,No need for feature engineering,,N/M,No,Raw EEG,Internal Recordings,Private,459,"2 EEG + 2 EOG
(the two bipolar EEG channels are then averaged)",N/M,"1,403,164 epochs",,,"1) Pass-Band Filter (FIR): 0.3-45Hz
2) Downsampled to 100Hz (polyphase FIR filter)",No,Spectrogram,Frequency-domain,N/M,,TensorFlow,"CNN + MLP
(2 Stages)",CNN,Consecutive probabilities outputted by the CNN are aggregated by the MLP ,N/M,Yes,"32x32x3
(spectrogram 2D x 3 channels) ","CNN: 16
MLP: 1","CNN: ReLU
MLP: tansig",N/M,,,"5
(Softmax)
Probability of each Sleep Stage","dCNN: 177 669 weights
MLP: 445 weights",Standard optimization,Stochastic gradient descent with Nesterov momentum,"Learning rate: 0.001
Momentum: 0.9
Learning rate decay: 10e-6","CNN: 300
MLP: 1000",Trial and error,No,"N/M
(Most probably categorical cross-entropy)",Inter,Yes,"Train: 75% of DS1 & DS2
Test: 25% of DS1 & DS2
Validation: DS3, DS4","The framework was tested on four datasets comprising ≈ 1700 polysomnography records ( ≈ 12 000 hr of recordings). A total of 11,727 hr of PSG data with 1,403,164 epochs were used for train- ing, testing, and validation.","Accuracy
Cohen's kappa","accuracy, Cohen's kappa",NVidia GTX 1060,,N/M,"Test set: ~89.8%. kappa=0.862
Validation set 1: 81.4%, kappa=0.740
Validation set 2: 72.1%, kappa=0.597",Expert rescoring of 50 records,None,,No,"""... our framework provides a practicable, validated, and speedy solution for automatic sleep stage classification that can significantly improve throughput and productivity of sleep labs. It has the potential to play an important role in emerging novel applications of real-time automatic sleep scoring as well as being installed in personal sleep monitors.""",N/M,No,N/A,No,"Great paper, with most of the information available. Interesting experiment (slow wave entrainment)",,Yannick,Hubert,,Patanaik2018
,Epileptic Seizure Detection: A Deep Learning Approach,2018,"Hussein, Palangi, Ward & Wang",Arxiv,Yes,UBC,12,,Classification of EEG signals,Clinical,Epilepsy,Detection,"Improve State-of-the-Art: DL for Epilepsy
(LSTM)","Improve performance on seizure detection with DL, on real conditions (with noise)","Resting State, Eyes Open, Eyes Closed, Seizures.",Automatically learns features,,N/M,Both,Raw EEG,Bonn University,Public,15,1,173.6Hz,500,,,"1) Artifacts Removed
2) Band-Pass Filter: 0.53-40Hz
(before saving the dataset... ""hardcoded"")",Yes (dataset already cleaned),Raw EEG,Raw EEG,N/M,,"MATLAB, Python
Keras with TensorFlow backend",LSTM,RNN,N/M,N/M,Yes,100x2,3,N/M,N/M,,,"2, 3 or 5",N/M,Standard optimization,Adam,LR: 0.001,64,N/M,"Added artifacts (EMG, EOG) 
and Gaussian white noise",Categorical Cross-Entropy,Inter,"3-, 5- and 10-fold CV","Train: 80%
Test: 20%",Bonn University,"Accuracy
Sensitivity
Specificity","accuracy, sensitivity, specificy",NVidia K40,,2h,"100% everywhere.
For Sensitivity, Specificity & Accuracy of the
2-Classes, 3-Classes & 5-Classes.
Robust to artificial artfiacts","Compared with many other SotA using the same dataset.
BNN, ME, SVM, ELM, LDA, SVM, KNN, ANN, etc.",Traditional pipeline,,No,"Compared to the state-of-the-art methods, this approach can learn the high-level representations, and can effectively discriminate between the normal and seizure EEG activities. Another advantage of this approach lies in its robustness against common EEG artifacts (e.g., muscle activities and eye- blinking) and white noise.",Unbalanced class distributions,No,N/A,No,"""To the best of our knowledge, this is the most widely used dataset for epileptic seizure detection""  (Bonn University Dataset)",,Yannick,Hubert,,Hussein2018
,Development of a brain computer interface interface using multi-frequency visual stimulation and deep neural networks,2018,"Perez-Benitez, Perez-Benitez & Espina-Hernandez","IEEE Conference on Electronics, Communications and Computers",No,"National Polytechnic Institute, Mexico",7,,Classification of EEG signals,BCI,Reactive,SSVEP,Improve State-of-the-Art: SSVEP with CNN,Increase number of commands and reduce eyestrain in a visual BCI,SSVEP (with LEDs),Just another classifier!,,Custom-made,No,SSVEP,Internal Recordings,Private,11,3,250,N/M,,,N/M,N/M,Spectrum,Frequency-domain,N/M,,N/M,"SAE
(Sparse AutoEncoder)",AE,N/M,N/M,Yes,N/M,"SAE: 2
Final: 2",Sigmoid,"L2 regularization
Sparsity loss",,,"5
(Softmax)
Diff SSVEP Freqs",N/M,"1) Train SAE
2) Train softmax on top of SAE middle layer",N/M,"epochs: 50
lambda (L2): 0.16
gamma (sparsity): 1.0
rho: 0.1",N/M,N/M,No,"Mean Squared Error (SAE)
Cross-entropy (softmax layer)",Intra,No,N/M,"11 voluntary participant, 5 visual stimuli ...",Accuracy,accuracy,N/M,,N/M,97.78% (not clear if on training set or something else!),"k-NN
Naive Bayes, Bayes Kernel
Decision Tree, Random Forest, Gradient Boosted Tree
Rule Induction, MC-SVM, 
ML Perceptron",Traditional pipeline,,Yes (visualization of learned parameters),"The analysis of the DNN first layer weights reveals that there are two main patterns containing information about the SSVEPs in the power spectrums of the measured EEG signals: (i) the weights reinforces the features of the spectrum at frequencies {fst}, 3/2 {fst} and 2{fst} where fst are the frequencies of the MFVS and the other (ii) the weights reinforces the features of the spectrum at low frequencies from 0 Hz – 20Hz.",N/M,No,N/A,No,"They say that it could go up to 220 commands!!! But tested with 5 and their next step is to try with 30 commands.
Also, since they don't talk about data split, it could be that the results they report were obtained on the training set...",,Yannick,Hubert,,Perez-Benitez2018
,Deep Semantic Architecture with discriminative feature visualization for neuroimage analysis,2018,"Ghosh, Dal Maso, Roig, Mitsis & Boudrias",Arxiv,Yes,"McGill, UdeM",11,,Classification of EEG signals,Monitoring,Physical,Exercise,Improve SOTA,Study the add-on effects of exercise on motor learning,Hand motor task before and after an acute exercise,Does not require hand-engineered features,,ActiCap (BrainVision),No,"Brain Rhythms
(SMR)",Internal Recordings,Private,25,64,2500,N/M,,,"1) Band-Pass Filter: 0.5-55Hz
2) Re-reference to average.
3) Visual Inspection, noisy signal segment removed
4) ICA to remove eye blinks
5) Morlet Wavelet (wave:7, 1Hz reso)","Visual inspection to reject transient artefacts
ICA for eye blinks",Frequency Bands (55),Frequency-domain,Per-electrode spectral normalization,,"Brainstorm (MATLAB), Torch",CNN,CNN,"1) Base CNN that expects baseline and post-condition data in parallel
2) CNN that predicts class
3) Adverserial Component to penalize subject-dependent training",Base CNN: spectral-only convolutions,Yes,"64 x 55
(channels x freq bands)
[x2 since the Base CNN is used twice in a single pass]","[On TF maps, on topo maps]
BaseCNN: 2 + 1, 3 + 1
Discriminator: 2, 2
Adversary: 2, 2",ReLU,"Dropout, weight decay",,,"2
Prob of EXE
Prob of CON",N/M,Standard optimization,Adam,"[On TF maps, on topo maps]
LR: 0.001, 0.001
LR decay: 0.0001, 0.001
Weight decay: 0.001, 0.03",N/M,N/M,No,"Negative Log-Likelihood
 (part 1) & 
KL-Divergence (part 2)",Inter,N/M,"Train: 80%
Validation: 20%
Test: N/M","25 subjects, 4 visits
4x50 repetitions of 3.5 sec (holding) + 3 to 5 sec rest period.",Accuracy,accuracy,N/M,,N/M,98.70%,N/M,None,,Yes (focus of paper actually! New technique to visualize average feature maps),"""Importantly, the proposed novel method enabled us to visualize the features learnt by deep networks such as CNNs, which may in turn yield better interpretation of their classification basis.""",N/M,No,N/A,No,"Yes, yes.",,Yannick,Hubert,,Ghosh2018
,Cascade and Parallel Convolutional Recurrent Neural Networks on EEG-based Intention Recognition for Brain Computer Interface,2018,"Zhang, Yao, Zhang, Wang, Chen & Boots",AAAI Conference on Artificial Intelligence,Yes,University of New South Wales,8,,Classification of EEG signals,BCI,Active,Motor imagery,Novel Approach: Cascade & Parallel CNN and RNN,Compare Cascade and Parallel CNN + RNN on Motor Imagery Dataset (eegmmidb) to SOTA,"Motor Imagery
(see eegmmidb dataset)",To capture temporal and spatial information.,,BCI2000 Instruments,No,Motor Imagery,"eegmmidb;
Internal Recordings;",Both,108,64,160,"3,145,160 EEG records",Offline,,"1) 2D Mesh (Matrice)
2) Sliding Window (clips)
3) Normalize",No,"2D Mesh Clips
(of Raw EEG)",Raw EEG,z-score,,N/M,"Cascade / Parallel
CNN + RNN (LSTM)",CNN+RNN,CNN + LSTM combined (serial or parallel),To capture spatial and temporal resolution,Yes,"2D Data mesh

(time signal x spatial matrice)","3 CNN + 1 FC (1024)
2 LSTM (64) + 1 FC (1024)",N/M,"Dropout
(0.5)",5,5 Motor Commands,"5

(Softmax)",N/M,N/M,Adam,LR: 0.0001,N/M,N/M,N/M,Cross-Entropy,Inter,N/M,"Train: 75%
Test: 25%","108 subjects, 3,145,160 EEG records (eegmmidb)
+ 9 subjects x 30 trials (6 per class) (Internal recordings)
Internal recordings: 10s action, 10s rest",Accuracy,accuracy,Nvidia Titan X Pascal,,N/M,"Cascade: 0.9824
Parallel: 0.9828","(Major and Conrad 2017)  : 0.72  -   ICA
(Shenoy, Vinod, and Guan 2015) : 0.82  -  SR-FBCSP
(Pinheiro et al. 2016) : 0.85  -  SVM
(Kim et al. 2016) : 0.80  -  SUTCCSP
(Zhang et al. 2017) : 0.79  -  XGBoost
(Bashivan et al. 2016) : 0.67  -  R-CNN",DL & Trad.,,it is observed that the cascade architecture produces best performance when the hidden state size of LSTM cells is 64. This is probably because it is hard to well trained the network with larger size and smaller hidden state size has limited representation capabilities,"A large-scale dataset of 108 participants on five categories is used to evalu- ate the proposed models. The experimental results show that both the cascade and parallel architectures could achieve very competitive accuracy around 98.3%, considerably superior to the state-of-the-art methods.",N/M,No,N/A,No,"Results seem a little too good. Need to be reproduced!
98% in the BCI world for a 5 classes MI... That's too good... Very interesting! CNN + LSTM together (serial or parallel) Even when trying on the Emotiv (5 Classes MI-BCI; 93% Accuracy!!!)",,Yannick,Isabela,,Zhang2018c
,A hierarchical LSTM model with attention for modeling EEG non-stationarity for human decision prediction,2018,"Hasib, Nayak & Huang",IEEE EMBS International Conference on Biomedical & Health Informatics,No,"University of Texas, San Antonio",4,,Classification of EEG signals,BCI,Active,Mental tasks,Improve SOTA,Novel Approach: H-LSTM with Attention for Decision Classification ,"Allow or Deny Access based on ID + Image
(Guard)",No need for hand-engineered features,,BioSemi,No,Raw EEG,BCIT Guard Duty,Private,18,64 (out of 256),512,"Total: 1782
Deny: 892
Allow: 890",,,"1) Downsampled to 128Hz
2) Band-Pass Filter: 0.1-55Hz",N/M,Raw EEG,Raw EEG,z-score,,N/M,LSTM,RNN,"Hierachical (from samples in first layer to epochs in second layer)
Attention mechanism","First layer acts on samples
Second layer acts on epochs",Yes,0.5s epochs,2,N/M,L2 weight decay,,,"1
Allow / Deny",N/M,Standard optimization,Adam,N/M,N/M,N/M,N/M,Cross-Entropy,Inter,3-Fold CV,"Train: 60%
Validation: 6%
Test: 33%","Altogether, there were 5297 sequences, where 892 corresponded to the decision Deny. To balance data, we selected 890 allow and 892 deny sequence or total 1782 sequences.
(from 18 subjects)",AUC,AUC,N/M,,N/M,"H-LSTM (w/ Attention & 0.5s epochs): 82.6%
H-LSTM (w/ Attention & 2.5s epochs): 81%
H-LSTM (w/ Attention & 5s epochs): 81.6%
H-LSTM (w/out Attention & 0.5s epochs): 80.3%
H-LSTM (w/out Attention & 5s epochs): 73.7%","SVM: 65%
CNN: 69%",DL & Trad.,,N/M,"""Using the attention mechanism does help enhance the discriminate features obtained from these epochs, although it does not help model the EEG non-stationarity"" 
""Consistent with the observation from LSTM performance, we observed an increase of performance with shorter epoch length.""",N/M,No,N/A,No,Interesting task and approach.,,Yannick,Hubert,,Hasib2018
,Deep EEG super-resolution: Upsampling EEG spatial resolution with Generative Adversarial Networks,2018,Corley & Huang,IEEE EMBS International Conference on Biomedical & Health Informatics,No,"University of Texas, San Antonio",4,,Generation of data,Generating EEG,Spatial upsampling,,Novel Approach: GAN for EEG Upsampling.,,BCI Competition III - Dataset V,GANs previous great results on image super-resolution,,"N/M
(see dataset)",No,N/A,BCI Competition III - V,Public,3,32,512,N/M,,,1) Downsampling in the number of channels (from 32 to 16),No,None,Raw EEG,z-score,,N/M,WGAN,GAN,N/M,Convolutional layers with kernel dimensions that find the relationships between channels,Yes,"32 x 512
(channels x samples)","Gen: 6 Conv Layers
Discrim:  4 Conv Layers + 1 FC",ELU,"Dropout
(0.1 - 0.25)",,,"32 x SR
(Channels x Super Resolved)
(upsampled data)",N/M,"Pre-trained Gen fine-tuned w/
WGAN framework losses w/ gradient penalty weight of 10. 
Also, label smoothing technique",Adam,"a=10^-4, b1=0.5, b2=0.9",64,N/M,N/M,"Gen: MSE
Discrim: Distance",Inter,Holdout,"Train: 75%
Valid: 20%
Test: 5%","The train set contained a total of 1,096,192 samples
epochs of size (32 channels by 512 samples)
3 subjects","MSE 
MAE 
(mean absolute error)
Accuracy, precision and recall (for classification task)","MSE, MAE, accuracy, precision, recall",N/M,,N/M,"[Scale 2 - Test]   MSE: 2.06E3  |  MAE: 24.66
[Scale 4 - Test]   MSE: 8.68E3  |  MAE: 64.39

~10^4 fold (MSE) and ~10^2 fold (MAE) compared to Bicubic Interpolation",Bicubic Interpolated Channel Data,Traditional pipeline,,N/M,"""Feature scaling techniques besides standard normalization decreased model performance. [...] It was notably difficult and time-consuming to train GANs for EEG data. [...] After testing different variants of GAN: WGAN appeared to be more stable during training.""","""It was notably difficult and time-consuming to train GANs for EEG data""",No,N/A,No,N/A,,Yannick,Isabela,,Corley2018
,Spatial and Time Domain Feature of ERP Speller System Extracted via Convolutional Neural Network,2018,"Yoon, Lee & Whang",Computational Intelligence and Neuroscience,No,"Duke University
Sangmyung University",12,,Classification of EEG signals,BCI,Reactive,ERP,Alleviate BCI illiteracy,Reduce BCI illiteracy in P300 spellers by using CNNs,Rapid Serial Visual Presentation (P300 speller),"Uncover new unknown spatial/temporal patterns.
When an optimal filter is applied, the convolution will magnify the feature of interest and reduce the others [25].",,B-Alert X10,No,P300 and oddball paradigm-related EEG activity,Internal Recordings,Private,33,11,256,"6x12x20x33
6 icons
20 times each icon / trial
12 trials
33 subjects",Both,,N/M,N/M,Raw EEG,Raw EEG,N/A,,"TensorFlow
Python",CNN,CNN,-,"Layer 1: spatial correlation
Layer 2: temporal filter",Yes,"14 x 300
(channels x samples)","CNN: 2
FC: 2",ReLU,"Dropout
(0.1 - 0.25)",6,"6 different icons 
(Power On/Off, Volume Up/Down, Channel Up/Down)",2,N/M,Standard optimization,Adam,N/M,N/M,N/M,N/M,N/M,Intra,No,"Train: 50% (offline)
Test: 50% (online)","33 subjects, 2 to 4 pairs of sessions (offline + online)
12 trials x session (each trial = 10s + ERP stimuli)","Accuracy, sensitivity, precision, F1 score, ROC (+ ANOVA on metrics)","accuracy, sensitivy, precision, f1-score, ROC",N/M,,N/M,"Accuracy: 88.9 for high performing group, 68,7% for low performing group",No benchmark,None,ANOVA,Analysis of feature maps,"A P300 is not visible in all subjects, but there seems to be a P700 that is pretty consistent across subjects.
Spatial features seem to play a more important role than temporal features in the classification of an oddball task. ",-,No,N/A,No,"I don't understand how they trained their nets, per-subject or across everyone? Their whole analysis is based on grouping Low and a High performing participants, but they came up with these groups based on the performance of each group, while providing learning curves per group... So what came first?",,Hubert,Yannick,,Yoon2018
??,Spectrographic Seizure Detection Using Deep Learning With Convolutional Neural Networks,2018,"Yan, Wang & Grinspan",Neurology,No,Well Cornell Medical College New York,,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve State-of-the-Art: Using CNN on Spectrogram for Seizure Detection,,"Existing dataset, no mention of any task.
(Supposed: Resting Sate)",,,N/M*,N/M*,"Raw EEG
(Seizure)",PhysioNet ,Public,"N/M*
(130 EEG with 
+ 130 EEG without)",N/M*,N/M*,"16,992 seizure containing images and 16,992 images without seizures",,,N/M*,,Medium Power Spectrogram (MPS),Frequency-domain,,,N/M*,"CNN
(4 variants of VGG16)",CNN,N/M*,,No,"Images 
(1s sliding window of MPS)",N/M*,,,,,N/M*,N/M*,,Dropout: 0.5,,,,No,N/M*,Inter,N/M,"Train: 80%
Test: 20%","130 EEGs with 177 total seizures, and 549 EEGs without seizures. >90% of seizures were <2 minutes long. 130 EEGs with seizure and 130 randomly selected EEGs without seizures were converted to the median power spectrogram (MPS). The training set consisted of 16,992 seizure containing images and 16,992 images without seizures (80% of total images). The testing set contained 4,248 seizure containing images and 4,248 images without seizures (20% of total images).","Sensitivity
Specificity","sensitivity, specificity",,,N/M*,All four CNN variants achieved >98% sensitivity and specificity,N/M*,None,,,"""Convolutional neural nets can achieve high sensitivity and specificity in detecting seizures within spectrograms. However, generalizability and overfitting remains a concern. Further evaluation with more diverse data sets, images grouped by individual seizures, and additional regularization techniques is warranted.""",,No,N/A,TBD,"Can't find the actual paper, if any, seems to be just a brief description of a conf paper.",,Yannick,[TBD],,Yan2018
,Generating target / non-target images of an RSVP experiment from brain signals in by conditional generative adversarial network,2018,Lee & Huang,IEEE EMBS International Conference on Biomedical & Health Informatics,No,"University of Texas, San Antonio",4,,Generation of data,Generating images conditioned on EEG,,,Novel Approach: generating images confitioned on EEG,Using EEG from RSVP to generate images (target or non-target),RSVP - 5 Images/s,GAN models.,,Biosemi,No,RSVP,Internal Recordings,Private,10,"32 
(out of 256 recorded)",N/M,"10 subjects 
x 5 sessions (~1h)",Offline,,"- PREP Pipeline (EEGLAB): bandpass (0.1-55 Hz), robust referencing, interpolating bad channels
- Downsampled to 32Hz
- Subset of 32 channels (visual cortex)",Yes,Raw EEG,Raw EEG,z-score,,EEGLAB,cGAN,GAN,"It's to generate the image, not the EEG data. Based on DCGAN",N/A,Yes,"32 x 32
(channels x samples)","Generator: 4
Discriminator: 4","G: Leaky ReLU
D: ReLU",N/M,N/A,N/A,64 x 64 (image),N/M,GAN Style.,N/M,N/M,16,N/M,N/M,N/M,Inter,No,"Train: 704 epochs 
Test: 176 epochs","10 subjects, 5 sessions (~1h /session), 880 Epochs
1s long epochs",Visual inspection (making sure generated image is of the right class),visual inspection,N/M,,2-3h,Accuracy: 0.625,Generator conditioned on uniform noise from non-overlapping distribution for target and non-target classes,DL,N/M,"Occlusion of input image
(Occluding P300 part did not change anything, but before and after made the image blurry)",We demonstrated the performance of the proposed cGAN model and showed that generation with raw or normalized EEG produced better performance than that with added noise. We also showed how this model could be used for investigating the EEG and image associations.,N/M,No,N/A,No,"It uses DL on EEG as an input to generate an image. Their method doesn't seem to work well (only 0.625 accuracy on a 2-class generation problem), and their occlusion experiment shows that the network doesn't even care about the relevant features in the input data...",,Yannick,Hubert,,Lee2018
,Cross-Participant EEG-Based Assessment of Cognitive Workload Using Multi-Path Convolutional Recurrent Neural Networks,2018,"Hefron, Borghetti, Schubert Kabban, Christensen & Estepp",Sensors,No,Air Force Institute of Technology (Ohio),27,,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Novel Approach: Using a Multi-Path Convolutional Recurrent Neural Network (MPCRNN) to improve SOTA on cross-participant classification of cognitive workload ,Tackle cross-subs variability in cognitive workload assessment,Multi-Attribute Task Battery (MATB) environment,,,BioSemi ActiveTwo,No,None,Internal Recordings,Private,8,128,4096,N/M*,,,"1) Trimmed to 303s trials
2) Downsampled to 512Hz
3) Down-selected 64 electrodes
4) PREP Pipeline to identify and interpolate bad channels, calculate a robust average reference, and remove line noise
5) High-Passe Filter: 1Hz
6) PSD 3-55Hz (2s Hanning-Windowed STFT, 1s overlap)",No,PSD - Frequency Bands (53),Frequency-domain,"[-1, 1]",,"Keras, TensorFlow","(multi-path, residual)
CNN
+
(bi-directional, residual)
LSTM",CNN+RNN,"It combines a wide multi-path, residual, convolutional networkwith a bi-directional, residual LSTM.",1x1 convolutions to act as cross-channel parametric pooling,Yes,"20x53x64
(time x frequency bands x channels)
","[very deep, see schema / paper]",ReLU and sigmoid,Dropout + batch normalization + early stopping + L1 + L2,,,"1
(Mental Workload)",N/M,Standard.,Adam,LR: from 0.0001 to 0.000001,128,N/M,N/M,Binary cross-entropy,Inter,"Test: Hold-out 1 Participant
Training: 7-Fold Cross-Validation",,,Mean Accuracy,accuracy,N/M,,N/M,between 80-86% (depending on sequence length used as input),Simpler DL architectures,DL,,No,"We show that increasing sequence length—a common method to improve accuracy in non-stimulus-locked settings—increases both mean accuracy and variance at statistically significant levels for cross-participant models. Since variance grows with sequence length, increasing temporal sequence length does not adequately address the cross-participant modeling challenge: Producing high-accuracy models with low variance across participants.",N/M,No,N/A,Yes,"Great Literature Review, explaining who did what!
""Ensemble methods, CNNs, and RNNs have generally improved results. However, no comparison using different training techniques has been characterized for deep neural network models""",,Yannick,Isabela,,Hefron2018
,Classification of auditory stimuli from EEG signals with a regulated recurrent neural network reservoir ,2018,"Moinnereau, Brienne, Brodeur, Rouat, Whittingstall & Plourde",Arxiv,Yes,Université de Sherbrooke,5,,Classification of EEG signals,BCI,Reactive,Heard speech decoding,Improve SOTA,Classify heard speech (vowels) from EEG,Auditory Stimuli + Imagined Speech,Can extract features automatically,,ActiCap + BrainAmp,No,Raw EEG,Internal Recordings,Private,8,64,N/M,4800,Offline,,"1) Pass-Band Filter: 0.1-45Hz
2) Re-sampled at 500Hz
3) Windows of 2s (stimulus at 0.5s)
4) Trials with Amplitude > +-75uV rejected
5) Re-reference to local average",Yes (amplitude thresholding),"Spike Train from
Ben’s Spike Algorithm (BSA) ",Other,N/M,,Python,RNN Reservoir,RNN,The reservoir comprises 512 neurons placed in a three-dimensional grid where 80% are excitatory and 20% are inhibitory neurons,N/M,Yes,Spike Trains per channel,N/A,Leaky Integrate-and-Fire,N/M,3,"""a"", ""i"", ""u""",1,N/M,"Reservoir: unsupervised tuning
Classifier: linear regression",N/M,N/M,N/M,N/M,N/M,N/M,Intra,5-Fold CV,"Train: 4/5
Test: 1/5","8 subjects were presented randomly with 3 different auditory stimuli
An auditory stimulus was presented randomly every 10 s and 1 min breaks were imposed every 5 min so that the subject could relax and stretch. Each stimulus was presented a total of 200 times each.
2s epochs (onset at 0.5s) (preprocessing removed 30%!)",Accuracy,accuracy,N/M,,N/M,"83.2% (64 electrodes)
1 Electrode: 57.3% 
3 Electrodes: 71.4% 
10 Electrodes: 81.7%
[Chance: 33%]","CNN
(3 conv layers of 64 filters)",DL,N/M,N/M,"""It’s hard to compare these results with the previ- ous work where many different experimental conditions (e.g. different type and number of stimuli) and preprocessing has been used. However, we show here that excellent classifica- tion results can be obtained with minimal preprocessing of the EEGs.""",N/M,No,N/A,No,"I don't know about the BSA algo to get the features.
The Reservoir Idea seems interesting.",,Yannick,Hubert,,[TBD]
,Deep learning for detection of epileptiform discharges from scalp EEG recordings,2018,"van Putten, de Carvalho, Tjepkema-Cloostermans",Clinical Neurophysiology,No,University of Twente,6,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,Use CNN and/or LSTM to classify yes/no discharges,"Pre-Recorded EEG, no mention of any task.
(Supposed: Resting Sate and sleep)",DL is  promising novel approach and is able to learn from large data-sets,,N/M,No,"Raw EEG
",TBD,Private,"N/M
",19,125,"Training: 41381
Test: 8775
Valid: 47122 (discharge)
Valid: 11782 (normal)",Offline,,"1) Band-Pass Filter: 0.5-35Hz
2) Re-referenced to both a longitudinal bipolar montage and a source Laplacian",No,Raw EEG,Raw EEG,N/M,,Keras,"CNN
RNN",CNN+RNN,Multiple designs,N/M,Yes,19 (channels) x 250 (2s) ,"CNN: 4-9 Layers
LSTM: 50-100 Units
Both w/ 1-3 FC Layers",N/M,Dropout (20-50%),2,"Normal
IED (discharge)","1
(prob [0,1] of discharge)",9142859,Standard,Adam,"LR:3e-3
Beta1: 0.91
Beta2: 0.999
Epsilon: 1e-8",N/M,N/M,N/M,Categorical Cross-Entropy,Inter,N/M,"Train: 41,381
Valid: 58,904
Test: 8,775","Subsequently, we extracted non-overlapping 2 s epochs from the 100 EEGs, and divided them into a training (n = 41,381 epochs) and test (n = 8775 epochs) set. For validation we used 7 EEGs (47,122 epochs) with 538 focal epileptiform discharges and 12 normal EEGs (n = 11,782 epochs).","AUC
Sensitivity
Specificity","AUC, sensitivity, specificity",NVidia GTX 1080,,2h,"AUC: 0.94
Sensitivity: 0.73
Specificity: 1",N/M,None,No,No,"""We foresee that deep nets may outperform humans both in classification accuracy and speed, leading to a fundamental shift in clinical EEG analysis in the next decade.""",N/M,No,N/A,No,I really don't feel that it is possible to assess how good these results are without a baseline,,Yannick,Isabela,,VanPutten2018a
,"Cognitive Analysis of Working Memory Load from EEG, by a Deep Recurrent Neural Network",2018,"Kuanar, Athitsos, Pradhan, Mishra & Rao",ICASSP,No,"University of Texas, Arlington",5,,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art: Using RNN to measure levels of cognitive load.,"Extract features less sensitive to
variations along each spatial dimension","Working memory / workload experiment.
(showing a set of letters and then showing a letter asking if the letter was part of the set) Sets of 4,6,8,10 letters corresponding to mental workload 1,2,3,4.",ConvNets have demonstrated the ability to extract features that are invariant to changes in input patterns,,"Neurofax EEG-1200 
(Nihon Kohden)
",No,PSD,NIMHANS,Private,22,64,256,N/M,,,1) From 4.5s Windows to 9 Windows of 0.5s,No,"192 Features: 64 chan x 3 bands
Theta (4-7Hz), Alpha (8-13Hz), Beta (13-30Hz) (FFT)
Converted into images. (32x32)
3D electrodes spatial to 2D.",Frequency-domain,N/M,,"Theano, Python",CNN + BiLSTM,CNN+RNN,"Transforming channels and frequency bands into images of 0.5s windows, fed to an Hybrid CNN+BiLSTM",N/M,Yes,"EEG Images 32x32
(0.5s windows)
(mixing 3 freq bands + 64 channels)","9 Conv Layers + 1 FC
+ 2 LSTM Layers of 64 units + 1 FC",Sigmoid,Dropout (0.5) + L2 (0.0001),,,"4 Classes
(Softmax)",1.66 Mil,Standard,Adam,"LR: 10^-4
Beta1: 0.9
Beta2: 0.99",30,N/M,"Gaussian noise
(on image)",Cross-Entropy,Inter,"Leave-Subject-Out 
22-Fold CV",N/M,"A total of 6490 correctly responded samples were collected from 22 subjects and assigned to four different classes corresponding to loads from 1 to 4. EEG signals from each trial of 4.5 sec were sliced into 0.5 sec pieces through an offline windowing process, and an image was constructed over each time slice.",Accurary,accuracy,NVidia K40,,18h,92.50%,"SVM, Logistic Regression, Random Forest
CNN+LSTM, CNN+LSTM+1Conv",DL & Trad.,,N/M,"""Our implementation was different from the previous attempts and learned the robust representations from EEG image sequences using a ConvNet and BiLSTM hybrid network. Our proposed hybrid network demonstrated the significant improvements in finding better classification accuracy i.e. up to 92.5% over various existing LSTM models.""",N/M,Yes,Website,No,N/M*,,Yannick,Isabela,,Kuanar2018
,A Deep Learning Approach with an Attention Mechanism for Automatic Sleep Stage Classification,2018,Längkvist & Loutfi,Arxiv,Yes,"Center for Applied Autonomous Sensor Systems, Orebro University",18,,Classification of EEG signals,Clinical,Sleep,Staging,"New approach: ""Explore the advantages of using a model qith selective attention applied to automatic sleep staging""",Learn representations of sleep EEG with attention,Sleep (PSG),Learn better features,,N/M,No,Sleep,UCDDB,Public,25,"1 EEG (out of 2)
+ 1 EMG
+ 2 EOG",128,N/M,Offline,,"1) Notch Filter: 50Hz
2) Down-Sampled to 64Hz
3) Band-Pass Filter: 0.3-32Hz",N/M,"28 Features: Relative Power: Delta (0.5 − 4Hz), Theta (4−8Hz), Alpha (8−13Hz), Beta (13−20Hz), & Gamma (20−32Hz), Entropy, Kurtosis, and Spectral Mean of all signals and fractal component of EEG.  [+ EOG & EMG features]",Frequency-domain,z-score,,N/M,SAE,AE,"Attention Mechanism
(static & adaptive approaches)",N/M,No,28,1,Sigmoid,"L2 normalization
KL term in cost function for sparsity",5,"SWS, S2, S1, REM, Awake","5 Classes
(Softmax)",N/M,"1) Training AE
2) Training softmax layer on learned features",SGD with momentum,"Momentum: 0.9
LR decay: 0.01",30,Random grid search,N/M,MSE,Inter,5-Fold CV,"Train: 60%
Valid: 20%
Test: 20%","6-9 hours of multivariate time-series sleep data. 25 PSG recordings.
Windows of 30 sec. 1 mini batch = 30 x 30s",Accurary,accuracy,N/M,,2-3h,60-90% on each of the 5 classes.,"DBN
SAE (standard a)
SAE (fixed a)
SAE (adaptive a)",DL,N/M,Visualization of attention mechanism weights,"""[...] Many of the used features try to capture the most relevant information for the current sleep stage and therefore mimic the standard Rechtschaffen and Kales (R&K) system [38, 18, 17] that is manually used by sleep technicians.""",Unsupervised learning treats all features equally; that's why attention mechanism is useful,No,N/A,No,"Not clear how the attention and the recurent network is used with the SAE.
[Hubert]: They mention the RNN once and then forget about it! I think that's probably a mistake that will be corrected in the next version of their paper.",,Yannick,Hubert,,Langkvist2018
,On the Classification of SSVEP-Based Dry-EEG Signals via Convolutional Neural Networks,2018,"Aznan, Bonner, Connolly, Moubayed & Breckon",Arxiv,Yes,Durham University,6,,Classification of EEG signals,BCI,Reactive,SSVEP,Improve State-of-the-Art,Apply CNN to SSVEP with dry EEG headset,SSVEP,Want an end-to-end system (no need to extract features),,Quick-20 (Cognionics),No,SSVEP,Internal Recordings,Private,4,20,500,"Collected: 640
For first subject: 400
For cross-subject: 80",Offline,,None,No,None,Raw EEG,N/A,,Pytorch,CNN,CNN,-,Layer 1: temporal filter,Yes,N/M,"2
(Tried 7 in the end)",ReLU,"L2 normalization
Dropout (50%)",,,4,N/M,Standard optimization,Adam,N/M,32,Grid search,No,Categorical cross-entropy,Both,"10-Fold CV
and
Leave-One-Subject-Out",N/M,"3 subjects x 20 trials x 4 classes
+ 1 subject x 100 trials x 4 classes
(time per trials not mentioned)",Accuracy,accuracy,Nvidia GTX 1060,,4 min,"Subject 1 - all data: 96%
Subject 1-3 (individually, only 20 trials each): mean of 89%
Across-subjects: 78%
Leave-one-subject:out:59% ","Traditional feature-based pipeline (Riemannian Geometry + classifier)
RNN, LSTM, GRU",DL & Trad.,No,No,Repeating the convolutional layer block increased accuracy on the held-out subject.,N/M,No,N/A,Yes,"Their benchmark results look a bit weak, knowing that they used RG...
The paper only mentions at the very end that they tried a deeper net too.",,Hubert,Isabela,,Aznan2018
,A Long Short-Term Memory deep learning network for the prediction of epileptic seizures using EEG signals,2018,"Tsiouris, Pezoulas, Zervakis, Konitsiotis, Koutsouris & Fotiadis",Computers in Biology and Medicine,No,National Technical University of Athens,14,,Classification of EEG signals,Clinical,Epilepsy,Prediction,"New Approach: Using LSTM for seizure detection. (claiming they are the first ones but they are not, so its a Improve SOTA)",Apply LSTM for seizure detection on CHB-MIT,"Resting State, Eyes Open, Eyes Closed, Seizures.","Expand from CNN to LSTM. (they claimed to be first, but they are not...)",,"N/M*
(see dataset paper)",No,Seizures,CHB-MIT,Public,23,23,256,"~980 hours of EEG
185 seizures",,,"1) Selecting only channels that are stable across recordings (for cross-validation)
2) Kept 18 channels.",No,"Time Domain: the 4 Statistical Moments, Standard Dev, Zero Crossings, Peak-to-peak Voltage, Total signal area, decorrelation time.
Frequency Domain: FFT (PSD), DWT.
Cross-Correlation: Max absolute coefficient.
Graph Theory: Local & Global measures.
(all on 5s windows)",Combination,N/M,,"Keras
Tensorflow
Python 3.6",LSTM,RNN,-,LSTM Length: predicting seizures from 15 min before onset to 120 min before onset,Yes,"Features x EEG Segments

643x[5-50]","LSTM_1: 1 (32 HU)
LSTM_2: 1 (128 HU)
LSTM_3: 2 (128/128 HU)

+ 1 FC (30)",ReLU,"Dropout
(finally discarded, because the shuffling of data seems to be enough)",,,"2
(Softmax, 1 hot encoded: preictal or interictal)",N/M,"By shuffling the EEG segments that are used as input, the LSTM network is forced to learn more generic preictal patterns as each sequence consists of random, non-adjacent preictal segments that not only come from various locations with different time distances from the actual seizure onset, but also from the preictal activity of different seizures.",Adam,"LR: 0.001
B1: 0.9
B2: 0.999
Decay: 0",10,Manually trying 3 different configurations,Splitted minority class in smaller subgroups to balance classes,Cross-Entropy,Both,10-Fold CV,"Eval: 3/24 
Train: N/M 
(assuming 21/24)","980 hours of EEG signals and 185 seizures from 24 cases.
5s windows","Sensitivity (SEN)
Specificity (SPEC)
False Prediction Rate (FPR)
Preictal Window","sensitivity, specificity, false prediction rate","N/M
(he seems to say CPU)",,N/M,"[Segments] SEN, SPEC |  [Events] SEN, FPR

15-min Preictal Window: 99.28, 99.28 |  100, 0.107
30-min Preictal Window: 99.37, 99.60 |  100, 0.063
60-min Preictal Window: 99.63, 99.78 |  100, 0.032
120-min Preictal Window: 99.84, 99.86 |  100, 0.02","SVM
Decision Trees
Repeated Incremental Pruning to Produce Error Reduction (RIPPER)

(LSTM outperforms all of them on all subjects)",Traditional pipeline,No,"Yes, going in depth on the 3 different LSTM networks they tried.","In theory, better EEG signal representation could be learned if the size of LSTM network was substantially increased, by adding more layers and memory units, to compensate for the increased input size of directly providing the EEG signals. However, the computational cost of training larger LSTM networks increases rapidly requiring more training time or using arrays of GPUs. Even if computational cost was not a problem, this approach would require even more EEG data to effectively train the millions of network parameters.","1) Overal amount of Data
2) Number of Seizures",No,N/A,Yes,"All Papers need to describe their network that way!
They compared 3 different LSTM
They compared feature-based vs learned features and Raw EEG underperforms feature-based.",,Yannick,Isabela,,Tsiouris2018
,Joint Classification and Prediction CNN Framework for Automatic Sleep Stage Classification,2018,"Phan, Andreotti, Cooray, Chén & De Vos",Arxiv,Yes,University of Oxford,11,,Classification of EEG signals,Clinical,Sleep,Staging,"Improve State-of-the-Art
(~New task: predict neighboring classes too)",Use one-to-many approach with a multi-task softmax to leverage neighboring data to predict sleep stage,Sleep,"Re-using their previous network.
(H. Phan et al., 2018)",,N/M*,No,Sleep events,MASS,Public,200,"1 EEG
1 EMG
1 EOG",100,"228,870",Offline,,"1) Convert 20s epochs in 30s epochs
    (+5s before + 5s after)",N/M,"Spectrogram (STFT)
Hamming window 2s + 50% overlap
Log Spectrum",Frequency-domain,N/M*,,Tensorflow,CNN,CNN,Conv-Pool-Softmax,Layer 0: filter bank on spectrogram,Yes,"129 x 29 x {1, 2, 3}
Bins x time, x channels
30-s epochs","1

(1xCNN +Pooling +Softmax)",ReLU,"L2
Dropout (20%)",5,"Wake
N1, N2, N3
REM",5 x (1 + 2 * nb of neighbouring windows),N/M*,Standard optimization,Adam,LR: 0.0001,200,N/M,Randomly selected batch with balanced classes,Categorical cross-entropy,Inter,"Leave-P-Subjects-Out
20 folds
","Train: 180 subjects
Valid: 10 subjects
Test: 10 subjects","228,870 epochs x 30s per epochs from 200 subjects","Accuracy, Kappa, Specificity, Sensitivity, F1-score","accuracy, Cohen's kappa, specificity, sensitivity, f1-score",N/M*,,1.36 hours,Multimodal acc.: 83.6 %,"One-to-one and Many-to-one with same architecture and with a different ConvNet architecture without l-max pooling
DeepCNN
DeepSleepNet",DL,No,No,"Increasing the number of filters in the Conv layer doesn't impact the performance much
Adding other modalities (EOG, EMG) lead to significant improvements
A context size larger than 3 leads to performance degradation
Using recurrent layers might help",No,No,N/A,No,"1. Not sure how their first ""filter-bank"" layer works. Seems to be omitted from their network graph figure.
2. Is this really a deep net? Looks like a 1-layer ConvNet to me.",,Hubert,Yannick,,Phan2018
,Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals,2018,Wen & Zhang,IEEE Access,No,Xiamen University,12,,Improvement of processing tools,Feature learning,,,Improve SOTA,Learn features for epilepsy detection using unsupervised learning,"Resting State, Eyes Open, Eyes Closed, Seizures.",Learn features automatically,,"N/M
(see dataset papers)",Both,Raw EEG,"Bonn University;
CHB-MIT",Public,"D1: 10? (Some healthly, some epileptic, some with intracranial EEG)
D2: 23","Chose a single channel
[D1: 128
D2: 23]","D1: 173.61
D2: 256",500,Offline,,"1) Common average reference
2) Bandpass 0.53-40 Hz",N/M,1) Chose single channel with the most variance,Raw EEG,min-max,,"Scikit-learn
Python",Convolutional AE,AE,Various (tried multiple classifiers on top of the encoder),-,Yes,4096 x 1,"9
[YR: not sure how HJB got that 9]",ReLU,N/M,2,"Seizure
No Seizure

(not explicit)",4096 x 1,N/M,"1) Training AE
2) Training standard classifier on learned features",Adam,N/M,N/M,N/M,N/M,Mean absolute error divided by input mean amplitude,Both,5 and 10 -Fold CV,N/M,"five subsets and each subset has 100 EEG signals. 
Each EEG signal has a duration of 23.6s and the length is 4096.",Accuracy,accuracy,N/M,,N/M,"No aggregate is reported...

(see paper, they report results per subject and per classifier)","PCA
Random projection",Traditional pipeline,No,No,"Less than 4 hidden units on the bottleneck layer led to a drop in accuracy as compared to standard dimensionality reduction techniques.
Their approach is flexible to new datasets...","""It is very difficult to train multiple hidden layers [...]"" ",No,N/A,No,"Interesting approach, but only used one channel!",,Hubert,Yannick,,Wen2018
,Deep learning with convolutional neural networks for decoding and visualization of EEG pathology,2018,"Schirrmeister, Gemein, Eggensperger, Hutter & Ball",Arxiv,Yes,University of Freiburg,7,,Classification of EEG signals,Clinical,Pathological EEG,,Improve SOTA ,End-to-end detection of abnormal EEG,N/M,Automated EEG diagnosis,,N/M,No,Raw EEG,TUH Abnormal EEG Corpus,Public,2385,21,250,"Abnormal: 1361 (train), 127 (test)
Normal: 1379 (train), 150 (test)",,,"1) Select 21 electrodes common to all subjects 
2) Remove 1st minute
3) Crop to recording to up to 20 minutes
4) Clip amplitude to +-800uV
5) Resample to 100Hz",N/M,Raw EEG,Raw EEG,N/M,,Pytorch,CNN,CNN,Tried two architectures: shallow and deep CNNs,Shallow CNN tailored to decode band powers,Yes,600 x 21,"Deep: 5 conv layers
Shallow: 1 conv layer",ELU,N/M,,,2,N/M,Standard optimization,Adam,Used SMAC ,N/M,SMAC ,N/M,Binary cross-entropy,Inter,10-Fold CV,"Train: 5480 (~90%)
Test: 554 (~10%)","we used 10-fold cross- validation performance obtained on the first 1500 recordings of the training data

16000 recordings of ~20 min from > 1000 patients","Accuracy, Sensitivity, and Specificity","accuracy, sensitivity, specificy",N/M,,< 3.5 h,"Accuracy: 85.4% (deep), 84.5% (shallow)
Sensitivity: 75.1% (deep), 77.3% (shallow)
Specificity: 94.1% (deep), 90..5% (shallow)",CNN and linear model with band-power features as input,DL & Trad.,,Effect of spectral perturbations of the input on the resulting prediction,"Perturbation visualizations showed that the CNNs used information related to changes in delta and theta bands. Suprisingly, shorter length EEG recordings yielded better accuracies.","""Still, to yield more clinically useful insights and diagnosis explanations, further improvements in ConvNet visualizations are needed.""",Yes,GitHub,No,Performed an architecture search that provide non-intuitive models. Best architecture did not reach significantly better performance. ,,Isabela,Hubert,,Schirrmeister2017a
,Predicting sex from brain rhythms with deep learning,2018,"van Putten, Olbrich & Arns",Scientific Reports (Nature),No,University of Twente,7,,Classification of EEG signals,Personal trait/attribute,Sex,,New Approach: Detecting Sex from RS EEG with DL (CNN),Predicting an individual's sex from their EEG,Resting State EEG.,"No need for engineered features, and ""have potential to detect subtle differences in otherwise similar patterns"".",,N/M,No,Raw EEG,Brain Resource Int'l Database,Public,1308,24,128,"52320
(Train: 40000)
(Test: 12320)",,,"1) Downsampled to 128Hz (from 500Hz)
2) Band-Pass Filter: 0.5-25Hz",EOG regression,Raw EEG,Raw EEG,N/M,,"Windows 10
Keras, Tensorflow
Python 3.6",CNN,CNN,None,N/M,Yes,"256 x 24
(Samples x Channels)
2s epoch",6,ReLU,Dropout,,,"1
0: Female  |   1: Male
(2 from schema)","9,051,902",Standard optimization,Adamax,"LR=0.002, B1=0.9, B2=0.999, e=10^8, decay=0.00",70,N/M,N/M,Categorical Cross-Entropy,Inter,No,"Train: 1000 subjects
Test: 308 subjects","40 non-overlapping EEG segments of 2 s dura- tion with eyes closed from every subject. In total, EEGs from 1000 adults were used for the training set (40 epochs × 1000 subjects = 40000 epochs of 2 s with 47% being males)
The independent test set comprised 308 cases (49% males, 40 segments from each subject × 308 subjects = 12320 samples of 2 s)",Accuracy,accuracy,NVidia GTX-1060,,N/M,"81% 
(of correct classification over all subjects)",CNN with precomputed features (from other paper),DL,,Visualization of learned filters through Deep Dream-like backprop on inputs,"While not all details of the features used for classification by the deep net have been revealed, our data show that differences in brain rhythms between sexes are mainly in the beta frequency range.",N/M,No,N/A,No,They also say that DL for Epilepsy might become the standard.,,Yannick,Hubert,,VanPutten2018b
,Deep learning with EEG spectrograms in rapid eye movement behavior disorder,2018,"Ruffini, Ibanez, Castellano, Dubreuil, Gagnon, Montplaisir & Soria-Frisch",BioarXiv,Yes,"NeuroElectrics
University of Montreal",10,,Classification of EEG signals,Clinical,Sleep,Abnormality detection,New Approach,Using DCNN for Rapid Eye Movement Behavior Disorder,Resting State EEG.,Exploiting compositional structure in data,,N/M,No,"
Raw EEG",Internal Recordings,Private,"118 RDB
74 Healthy",14,256,N/M,Offline,,"1) Band-Pass Filter: 0.3 and 100 Hz  [Hardware]
2) Notch Filter: 60Hz [Hardware]
((FFT) after detrending blocks of 1 second with a Hann window (FFT resolution is 2 Hz))",N/M,Spectrogram Frames,Frequency-domain,z-score,,Tensorflow,DCNN,CNN,Conv-Pooling-Dropout,N/M,Yes,"14 x 21 x 20
Channels x FFTBins x Epochs",5,ReLU,Dropout,2,"Parkinson's disease
Healthy",2,N/M*,Standard optimization,N/M,N/M,N/M,N/M,Random replication of subjects in the minority class,Cross-Entropy,Inter,"Leave-Pair-Out
(one subject for each class)",N/M,"118 out of 121 + 74 out of 85 subjects (~2.5min / subject)
148 windows of 20s per subject (sliding window of 1s)","Accuracy
AUC","accuracy, AUC",N/M,,N/M*,"Net: Problem [ N ] ACC (AUC)
DCNN: HC vs PD [2x73 / 2x1]   79% (87%)
RNN: HC vs PD [2x73 / 2x1]     81% (87%)
DCNN: HC+RBD vs PD+DLB [2x159 / 2x1]   73% (78%)
RNN: HC+RBD vs PD+DLB [2x159 / 2x1]     72% (77%)","Stacked RNN
Shallow CNN",DL,No,Yes (by maximizing network outputs for a given class). ,"Although here, as in [28], we worked with time-frequency pre-processed data, the field will undoubt- edly steer towards working with raw data in the future when larger datasets become available—as suggested in [21]","""We note that one of the potential issues with our dataset is the presence of healthy controls without
follow up, which may be a confound. \We hope to remedy this by enlarging our database and by
improving our diagnosis and follow up methodologies""",No,N/A,Yes,--,,Yannick,Isabela,,Ruffini2018a
,Deep transfer learning for error decoding from non-invasive EEG,2018,"Völker, Schirrmeister, Fiered, Burgard & Ball",IEEE International Conference on Brain-Computer Interface,Yes,University of Freiburg,6,,Classification of EEG signals,BCI,Reactive,ERP,New approach: Exploring Transfer Learning for BCI.,"Using CNN on 2 different BCI tasks, can it generalize? Transfer Learning across subjects and across tasks","1) Eriksen Flanker Task
2) Online GUI to control intelligent robots",Enables transfer learning,,N/M,No,"1) Error
2) Mental tasks (MI)",Internal Recordings,Private,"1) 31
2) 4","1) 128
2) 64",N/M,"1) N/M
2) (3032 +/- 818) * 4",,,"1) Re-referenced to Common Average (CAR)
2) Resampled to 250Hz",N/M,Raw EEG,Raw EEG,Electrode-wise exponential  running standardization,,"Python
BrainDecode
Scikit-learn",CNN,CNN,N/M,"N/M
(see BrainDecode paper)",No,"N/M
(Raw EEG windows)","N/M
(see BrainDecode paper)",N/M,"N/M
(see BrainDecode paper)",,,N/M,N/M,"N/M
(See braindecode paper)","N/M
(see BrainDecode paper)",N/M,N/M,N/M,N/M,"N/M
(see BrainDecode paper)",Both,"Withing-Sub: Leave-One-Session-Out CV
Between-Sub: Leave-One-Subject-Out CV","Within-Sub Train: 80%
Within-Sub Test: 20%
Between-Sub Train: N-1 Sub.
Between-Sub Test: 1 Sub.","Task #1: 31 subjects, Task #2: 4 subjects
Task #1: 1000 trials each sub, Task #2: 3032 ± 818 trials each sub.
1.5s trial (kept. onset at 0.5s)",Normalized Accuracy,normalized accuracy,N/M,,N/M,"Between-Subject Transfer Learning
Flanker Task:  81.7%  Normalized Accuracy
GUI Robots Task:  Poor results, because only 4 subjects.
Between-Paradigms Transfer Learning
Both failed. ~50%","rLDA
(CNN outperforms rLDA)

Also, best result ever reported on the Error Detection on Flanker Task*",Traditional pipeline,,Input-perturbation network-prediction correlation maps,"(1) As a next step, techniques including data augmentation and automated hyper-parameter and architecture search might help to improve the generalization of deep ConvNets. (2) For a generalization to new subjects, our data suggest that a training subject group of at least 15 subjects might be necessary for reliable error decoding on unknown subjects. (3) In the flanker task, our deep ConvNets achieved the highest to date reported average accuracy.",N/M,No,N/A,Yes,"Interesting to see that after 15 subjects the gain isn't that much.
Lots of information is not included in the paper and can be found in the original braindecode paper.",,Yannick,Hubert,,Volker2018
,DeepIED: An epileptic discharge detector for EEG-fMRI based on deep learning,2018,"Hao, Khoo, von Ellenrieder, Zazubovits & Gotman",NeuroImage: Clinical,No,"McGill University, Osaka University",14,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,Detect interictal epileptic discharges in noisy EEG data collected during an fMRI recording,Resting state EEG - Seizures.,Reduce the amount of time it takes to manually label interictal epileptic discharges,,Brain-Amp,No,Raw EEG,Internal Recordings,Private,67,25,200,N/M,Offline,,"1) Bandpass 0.5-50 Hz
2) fMRI-induced artefact removal
3) Electrode-wise exponential running standardization [6] was applied with a decay factor of 0.999
4) BCG artifact removal (ballistocardiographic)",N/M,Raw EEG,Raw EEG,N/M,,N/M,CNN (ResNet),CNN,-,-,Yes,25 x [16 to 256],31,ReLU,Dropout on penultimate layer (50%),"N/M
(different EID types)",EIDs,"128 (FC)
going to softmax and triplet (real output N/M)","999,920",Standard optimization,N/M,N/M,N/M,N/M,N/M,"Softmax for multi-class classification
Triplet loss function",Inter,No,"Train: 30 subjects
Test: 37 subjects","Trained on 30 patients with 70 studies
Tested on 37 patients with 78 studies
The average duration of EEG recording inside scanner was 50 min (range, 18–72 min).","ROC curves
Sensitivity
False positive rate","ROC curves, sensitivity, false positive rate",N/M,,N/M,"Median sensitivity: 84.2%
False positive rate: 5 events/min",Cross-correlation (template-based) method for finding similar EEG epochs,Traditional pipeline,"Yes
One-Way Anova + Post Hoc paired t-test",-,"In their tests, they asked experts to edit the outputs of the net and reject false positives; they argue that it's a necessary step and that it is not too time-consuming.",-,No,N/A,No,Good example of using DL as a clinical assistant tool.,,Hubert,Yannick,,Hao2018
,Deep learning for hybrid EEG-fNIRS brain–computer interface: application to motor imagery classification,2018,"Chiarelli, Croce, Merla & Zappasodi",Journal of Neural Engineering,No,G. d'Annunzio' University,12,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Improving MI classification with DL in multimodal system,Motor Imagery,High performance on other tasks,,Electrical Geodesic,No,ERD/ERS,Internal Recordings,Private,15,123 (out of 128),250,3000,Offline,,1) Bandpass 8-30 Hz,N/M,"Power in the mu-beta range, averaged across 1-s",Frequency-domain,N/M,,TensorFlow,Fully-connected NN,FC,N/M,N/M,Yes,"123 x 1, 16 x1, or 139 x 1",5,ReLU,Dropout (0.75),2,"Right-hand MI, Left-hand MI",2,N/M,Standard optimization,Adam,"LR=1e-4, B1=0.9, B2=0.999, constant=1e-8",90,N/M,N/M,Cross-Entropy,Intra,"10-Fold CV
(1000x)","Train: 180
Test: 20","MI: 5s task + 10s rest per trial  (10 min experiments)
20 trials left-hand + 20 trials right-hand = 40 trials of 5s
Taking 1s windows = 200 trials per subjects x 15",Accuracy,accuracy,N/M,,N/M,"EEG only: ~70%, NIRS only: ~77%, EEG+NIRS: ~83%","LDA, linear SVM",Traditional pipeline,"2-way repeated measurement ANOVA
+ post-hoc analysis ",N/M,"DNN worked better than CNN, RNN not tested.",RNN was not tested,No,N/A,No,NIRS alone is better than EEG alone!,,Hubert,[TBD],,Chiarelli2018
,Preference Classification Using Electroencephalography (EEG) and Deep Learning,2018,"Teo, Hou & Mountstephens","Journal of Telecommunication, Electronic and Computer Engineering (JTEC)",No,University Malaysia Sabah,5,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,"Improving classification of preference (like vs. dislike), and overcoming intra- and inter-subject variability","Rating of 3D Stimulus (1: like very much, 2: like, 3: undecided, 4: do not like, 5: do not like at all)  ",N/M,,ABM B-Alert X10,No,Raw EEG,Internal Recordings,Private,10 + 16,9,N/M*,208 (out of 960 total),Offline,,1) Notch Filter: 50Hz,Proprietary artefact rejection and interpolation," 45 features
(PSD for each channel)
D (1-3Hz), T (4-6Hz), A (7-12Hz), B (13-30Hz), G (31-64Hz)",Frequency-domain,N/M,,R,DNN,FC,N/M,N/M,No,47,2,ReLU,N/M,2,"Like very much
Do not like at all",N/M,N/M,Standard optimization,Adadelta,N/M,N/M,N/M,N/M,Cross-Entropy,Inter,10-Fold CV,N/M,"trials: 9s + [5-15]s x 16 subjects
208 trials out of 960 recorded (60 stimuli x 16 subjects)

10 subjects were for kNN",Accuracy,accuracy,N/M,,N/M,63.99%,"SVM Linear: 60.19%, SVM Radial:  59.67%, OneR: 59.00%, Adaboost: 58.65%, Random Forest: 57.74%, NNet: 57.71%, JRip: 57.21%, Naive Bayes: 56.79%, C5.0: 56.74%, kNN (k = 5): 56.29%       ",Traditional pipeline,No,No,"""An initial study using kNN provided sufficiently good results in a 10-subject study. However, when expanded to a larger cohort size of 16 subjects, the results were not encouraging. However, the use of deep learning was able to observably overcome some of the difficulties presented by inter-subject variability posed by larger cohort sizes in EEG-based preference classification.""",Intersubject variability,No,N/A,No,None,,Yannick,Hubert,,Teo2018
,An Automated System for Epilepsy Detection using EEG Brain Signals based on Deep Learning Approach,2018,"Ullah, Hussain, Qazi &Aboalsamh",Arxiv,Yes,"National University of Ireland
King Saud University",18,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,Improving ternary classification of ictal vs. normal vs. interictal windows,"Resting State, Eyes Open, Eyes Closed, Seizures.",Automatic feature learning,,N/M,No,Raw EEG,Bonn University,Public,15,1,173.6,"500 ""EEG samples"" with 23.6s each",Offline,,N/M,N/M,Raw EEG,Raw EEG,z-score,,TensorFlow,Pyramidal 1D-CNN (P-1D-CNN),CNN,No pooling,"1D convolution motivated by EEG being a ""1D signal""",Yes,"8 EEG windows
Raw EEG (1 channel)",3 Conv + 2 FC,ReLU,"Dropout (0.5)
Batch norm",2 or 3,"2: Epileptic vs. non-epileptic
3: normal vs. ictal vs. interictal","2 or 3 Classes
(Softmax)",N/M,Standard optimization,Adam,"LR=0.001, B1=0.9, B2=0.999, epsilon=0.00000001, locking=false",N/M,N/M,"Overlapping windows
(87.5% and 25% overlap)",Cross-Entropy,Inter,10-Fold CV,"Train: 90%
Test: 10%","100 signals for each class
Bonn University
Each record in the dataset consists of 4097 samples","Accuracy, Specificity, Sensitivity, Precision, f-measure, and g-mean.","accuracy, specificity, sensitivity, precision, f-measure, g-mean",N/M,,N/M,"99.1 ± 0.9% (for 3 classes problem)
The mean accuracy of the proposed system is 99.6% for all the sixteen cases/
Many results (see papers) comparing Binary / Tenary classifications.","Random forests, Naive Bayes, kNN",Traditional pipeline,No,No,"""According to our knowledge until this date, DL approach has never been used for this problem. The mean accuracy of the proposed system is 99.6% for all the sixteen cases (shown in Table 8 last column), which figures out the generalization power of the proposed system.""",Small datasets,No,N/A,Yes,-,,Yannick,Hubert,,Ullah2018
,A Novel Channel-aware Attention Framework for Multi-channel EEG Seizure Detection via Multi-view Deep Learning,2018,"Yuan, Xun, Ma, Suo, Xue, Jia & Zhang",IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),No,"Beijing Laboratory of Advanced Information Network
State University of New York at Buffalo",4,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,Use end-to-end model with attention mechanism to select channel and detect seizures.,N/M,"""Explore inherent EEG representations""",,N/M,No,Raw EEG,CHB-MIT,Public,9 (out of 23),23,256,4302,Offline,,N/M,N/M,Spectrogram (STFT),Frequency-domain,N/M,,N/M,2 SAEs,AE,"Channel Encoders (SAE)
Global Encoder (SAE)
+ Attention",N/M,Yes,N/M,2,N/M,Dropout,2,"No seizure
Seizure",2,N/M,"[Not clear!] Unsupervised pretraining, followed by fine-tuning with softmax layer?",Adam,N/M,N/M,N/M,N/M,Cross-Entropy,Inter,Hold-out,N/M,CHB-MIT,"F1-Score
Accuracy
AUC of ROC and precision-recall curves","f1-score, accuracy, AUC",N/M,,N/M,"[F1-score] - Channel Attloc:  0.9781, Channel Attglo: 0.9785
[Accuracy] - Channel Attloc:  0.9651, Channel Attglo: 0.9661","PCA+SVM (PSVM)
SAEs + attention
DNN + hard channel selection",DL & Trad.,N/M,Analysis of mean attention score values for a single subject,"""To the best of our knowledge, this is the first work using attention mechanism for biosignal channel selection in healthcare.""",,No,N/A,No,"Looks like the first attempt at attention mechanisms for channel selection.
Fig. 1 is wrong though: the attention score should be computed from the h_g and h_i, not the spectrograms. Also, according to Fig. 1 their input is 4-dimensional (channels x freq x time x ???)? They don't mention using Conv layers.
Also, not clear whether they use unsupervised pre-training or not.",,Yannick,Hubert,,Yuan2018a
,Compact Convolutional Neural Networks for Classification of Asynchronous Steady-state Visual Evoked Potentials,2018,"Waytowich, Lawhern, Garcia, Cummings, Faller, Sajda, Vettel",Arxiv,Yes,"U.S. Army Research Laboratory
Lab for Intelligent Imaging and Neural Comp.
University of Pennsylvania
University of California, Santa Barbara",21,,Classification of EEG signals,BCI,Reactive,SSVEP,Improve SOTA,Use ConvNet for SSVEP classification,SSVEP (12 classes!),Automatic feature learning without domain-specific information,,BioSemi ActiveTwo,No,SSVEP,Internal Recordings,Public,10,8,2048,1800,Offline,,"1) Bandpass 9-30 Hz
2) Downsampled to 256 Hz",,Raw EEG,Raw EEG,,,"TensorFlow, Keras
Original Stimuli (from 2015) on MATLAB with Psychophysics Toolbox",EEGNet,CNN,Filter banks (temporal convolutions) followed by spatial filters,N/M,Yes,8 channels x 256 samples,4,ELU,"Batch norm
Dropout (0.25)",12,12 different combinations of frequency and phase,12,N/M,Standard optimization,Adam,N/M,64,N/M,N/M,Categorical Cross-Entropy,Inter,Leave-One-Subject-Out,"Train: 90%
Test: 10%","10 subjects x 15 block x 12 trials x 4s
splitted in 1s trials to increase the amount of trials",Accuracy,accuracy,N/M,,N/M,"~90% for 7/10 Subjects.
60%, 75%, 30% for the others.
(chance = 8%)","CCA 
(Canonical Correl. Analysis)
C-CCA (Combined CCA)",Traditional pipeline,Paired t-tests when comparing to baseline,Visualization of feature activations with t-SNE,"""Although unexpected, these within-class clusters highlight the strength of the deep learning approaches to learn diagnostic features directly from the data.""",Experiment did not includ a non-control state,No,N/A,No,Their previous paper on C-CCA showed 90%+ on each subject on 1s windows and here C-CCA showed very poor performance... I'm missing something.,,Yannick,Hubert,,Waytowich2018
,Deep Classification of Epileptic Signals,2018,"Ahmedt-Aristizabal, Fookes, Nguyen & Sridharan",Arxiv,Yes,Queensland University of Technology,4,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve State-of-the-Art: Using LSTM for Epilepsy classification,End-to-end seizure detection,"Resting State, Eyes Open, Eyes Closed, Seizures.",Automatic feature learning,,"N/M*
(Using Bonn University dataset)",Both,Raw EEG,Bonn University,Public,15,1,173.6,"500 ""EEG samples"" with 23.6s each",Offline,,"None, but the Bonn University Dataset already has some preprocessing.",N/M,Raw EEG,Raw EEG,N/M,,Keras,LSTM,RNN,N/M,N/M,Yes,"100 x 4096
(100 samples of 4096 segments)","Model 1: 1 LSTM + 1 Dropout
Model 2: 2 LSTM + 2 Dropout
+ 1 FC",N/M,Dropout (0.35),2,"No seizure
Seizure",1,"Model 1: 16,961
Model 2: 116,033",Standard,Adam,"LR: 1e-3, b1:0.9, b2:0.999",4,N/M,No,Binary Cross-Entropy,Inter,10-Fold CV,"Train: 70% 
Valid: 20% 
Test: 10%","Bonn University
100 samples, each of them with 4096 segments.","Accuracy, Sensitivity, Specificity, Precision and the Area Under the Curve (AUC).","accuracy, sensitivity, specificy, precision, AUC",N/M,,N/M,"Accuracy: [Valid] 95.54% [Test] 91.25%
Sensitivity: [Test] 91.83%
Specificity: [Test] 90.50%
Precision: [Test] 91.50%
AUC: [Test] 0.9582","""Classification of epileptic EEG signals with stacked sparse
autoencoder based on deep learning""",DL,N/M,N/M,"""We experimented with various numbers of memory cells in each layer and obtained the best performance with a network configured with one single layer with 64 hidden units (Model 1) and with 2 hidden layers of 128 and 64 hidden units respectively (Model 2)""",N/M,No,N/A,Yes,The baseline utilized is a deep neural network. It would be nice to see how features+simple classifier works in this case.,,Yannick,Isabela,,Ahmedt-Aristizabal2018
,Emotion Recognition from EEG Using RASM and LSTM,2018,"Li, Tian, Shy, Xu & Hu",International Conference on Internet Multimedia Computing and Service,No,"South China University of Technology
Lanzhou University",9,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Using rational assymetry (RASM) as features and LSTM as classifier on DEAP dataset for emotion classification. 2 Classes (Positive / Negative Valence),Watching emotional movies (clips),LSTM to capture temporal dependencies in emotions,,N/M,No,Raw EEG,DEAP,Public,32,32,256,895 Trials,Offline,,None,No,"RASM14
(STFT + Hanning Window --> 4 Freq Bands)
",Frequency-domain,N/M,,N/M,LSTM,RNN,N/M,"""In our assumption, emotions change continuously, and this continuity is reflected in the temporal correlations of EEG signals. To explore the correlations, the classification method of Long Short-TermMemory networks (LSTM) is adopted.""",Yes,"125 * 14 * 4
(segments * pairs * bands)",1,N/M,"Dropout
(0.5)",2,"Positive valence
Negative valence",1,N/M,Standard,N/M,N/M,N/M,N/M,N/M,N/M,Inter,10-Fold CV,N/M,"895 trials in total were obtained, with 63-s data for each. And 125 segments for each trial were obtained using a half-overlapped 1-s Hanning window. 28 channels of EEG signals were selected out of 32 channels in the DEAP database",Accuracy,accuracy,N/M,,N/M,"RASM + LSTM:     76.67    (Accuracy)
RASM + SVM:       65.62    (Accuracy)
Zhang, 2016:         69.67    (Accuracy)
Chen, 2015:           73.00    (Accuracy)
Li X, 2016:             72.06    (Accuracy)","SVM
Zhang [10] (DE + GELM)
Chen [2] (Fusion feature + HMM)
Li [6] (Wavelet energy + CRNN)",DL & Trad.,No,No,"""Although the accuracy of our experiment is more than 75%, it is not good enough for applications. The task of the future work is to improve the recognition accuracy. More features will be tried especially those reflect the characteristics of EEG signals in frequency-space domain.""",N/M,No,N/A,No,Only 2 classes for Emotion Classification. Not sure if it's that good. Shouldn't be too hard to reproduce!,,Yannick,Isabela,,Li2018
,EEG detection and de-noising based on convolution neural network and Hilbert-Huang transform,2018,"Wang, Guo, Zhang, Bai & Wang","International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",No,"Changchun University of Science and Technology
Jilin Engineering Research Center of RFID and Intelligent Information Processing",6,,Improvement of processing tools,Signal cleaning,Artifact handling,,New Approach,Denoising EEG with Hilbert-Huang Transform after a detection of (yes/no) EOG artifact from a CNN classifier,N/M*,Nonlinearity of EEG,,N/M,No,Raw EEG,Internal Recordings,Private,N/M*,N/M*,1000,2100,,,N/M*,N/M*,IMF / HHT,Other,N/M,,N/M,CNN,CNN,2*2 convolution kernels,N/M,Yes,"""characteristic matrix of the extracted instantaneous power""",1,Softmax,N/M,,,"1
EOG artifact yes/no
(softmax)",N/M,N/M,N/M*,N/M,N/M,N/M,No,N/M*,,No,"Train: 2000
Test: 100",,Accuracy,accuracy,N/M,,N/M,80%,"(they don't compare the DL aspect... Just the HHT - after the DL)
Wavelet db8
HHT
HHT+FastICA",Traditional pipeline,,No,The results show that the method in this paper takes a little longer CPU time compared with the traditional wavelet de- noising [4] and HHT de-noising alone. But the signal-to-noise ratio after de-noising is obviously higher than the other two methods.,N/M,No,N/A,No,"They seem to use the CNN just to detect if there is an artifact or not, then use the Hilbert-Huang transform. The paper is more about that transform than the CNN.
Missing LOTs of info on the DL-EEG side. They don't even talk about the data they recorded...",,Yannick,[TBD],,Wang2018a
,Data Augmentation for EEG-Based Emotion Recognition with Deep Convolutional Neural Networks,2018,"Wang, Zhong, Peng, Jiang & Liu",International Conference on Multimedia Modeling,No,"Shenzhen University
The Hong Kong Polytechnic University",12,,Generation of data,Data augmentation,,,New Approach: Data augmentation on Emotion datasets for Deep learning models,Data augmentation on SEED & MAHNOB-HCI dataset and evaluation using ResNet & LeNet.,Watching emotional films/clips,Data augmentation for deep models with many parameters,,"N/M
(see datasets papers)",No,"Emotions
(Frequency Features)","SEED;
MAHNOB HCI",Public,"1) 14
2) N/M","1) 62
2) 32",N/M,"1) 1890
2) 527",Offline,,"1) Downsampled to 200Hz
2) Band-pass filters: 5 freq bands
3) SFTF with non-overlapping Hamming window 1s",Manual removal,Differential Entropy (DE) per band,Other,N/M,,MATCONVNET,"ResNet
LeNet",CNN,"Data Augmentation Paper, it's not about these networks.",Data augmentation with Gaussian Noise of various std,No,"n x l x 5
n: electrodes
l: length (time)
5: Freq Bands DE","LeNet: 5
ResNet: 14",N/M,N/M,3,"positive, neutral, negative","1) 3
2) 3","1) 4,000
2) 20,000",Standard optimization with augmented data,N/M,lr = 0.1,100,N/M,"Gaussian Noise
(augmented up to 30 times)",N/M,Inter,N/M,"1) 1134 (train), 675 (test)
2)  N/M",,Accuracy,accuracy,N/M,,N/M,"DS #1) LeNet: [Pre] 49.6% | [Post] 74.3%
DS #1) ResNet: [Pre] 34.2% | [Post] 75.0%
DS #2) ResNet: [Pre] 40.8% | [Post] 45.4%
DS #2) LeNet: N/M","DS #1) SVM: [Pre] 74.2% | [Post] 73.4%
DS #1) PCA-SVM: [Pre] 49.8% | [Post] N/M%
DS #2) SVM: [Pre] 42.5% | [Post] 44.3%
",Traditional pipeline,No,N/M,"By analyzing the experimental result, we find that the data augmentation method can effectively improve the performance of deep models. In future, we will seek to use other data augmentation methods, such as generative adversarial networks, to generate more effective samples of EEG data and improve the performance of EEG-based emotion recognition.",N/M,No,N/A,Yes,"Interesting results on the first dataset.
Their next step is trying a GAN to generate data. I'm quite interested in that.",,Yannick,Hubert,,Wang2018
,A convolutional neural network for sleep stage scoring from raw single-channel EEG,2018,"Sors, Bonnet, Mirek, Vercueil & Payen",Biomedical Signal Processing and Control,No,"Université Grenoble Alpes
CEA Leti, MINATEC Campus (Grenoble)
Dijon University Hospital (Dijon)
Grenoble University Hospital",8,,Classification of EEG signals,Clinical,Sleep,Staging,New Approach: Sleep Stage Scoring (5 stages) with CNN on Single EEG Channel,Use CNNs on raw EEG data for 5-class sleep prediction,Sleep,CNNs have presented good performance in other domains and other EEG tasks.,,N/M,No,Raw EEG,SHHS,Public,5728,1,125," Wake:1,514,280
N1: 201,431
N2: 2,169,452
N3: 719,690
REM: 779,548

Total: 5,384,401",Offline,,None.,No,Raw EEG,Raw EEG,No,,TensorFlow,CNN,CNN,(no mention of pooling or dropout),1D convolutional layers,Yes,"(3750 * 4) x 1

30s epoch + 2 preceding + 1 following
30s @ 125Hz = 3750 samples",12 Conv Layers + 1 FC (256) + 1 FC (5 classes),Leaky ReLU,N/M,5," Wake
N1
N2
N3
REM","5
[prob for each class]
(Softmax)",N/M*,Standard optimization,Adam ,"lr = 3 ×10^−5, b1 = 0.9, b2 = 0.999",128,N/M,"Tried cost-sensitive learning
and oversampling
(didn't improve. didn't use it.)",Multiclass Cross-Entropy,Inter,Train-valid-test split,0.5 / 0.2 / 0.3,,Accuracy,accuracy,NVidia GTX980Ti,,N/M*,87%,"Tsinalis [15] CNN: 0.75
Supratak [16] CNN-LSTM: 0.86
Liang [9] [...] : 0.88
Zhu [10]  DVG, SVM: 0.85
Fraiwan [6] T-F, RF: 0.83
Hassan [38] EMD, Ensemble: 0.87
Hassan [11] EMD, [...]: 0.89
Hassan [12] PSD, RF: 0.88
Hassan [39] EMD, [...] : 0.83
Sharma [13] Iterative filtering: 0.88
Hsu [14] Energy, RNN: 0.90",DL & Trad.,No,Yes,"""This study shows that it is possible to classify sleep stages using a single EEG channel and a convolutional neural network work- ing on raw signal samples without any feature extraction phase and with performance on par with other state-of-the-art methods.""
""Further research is necessary to address class imbalance. Ensemble learning [35] or CNN-specific methods [36] may prove suitable""",N/M,Yes,GitHub,No,If all the abstract could be like that one! You have ALL the info.,,Yannick,Isabela,,Sors2018
,ChronoNet: A Deep Recurrent Neural Network for Abnormal EEG Identification,2018,"Roy, Kiral-Kornek & Harrer",Arxiv,Yes,IBM Research - Australia,,,Classification of EEG signals,Clinical,Pathological EEG,,Improve SOTA,Detect abnormal EEG with a new end-to-end architecture,?,Automatic interpretation of EEG from raw data,,N/M,No,Raw EEG,TUH Abnormal EEG Corpus,Public,3017 sessions (patients might appear more than once!),22,250,"Abnormal: 1488
Normal: 1529",,,None.,,None,Raw EEG,N/A,,N/M,"1) Conv+GRU
2) Inception Conv+GRU
3) Dense Conv+GRU
4) Inception Dense Conv+GRU",CNN+RNN,"Conv filter sizes grow exponentially inside a given layer (e.g., 2, 4, 8)",-,Yes,15000 x ?,"1) 7
2) 7
3) 7
4) 7",N/M,N/M,,,2,N/M,Standard optimization,Adam,500 epochs,64,N/M,N/M,N/M,,"No for most of the paper, but tested 5-fold CV",90.8 - 9.2,,Accuracy,accuracy,N/M,,N/M,"1) 82.31
2) 84.11
3) 83.89
4) 86.57","CNN-MLP: 78.80
DeepCNN: 85.40",DL,,-,The ChronoNet architecture is a general-purpose architecture for time series - has been applied to speech data classication.,-,No,N/A,No,Preliminary version of the paper.,,Hubert,[TBD],,Roy2018
,EEG-GAN: Generative adversarial networks for electroencephalograhic (EEG) brain signals,2018,"Hartmann, Schirrmeister & Ball",Arxiv,Yes,University of Freiburg,7,,Generation of data,Generating EEG,,,Generate EEG signals,Generate EEG signals using GANs,Motor imagery,GANs are good at generating data,,N/M,No,Raw EEG,Internal Recordings,Private,?,1,250,438,,,None.,No,None,Raw EEG,Subtract mean then divide by maximum absolute value,,N/M,Wassertein GAN (modified),GAN,-,"Conv layers instead of autoregressive model, as it worked well in the authors's other papers",Yes,"Gen: 200
Discr: 768","Gen: 14
Discr: 14",Leaky ReLU,"Minibatch standard deviation [normalization?]
Pixel normalization",N/A,N/A,"Gen: 768
Discr: 1",N/M,GAN optimization with increasing resolutions,Adam,"""Equalized learning rate""
lr = 0.001
beta1 = 9
beta2 = 0.99",?,N/M,No,Improved Wassertein distance,N/A,-,286-72-80,,"Inception score
Frechet inception distance
Euclidean distance
Sliced Wassertein distance","inception score, frechet inception distance, euclidean distance, sliced Wasserstein distance",N/M,,N/M,[Too many obscure values],WGAN with gradient penalty,DL,No,"Visual inspection of generated segments (time series distribution, spectrum distribution, examples)","The metrics did not correlate with visual performance, and so the authors recommend using many metrics to obtain a balanced view",Mode collapse in GANs,No,N/A,No,Very descriptive on the DL side.,,Hubert,Isabela,,Hartmann2018
,Know Your Mind: Adaptive Brain Signal Classification with Reinforced Attentive Convolutional Neural Networks,2018,"Zhang, Yao, Wang, Zhang, Zhang & Liu",Arxiv,Yes,"University of New South Wales, Tsinghua University, Michigan State University",,,Classification of EEG signals,Multi-purpose architecture,,,Make general framework for EEG classification,Apply a single architecture (reinforced attentive CNN) to EEG classification,"1 & 2: Motor imagery
3: Person identification
4: Pathology (seizure detection)",Skip time-consuming feature engineering and no task-specific classifier.,,"1) ?
2) Emotiv
3) ?
4) ?",No,"1 & 2) Motor Imagery
3) None
 4) Seizures","eegmmidb;
Internal Recordings;
EEG-S;
TUH",Both,"1) 20
2) 7
3) 8
4) 5","1) 64
2) 14
3) 64
4) 22","1) 160
2) 128
3) 160
4) 250","1) 560,000
2) 241,920
3) 56,000
4) 60,000",,,None.,,None,Raw EEG,N/A,,TensorFlow,CNN with attention + DQN,CNN,"1) Replicating and shuffling incoming samples
2) Attention mechanism trained with RL
3) CNN
4) Nearest-neighbour classifier",A) Replicate and shuffle operation intended to randomly unveil interesting spatial patterns,Yes,1 x nb_channel,"CNN: 3
DQN: 2",ReLU & Sigmoid,L2,,,"1) 5
2) 6
3) 8
4) 2",N/M,Standard optimization (including reinforcement learning),Adam,Learning rate: 0.001,N/M,N/M,No,Cross-entropy,,N/M,N/M,,"Accuracy, Precision, Recall, F1-score
Latency
Resilience","accuracy, precision, recall, f1-score, latency, resilience",N/M,,N/M,"Accuracy
1) 0.9932
2) 0.9708
3) 0.9984
4) 0.9975","Not clear what they were trained on (samples? features?):
Linear SVM, Random Forest, kNN, LSTM, GRU, Adaptive boosting, LDA
+ 5 state-of-the-art papers for each (20 total)",DL & Trad.,,-,"Latency is comparable to other methods
The number of channels used affects the performance.",-,Yes,GitHub,No,"How come their accuracy is so high??
Sample-by-sample classification instead of per epoch is interesting! However, how did they go from labels (usually applied to windows) to samples when reporting performance?",,Hubert,Yannick,,Zhang2018a
,Gated Recurrent Networks for Seizure Detection,2018,"Golmohammadi, Ziyabari, Shah, Von Weltin, Campbell, Obeid & Picone",Arxiv,Yes,"Neural Engineering Data Consortium, Temple University",,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA (their previous work),"Explore Gated RNN (LSTM & GRU), explore initialiazation and regularization of these networks",(see TUH dataset paper),Improve their last results,,(see TUH dataset paper),No,Seizures,TUH Seizure Corpus,Public,(see TUH dataset paper),22,250,(see TUH dataset paper),,,None.,,LFCCs + First & Second Derivative of LFCCs,Other,N/A,,N/M,"1) CNN + LSTM
2) CNN + GRU",CNN+RNN,"2D CNN to 1D CNN to bi-LSTM
First LSTM output: 128 (1s data / epoch)
Second LSTM output: 2-way sigmoid
(classification of a 1s epoch)","1) Gated units to avoid vanishing gradient.
2) RNNs to capture long-term dependencies.",Yes,"210 x 22 x 26
(Windows * Channels * Features)","3x 2D CNN
+ 1x 1D CNN
+ LSTM",ELU,"1) L1
2) L2
3) L1/L2
4) Dropout
5) Guassian Noise",,,"1
(classification - sigmoid)",N/M,"Initialization: 
The best performance is achieved using orthogonal initialization",Adam,N/M,N/M,N/M,No,MSE,,N/M,N/M,,"Sensitivity, Specificity","sensitivity, specificity",N/M,,N/M,"CNN + GRU -   Sensitivity:  30.83%   |    Specificity:  91.49%
CNN + LSTM -   Sensitivity:  30.83%   |    Specificity:  97.10%

Best Regulation: L1/L2
Best Initialization: Orthogonal","Compared CNN+GRU vs CNN+LSTM
Compared 10 different initialization methods (see comments)
Compared 5 different regularization methods
(L1/L2, L1, L2, Gaussian noise, Dropout)
",DL,,-,"LSTMs outperformed GRUs. We also studied initialization and regularizations of these networks. In future research, we are designing a more powerful architecture based on reinforcement learning concepts. We are also optimizing regularization and initialization algorithms for these approaches. Our goal is to approach human performance which is in the range of 75% sensitivity with a false alarm rate of 1 per 24 hours [11].","No enough labeled data. Having certified specialist to label the data is very expensive, and hard to have people to do it.",No,N/A,Yes,They compare many Initializations methods. Interesting! Orthogonal [26] Lecun Uniform [27] Glorot Uniform [28] Glorot Normal [28] Variance Scaling [26] Lecun Normal [27] He Normal [29] Random Uniform [26] Truncated Normal [26] He Uniform [29]   (see Table 4),,Yannick,[TBD],,Golmohammadi2017b
,Optimizing Channel Selection for Seizure Detection,2018,"Shah, Golmohammadi, Ziyabari, Weltin, Obeid & Picone",Arxiv,Yes,"Neural Engineering Data Consortium, Temple University",,,Classification of EEG signals,Clinical,Epilepsy,Detection,Study the Impact of Number of Channels,Explore the impact of using/having from 2 to 22 channels with same network,(see TUH dataset paper),"Lower the number of EEG channels required 
(also save disk space)",,(see TUH dataset paper),No,Seizures,TUH Seizure Corpus,Public,(see TUH dataset paper),"[2, 22]",250,(see TUH dataset paper),,,None.,,LFCCs + First & Second Derivative of LFCCs,Other,N/A,,N/M,CNN + LSTM,CNN+RNN,(same as there previous paper: Gated Recurrent Networks for Seizure Detection),(same as there previous paper: Gated Recurrent Networks for Seizure Detection),Yes,"210 x 22 x 26
(Windows * Channels * Features)","3x 2D CNN 
+ 1x 1D FC CNN
+ 2x Bi-LSTM",ELU & Sigmoid,Dropout,,,"1*
(classification - sigmoid)",N/M,N/M,Adam,N/M,N/M,N/M,No,MSE,,N/M,N/M,,"Sensitivity, Specificity","sensitivity, specificity",N/M,,N/M,"22 Channels -    Sensitivity:  39.15%    |    Specificity:  90.37%
20 Channels -    Sensitivity:  34.54%    |    Specificity:  82.07%
16 Channels -    Sensitivity:  36.54%    |    Specificity:  80.48%
8 Channels -    Sensitivity:  33.44%    |    Specificity:  85.51%
4 Channels -    Sensitivity:  33.11%    |    Specificity:  39.32%",22 Channels is their baseline.,None,,-,The results presented in this paper use the Any Overlap scoring method [11] in which true positives are counted when the hypothesis overlaps with one or more reference annotations. False positives correspond to events in which the hypothesis annotations do not overlap with any of the reference annotations. This method of scoring is popular in the EEG research community.,-,No,N/A,No,-,,Yannick,[TBD],,Shah2017
,Improving brain computer interface performance by data augmentation with conditional Deep Convolutional Generative Adversarial Networks,2018,Zhang & Liu,Arxiv,Yes,Beijing Institute of Technology,,,Generation of data,Data augmentation,,,Generate EEG signals,Generate EEG signals using GANs for data augmentation,Motor Imagery (Left/Right Hand),To increase amount of data available for training,,(see BCI competition dataset),No,Motor imagery,BCI Competition II - III,Public,1,3,128,280,Offline,,None,No,"Continuous Wavelet transform (Morlet)
Only keep 7-15 Hz",Frequency-domain,N/A,,N/M,"Augmentation: cDCGAN
Classification: CNN",CNN,Conditional Deep Convolutional GAN (cDCGAN) + label information as input to both generator and discriminator,2D kernel to accomodate input TFR,Yes,N/M,N/M,ReLU,N/M,2,"Left Hand
Rigth Hand",Same as input (not mentioned),N/M,"cDCGAN optimization
Training CNN with real and artificial data",N/M,N/M,N/M,N/M,"GAN
[0.5 - 2x]
(artificial EEG data)",N/M,Intra,N/M,"Train: 50%
Test: 50%",,Accuracy,accuracy,N/M,,N/M,"No augmentation: ~83 %
50% of augmentation: ~84%
150% of augmetation: ~84%
200% of augmentation: ~85.5%",None,None,No,No,Data augmentation with GAN is does help increasing accuracy when limited data is available.,Limited amount of data available per subject when training a BCI.,No,N/A,Yes,Definitely a first draft - a lot of missing information and English has not been reviewed. ,,Hubert,Yannick,,Zhang2018b
,Convolutional neural networks for seizure prediction using intracranial and scalp electroencephalogram,2018,"Truong, Nguyen, Kuhlmann, Bonyadi, Yang, Ippolito & Kavehei",Neural Networks,,"University of Sydney
Royal Melbourne Institute of Technology
Swinburne University
University of Melbourne
University of Queensland
University of Adelaide",,,Classification of EEG signals,Clinical,Epilepsy,Prediction,Improve SOTA,Use CNN to improve SOTA in seizure detection,Ongoing recording with and without seizures,Test CNN on different epilepsy datasets,,N/M,Both,"None
(Seizures)","Freiburg Hospital;
CHB-MIT;
Kaggle: AESSPC",Public,"1) 13
2) 13
3) 2 humans + 5 dogs","1) 6
2) 22
3) 16",(see datasets papers),"1) 59 Seizures + 311h
2) 64 Seizures + 209h
3) 48 Seizures + 627h",,,"1) Removed Powerline: 47-53Hz + 97-103Hz
2) Removed DC Component (0Hz)",,"SFTF
(2D Freq x Time)
30s EEG windows",Frequency-domain,N/A,,"Python
Keras
Tensorflow",CNN,CNN,"Batch Norm + Pooling
2 Dense","First, we keep the CNN architecture simple and shallow as described above (Ba & Caruana, 2014)",Yes,"n x 59 x 114
(electrodes x time x freq)","CNN: 3
FC: 2","ReLU
Sigmoid
Softmax
","Dropout 
(50%)",,,2,N/M,We applied cost-sensitive learning by changing 300 the cost function in a way that the misclassification cost of preictal samples is multiplied by the ratio of interictal samples to preictal samples for each patient.,N/M,N/M,N/M,N/M,"Overlapping windows
(overlap % subject-specific to match classes)",N/M,,"Leave-one-out
(each out executed twice)","Train: 75%
Test: 25% ",,"Sensitivity
FPR (/h)","sensitivity, FPR", NVidia K80,,N/M,"Measures (Epilepsy Specific): 
SOP of 30 min  |   SPH of 5 min

DS #1) Sensitivity : 81.4% | FPR: 0.06/h
DS #2) Sensitivity : 81.2% | FPR: 0.16/h
DS #3) Sensitivity : 75.0% | FPR: 0.21/h","Compares on 3 Datasets

Compares to 14 other SOTA (papers)",DL & Trad.,,N/M,,"(1) Unbalanced Classes.
(2) Comparing results with SOTA is complicated because each approach was tested with one dataset that is limited in the amount of data.",No,N/A,Yes,-,,Yannick,[TBD],,Truong2018
,Semi-supervised Seizure Prediction with Generative Adversarial Networks,2018,"Truong, Kuhlmann, Bonyadi & Kavehei",Arxiv,Yes,"University of Sydney
University of Melbourne
University of Queensland",,,Classification of EEG signals,Clinical,Epilepsy,Prediction,Improve SOTA,Use unlabelled data and data fusion to improve SOTA in seizure prediction,"Resting State, Eyes Open, Eyes Closed, Seizures.",Leverage unlabelled data,,N/M,No,Raw EEG,"CHB-MIT;
Freiburg Hospital",Public,"1) 13
2) 13","1) 16 (22 available)
2) 6",256,N/M,,,"STFT on 1-s windows with 50% overlap
Removal of power line noise frequencies",,STFT,Frequency-domain,N/M,,Tensorflow,"1) GAN
2) CNN",Other,-,-,Yes,"1) GAN generator: 100 x1
2) GAN discriminator: n x 56 x 112
3) CNN: Same as discriminator","1) GAN generator: 4
2) GAN discriminator: 3
3) Classifier: 2","Softmax, Sigmoid",Dropout (50%),,,"1) GAN generator:
2) GAN discriminator:
3) CNN",N/M,"1) Train GAN
2) Train 2 new FC layers on top of discriminator using labelled data",N/M,N/M,N/M,N/M,"Overlapping windows
(overlap % subject-specific to match classes)",N/M,,Leave-one-sample-out (one example from each subject is left out),75-25,,AUC,AUC,Nvidia P100,,N/M,"AUC: 77.68% (CHBMIT), 75.47 (Freiburg)
[6 and 12% less than benchmark]",CNN,DL,,-,"Although the performance decreased as compared to a standard CNN, the authors argue this can reduce the effort put into labelling the data.",-,No,N/A,No,"This paper is obviously not in a state to be published. Missing references, and pretty short. The conclusion is completely unrelated to the rest of the paper... :P
Also, many things are not clear: what is their CV methodology? How was the benchmark trained? How much labelled data did they use after the GAN training?",,Hubert,[TBD],,Truong2018a
,Time Series Segmentation through Automatic Feature Learning,2018,"Lee, Ortiz, Ko & Lee",Arxiv,Yes,Princeton University,,,Classification of EEG signals,Multi-purpose architecture,,,Improve SOTA,Detect changepoints/breakpoints in data (changes in signal) and apply to different types of time series data,Eye movements,"Deep learning models for changepoint detection don't make assumptions about the underlying processes, as opposed to standard models",,Emotiv,No,Eyes open vs. eyes closed,EEG Eye State,Public,1,14,256,N/M,,,N/M,,N/M,NS,N/M,,N/M,Stacked Autoencoder,AE,-,-,No,N/M,2 (encoder),N/M,"Tied weights in encoder and decoder
L2 weight decay",,,2,N/M,Standard optimization,Stochastic gradient descent,N/M,N/M,N/M,No,Cross-entropy (or square loss?),,N/M,N/M,,"ROC
Prediction loss (specific to task)","ROC, prediction",N/M,,N/M,ROC curves...,"Bayesian changepoint detection (based on Gamma or Gaussian priors)
Pruned Exact Linear Time method
Density-ratio estimation method",Traditional pipeline,,-,Deep learning avoids typical problems in modelling changepoints.,-,No,N/A,No,"Interesting task. Cool to see that people from other field try their algorithms on EEG data. However, the data (eyes open vs. eyes closed) is in my opinion not challenging at all. Also, basic information is missing.",,Hubert,[TBD],,Lee2018a
,Investigating the Impact of CNN Depth on Neonatal Seizure Detection Performance,2018,"O’Shea, Lightbody, Boylan & Temko",Arxiv,Yes,University College Cork,,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,Use CNN to improve SOTA in seizure detection in neonatal,Ongoing recording with and without seizures,Improve SOTA with CNN-11 based on their CNN-6 (2017),,N/M,No,Raw EEG,Internal Recordings,Private,18,8,256,N/M,,,"Down-sample to 32Hz
Filtered between 0.5 and 12.8Hz",,8 sec windows (1 sec shift),Raw EEG,N/A,,N/M,CNN,CNN,"Conv - Batch Norm - Pooling
Output not Dense layer but 
Grand Average Pooling","""The 11-layer network can learn more simple features in the first layer (3 samples wide) and more complex features in the final layers (212 samples wide).""",Yes,"256x1 
(1sec - 256 samples)",11,Softmax,N/M,,,"2
Seizure / Non-Seizure","28,642","The network was trained for 100 epochs, after each epoch the validation AUC was calculated.",Stochastic Gradient Descent,"LR: 0.01
Momentum: 0.9",2048,N/M,N/M,N/M,,Leave-one-subject-out,The training data contains less than 2% of the validation dataset,,AUC,AUC,N/M,,N/M,AUC90: 86.85%,"CNN - 6 layers (O'Shea et al., 2017)
SVM",DL,,N/M,This represents a substantial improvement over a shallower 6-layer CNN network which has a smaller range of receptive fields. These results represent the current best results for this task obtained using a single classifier.,N/M,No,N/A,No,They are the new SOTA acording to them. To be validated!,,Yannick,[TBD],,Shea2018
,Fair Deep Learning Prediction for Healthcare Applications with Confounder Filtering,2018,"Wu, Wang, Cao, Chen, Xing",Arxiv,Yes,"Beijing University of Posts and Telecommunications, Carnegie Mellon University",12,,Improvement of processing tools,Reduce effect of confounders,,,New approach: Reduce effect of confounders in medical data,"Reduce the effect of confounders in medical data (e.g., gender bias in training data)",Students watching MOOC videos,Learn representations from scratch,,NeuroSky Mindset,No,Raw EEG,Internal Recordings,Private,10,1,N/M,N/M,N/M,,N/M,No,Raw EEG,Raw EEG,z-score,,TensorFlow,Bi-LSTM,RNN,Use of Confounder Filtering,N/M,No,N/M,N/M,Tanh,N/M,2,"Confused
Not-confused",1 (sigmoid),N/M,N/M,N/M,N/M,20,N/M,N/M,Binary Cross-Entropy*,N/M,5-fold CV,N/M,,Accuracy,accuracy,N/M,,N/M,CF-Bidirectional LSTM acc: 75.0%  ,"SVM: 67.2%
K-Nearest Neighbors: 51.9%
Convolutional Neural Network: 64.0%
Deep Belief Network: 52.7%
RNN-LSTM: 69.0%
Bidirectional LSTM: 73.3%",DL & Trad.,No,No,The use of confounding filtering improves the predictive performance. ,N/M,Yes,GitHub,No,"Nice paper. The proposed method (confounding filtering) is tested in many scenarios. Work is not super deep in the EEG side, but it is a nice example of people using EEG data to validate new approaches.",,Isabela,[TBD],,Wu2018
,HAMLET: Interpretable Human And Machine co-LEarning Technique,2018,"Deiss, Biswal, Jin, Sun, Westover & Sun",Arxiv,Yes,"Georgia Institute of Technology
Massachusetts General Hospital",9,,Classification of EEG signals,Multi-purpose architecture,,,New approach,Help experts generate high quality labels,"Tested on Epilepsy data, could be used for different tasks",Features can be automatically extracted to help experts label the data,,N/M,No,Raw EEG,Internal Recordings,Private,155,19,200,4176h of recordings,,,"1) Low-Pass filter: 60Hz
2) Computation of montages*
(not sure what that means)
3) 16s windows",No,"Raw EEG
(None)",Raw EEG,N/M,,"Python
Tensorflow","CNN
CAE
(Conv AutoEncoder)",Other,"1D CNN
FC Layer only for training
","One advantage of CNNs is the automated feature selection that happens during training. Without additional work, the model learns the features that it finds most relevant for its given task, from the raw signals.",Yes,16x,Classifier: 6 Conv + 1FC,ELU,"Dropout
(20%)",,,"5
(softmax)",N/M,"Co-Learning
Supervised & Unsupervised",Adam,N/M,128,N/M,"Flipped Electrodes Left <-> Right side of brain, keeping references the same (Fz, Cz, Pz)
almost 2x dataset.",N/M,,N/M,"Train: 80%
Test: 20%",,Accuracy,accuracy,"Intel(R) Xeon(R) 
E5-2630 2.40 GHz 
32 cores
256 Gb ofRAM 
4 GPUs Tesla K80",,13h,"Before re-labeling    |    After re-lbl full    |     After re-lbl re-eval only
HAMLET-CNN      39.36%  |  40.75%  |  68.75%
HAMLET-CAE      38.46%  |  39.06%  |  67.97%
CNN                      38.89%  |  41.58%  |  68.75% 
MLP                      21.04%  |  23.14%  |  14.06%","(only internal comparisons)
HAMLET-CNN
HAMLET-CAE
CNN
MLP",DL,,They talk about the importance of interpretability of the results.,"To summarize, first, we have introduced a novel tech- nique, HAMLET, for human and machine co-learning that is suited for creating high-quality labeled datasets on challenging tasks with a limited budget. This technique has benefits that can appreciated in many deep learning applications.",N/M,No,N/A,Yes,"Not an easy one to read / understand, but very interesting. Trying to address a real problem in EEG / DL
(prepare a bit of time :p)",,Yannick,[TBD],,Deiss2018
,Addressing Class Imbalance in Classification Problems of Noisy Signals by using Fourier Transform Surrogates,2018,"Schwabedal, Snyder, Cakmak, Nemati & Clifford",Arxiv,Yes,Emory University,7,,Generation of data,Data augmentation,,,Improve SOTA,Use FT Surrogates for Data Augmentation. (Tested with a CNN on Sleep Data),Sleep Dataset (CAP),"Some EEG problemes are unbalanced. (e.g. Sleep stages, Epilepsy, etc.) For DL to perform well, we need data augmentation techniques.
",,N/M,No,Sleep,CAP Sleep,Public,101,"EEG: 2
EOG: 1
EMG: 1","N/M
(see dataset paper)",101 x 8h,,,"Low-pass filter: 13Hz (4th order Butterworth)
Downsampling to 32Hz",No,"Raw EEG
(None)",Raw EEG,N/M,,N/M,CNN,CNN,"1D CNN for each channel: 
2xEEG + 1xEOG + 1xEMG",,Yes,30s Raw EEG,"Conv 1D: 4
Conv 2D: 1
FC: 3",,Dropout,6,"Wake
S1, S2, S3, S4
REM","6
(softmax)",N/M,N/M,RMS-Prop,"LR: 0.0016
Momentum: None
Decay: 0.9",128,Baysian Hyperparams Optim.,FT Surrogates,N/M,,5-Fold CV,"Train: 4/5
Validation: 1/5
Test: N/M",,"F1-Score
Accuracy","f1-score, accuracy",Google Cloud,,N/M,"Accuracy (no augmentation):    67% | 73% | 51% | 64% | 75% | 70% 
Accuracy (FT surrogate):          83% | 86% | 38% | 75% | 97% | 46% 
Accuracy (IAAFT surrogates):   91% | 83% | 48% | 79% | 96% | 81% ","(all internal, no external)
No data augmentation
FT surrogates
IAAFT surrogates",None,,N/M,"Increases in the S2-accuracy seemed to be at the expense of stages S1 and S3 for larger values of α. Based on these results, we hypothesize that the effect of surrogate augmentation on an individual class accuracy does not directly depend on their conditional prediction accuracies, which are on the diagonal of the conditional confusion matrix (cf. Fig. 4(a)); instead, augmentation may introduce mixing between class labels indicated by a large off-diagonal element upon which the accuracy of one of the mixed labels will dominate.","Unfortunately, we were not yet able to evaluate and compare IAAFT surrogates with these results due to temporal and budget constraints.",Yes,GitHub,Yes,Using FT Surrogates to generate Raw EEG is assuming that the frequency features are explaining pretty much all the data. (I feel like it reduces the power of DL on raw data),,Yannick,[TBD],,Schwabedal2018
,EEG Classification Based on Sparse Representation and Deep Learning,2018,"Gao, Shang, Xiong, Fang, Zhang, & Gu ",NeuroQuantology,No,"Zhejiang University City College,",7,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use CNN + Sparse coding on top of CSP features,Motor Imagery,N/M,,N/M,No,CSP,BCI Competition III - IVa,Public,2 out of 5,118,100,"140 / class
(280 trials)",Offline,,Band-pass filter 8-15Hz,No,CSP (32 CSP filters),Frequency-domain,N/M,,N/M,CNN,CNN,CNN's input is a sparse representation of CSP features,N/M,Yes,28 x 28,"CNN: 2
FC: 1",ReLU,N/M,2,"Right Hand
Right Foot",2 (softmax),N/M,N/M,N/M,N/M,N/M,N/M,N/M,Binary cross-entropy,Inter,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"Accuracy Class 1: 98%
Accuracy Class 1: 99%",Sparse representations (not clear what is the classifier),Traditional pipeline,No,No,Performance of CNN+sparse representations is less afect when the number of training samples decreases.,N/M,No,N/A,No,"The idea of using sparse coding seems really nice. However, the paper is shallow. Important aspects of the training and results are missing. ",,Isabela,Yannick,,Gao2018
,Use of features from RR-time series and EEG signals for automated classification of sleep stages in deep neural network framework,2018,"Tripathy, & Rajendra Acharya",Biocybernetics and Biomedical Engineering,,"Siksha 'O' Anusandhan, India
Ngee Ann Polytechnic, Singapore
SUSS University, Singapore",13,,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use DNNs on EEG + ECG for sleep stage scoring,Sleep Dataset (MIT-BIH),They don't mention why DL.,,"N/M
(see MIT-BIH paper)",No,"Raw EEG
(Sleep)",MIT-BIH,Public,18,"1 EEG
1 ECG",250,N/M*,,,1) 5 Band-pass filters to 5 freq bands,No,"14 EEG-HRV Features  (out of 19)
(The dispersion entropy and the variance features are evaluated from the different bands of EEG signal)
(the RQA and dispersion entropy features are evaluated from the IMFs of RR-time series)",Other,N/M,,Matlab 2015a,SAE,AE,"3 DNNs

EEG features + HRV features combined 
as inputs. Outputs = 2 classes (x3 DNNs)",N/M,Yes,"14 EEG Features
 ECG Features
(30s window)",2 AE,Sigmoid,"L2

(N/M... Assumed from the formula)",,,"2 (softmax)

3 DNN Networks
Classifying 2 classes each",N/M,Greedy Layer Wise,SGD,N/M,N/M,N/M,N/M,(See Formula),,10-Fold CV,N/M,,"Accuracy (Acc)
Sensitivity (Sen)
Specificity (Spe)","accuracy, sensitivity, specificity","CPU 2 GHz
2 GB RAM",,"1 Instance:
EEG: 4.89s 
RR: 0.03s","Acc Sleep vs Wake: 85.51%
Acc Light vs Deep Sleep: 94.03%
 Acc REM vs NREM: 95.71%","Hayet and Slim [55] (ELM, Werteni et al. [56] (SVM), Adnane et al. [16] (SVM), Rossow et al. [57] (HMM), Redmond and Heneghan [58] (QDA), Song et al. [59] (Multivariate Discrim. Analysis), Prucnal et al. [12] (NN), Hasan et al. [11] (RUSBoost), Da Silveira et al. [13] (RF)",Traditional pipeline,,N/M,"The dispersion entropy values for delta (d), theta (u) and alpha (a) bands are found to be more discriminatory for the classification of the wake and sleep classes.","The limitation of this work is that we have used only 18 subjects. The performance of this work can be improved using more subjects from the diverse race. The number of REM sleep stage instances in MIT-BIH polysomnography database is less as compared to deep sleep, light sleep and wake classes.",No,N/A,Yes,Interesting... Not really a multiclass however. But seems quite high compared SOTA.,,Yannick,[TBD],,Tripathy2018
,Emotion stress detection using EEG signal and deep learning technologies,2018,"Liao, Chen & Tai",IEEE International Conference on Applied System Invention (ICASI),,Department of Information Management Chaoyang University of Technology,,,Classification of EEG signals,Monitoring,Affective,Emotion,New approach,Use CNN to classify Attention & Meditation from raw EEG,Listening to music,Exploring the use of DL for stress detection via EEG,,Neurosky Mindwave Mobile,No,None,Internal Recordings,Private,7,1,512*,N/M,,,N/M,,Frequency Bands,Frequency-domain,N/A,,N/M,CNN,CNN,N/M,N/M,No,"1s
(N/M, assuming 512 samples)",7,RELU,N/M,,,"1
0: Meditation
1: Attention",N/M,N/M,N/M,N/M,N/M,Grid Search,N/M,N/M,,N/M,"Train: 80%
Test: 20%",,"Accuracy
F1-Score","accuracy, f1-score",N/M,,N/M,Accuracy: 80.13%,N/M,None,,N/M,The F1-score shows that our system is better in predicting class 1 than predicting class 0.,N/M,No,N/A,No,"Terrible Paper.
They talk about measuring stress, but they use DL on raw EEG from Neurosky to classify based on attention/meditation coming from the Neurosky values...",,Yannick,[TBD],,Liao2018
,Hierarchical internal representation of spectral features in deep convolutional networks trained for EEG decoding,2018,"Hartmann, Schirrmeister & Ball",BCI Conference,Yes,University of Freiburg,6,,Improvement of processing tools,Model interpretability,Model visualization,,Improve interpretability of CNNs ,Study most activating inputs. Study effect on internal representation of variations in the input signal,Motor imagery,End-to-end learning,,N/M,No,Raw EEG,Internal Recordings,Private,14,128,5000,1000 trials/subject,,,"1) Downsample to 250 Hz
2) Common average re-reference ",No,"Raw EEG
(None)",Raw EEG,N/M,,Pytorch,CNN,CNN,See Schirrmeister et al. (2017),See Schirrmeister et al. (2017),Yes,522 x 128 (samples x channels),"CNN: 5
FC: 1",ELU,N/M,,,4,N/M,Standard optimization,Adam,N/M,N/M,N/M,N/M,Cross-entropy,,N/M,"Train: 80%
Test: 20%",,"Accuracy
F1-Score","accuracy, f1-score",N/M,,N/M,"Mean accuracy over 14 subjects: 88.6% 
(but this is not the focus of paper)",No,None,,"Yes
1) Signal perturbation (amplitude & phase)
2) Most-activating input windows",Analyzed effect of perturbations in phase and amplitude of input signals. Earlier layers focus on frequency-related information while latest layers focus on amplitude.,N/M,No,N/A,No,Cool paper. The focus is in the interpretability of what is learned by the convolutional layers.,,Isabela,Hubert,,Hartmann2018b
,Spatial-Temporal Recurrent Neural Network for Emotion Recognition,2018,"Zhang, Zheng, Cui, Zong & Li",IEEE Transactions on Cybernetics,Yes,"Southeast University, Nanjing, China
Nanjing University of Science and Technology, China",9,,Classification of EEG signals,Monitoring,Affective,Emotion,"New Approach: Stacking 2 RNN layers for spatial and temporal resolution, for EEG & Facial Expression for emotion classification","Stacking 2 RNN layers for spatial and temporal resolution, for EEG & Facial Expression for emotion classification","Emotion Classification for short emotional films/clips
(SEED dataset)",Leverage RNN for both spatial and temporal features,,ESI neuroscan,No,Emotions,SEED,Public,15,62,1000,N/M,,,None,No,"DE descriptors (?)  -  Freq Bands
(256-point FFT + Hanning Window (1s) for 5 F-Bands)",Frequency-domain,N/M,,N/M,"STRNN
(Spatial-Temporal RNN)",RNN,Spatial & Temporal features representation with stacked RNNs,"1) To learn spatial dependencies, a quad-directional spatial RNN (SRNN) layer is first employed
2) Then, a bi-directional temporal RNN (TRNN) layer is further stacked on SRNN to capture long-term temporal dependencies",Yes,"Not clear...
(to be reviewed)","SRNN: 1
TRNN: 1","ReLU
Sigmoid",N/M,,,"3
(Softmax)",N/M,N/M,"Back Propagation 
Through Time
(BPTT)",N/M,N/M,N/M,N/M,Cross-entropy,,N/M,"Train: 9 Sessions
Test: 6 Sessions",,Accuracy,accuracy,N/M,,N/M,Accuracy: 89.5%,None,None,,N/M,"A multidirection SRNN layer and a bi-direction TRNN layer are hierarchi- cally employed to learn spatial and temporal dependencies layer by layer. To adapt the multichannel EEG signals to the proposed STRNN framework, the spatial scanning order of electrodes are specified by spatial coordinates and tempo- ral variation information is involved by slicing a window on the extracted DE feature sequences.",N/M,No,N/A,No,Interesting...,,Yannick,[TBD],,[TBD]
,Individual Recognition in Schizophrenia using Deep Learning Methods with Random Forest and Voting Classifiers: Insights from Resting State EEG Streams,2018,"Chu, Qiu, Liu, Ling, Zhang & Wang",IEEE Transactions on Neural Systems and Rehabilitation Engineering,Yes,Big Data and AI Research Center of Shanghai Jiaotong University,7,,Classification of EEG signals,Clinical,Schizophrenia,Detection,New Approach,Using Random Forest and Voting Classifiers with a CNN for Individual Recognition in Schizophrenia,"Resting State, Eyes Open. (300s each)",,,BrainCap,No,Raw EEG,Internal Recordings,Private,"120
(40 CHR, 40 FES, 40 Healthy)",64,1000,N/M*,,,"1) Occular Correction (with Brain Vision Analyzer's algos)
2) Re-Referenced to Common Average
3) Pass-Band Filter (IIR): 0.01 - 50Hz",,"1) Raw EEG
2) Freq Bands",Raw EEG,,,"Brain Vision Analyzer
EEGLab","1) Raw EEG
2) Freq Bands
(not very clear about the shape)",CNN,"3 Conv Layers, ELU, 3 Dropout 0.5, 3 Max Pooling + Dropout 0.25, 3 FCs, 1 voting (RF, softmax or SVM)",,Yes,"1) Raw EEG
2) Freq Bands
(not very clear about the shape)","15
(including in,out, dropout)",,,,,"3 Classes
(replaced Softmax with Random Forrest)",N/M*,,"exponential linear unit (ELU) to accelerate the learning speed, max pooling to prevent substantial overfitting problem.",,,,No,N/M*,,"Cross-Validation 
(""Our results are the averages of 1000 independent runs"")",,,Accuracy,accuracy,,,N/M*,"FES: 96.7% 
CHR: 81.6%
HC: 99.2%
(3 classes)","ANNV, RNNV, CNNV,
ANNV+mSVM, RNN+mSVM, CNN+mSVM, 
ANN+RF, RNN+RF, CNN+RF",DL,,,"In conclusion, we have shown that CNNV-RF performs better than softmax and CNNV-mSVM on a well-known dataset (mnist) and resting state EEG streams used in this paper. Switching from softmax or mSVM to RF is incredibly simple and appears ro be helpful for classification problems.",,No,N/A,No,"N/M*
(not a huge fan of the EEG signal presented...)",,Yannick,[TBD],,Chu2017
,An EEG-based Image Annotation System,2018,"Parekh, Subramanian, Roy & Jawahar","National Conference on Computer Vision, Pattern Recognition, Image Processing, and Graphics",Yes,"IIIT Hyderabad, India
University of Glasgow, Singapore
National Brain Research Centre, Manesar, India",11,,Classification of EEG signals,BCI,Reactive,RSVP,Novel Approach: Image classification based on subject's P300,Using CNN (EEGNet) to classify images based on P300. RSVP with Oddball.,"RSVP. Images from Caltech101 and VOC 2012.
Oddball Paradigm for P300",Not mentioned why DL...,,Emotiv,No,"RSVP
P300",Internal Recordings,Private,5,14,128,N/M,,,"1) Baseline power removal using the 0.5 second pre-stimulus samples
2) Band-Pass filter: 0.1 - 45 Hz
3) ICA to remove artifacts 
(eye-blinks, and eye and muscle movements)",Yes,P300,Other,N/A,,Braindecode,"CNN
(EEGNet)",CNN,"They add a Outlier Removal ""Feature"".
They used a pre-trained VGG-16 on predicted target image.
(to reduce false-positive due to class imbalance)",see EEGNet & Braindecode,No,"1s Windows
(Raw EEG)",3,ELU,"N/M

(see Braindecode / EEGNet)",,,"2

Target / Non-Target",N/M,N/M,Adam,N/M,N/M,N/M,N/M,Categorical Cross-Entropy,,5-Fold CV,"Train: 2500 images
Test: 2500 images",,"F1-Score

(Due to a heavy class imbalance between T/non-T, we use F1-score)",f1-score,"NVIDIA GEFORCE
 GTX 1080 Ti",,N/M," [DS: CT101] Before outliers removal: F1: 0.71 Precision: 0.66 Recall: 0.81
 [DS: CT101] After outliers removal: F1: 0.68 Precision: 0.63 Recall: 0.72
 [DS: VOC2012] Before outliers removal: F1: 0.88 Precision: 0.99 Recall: 0.81
 [DS: VOC2012] After outliers removal: F1: 0.83 Precision: 0.97 Recall: 0.72",None,None,,N/M,"Our annotation system exclusively relies on the P300 ERP signature, which is elicited upon the viewer detecting a pre-specified object class in the displayed image. A further outlier removal procedure based on binary feature-based clustering significantly improves annotation performance.",N/M,No,N/A,No,"They talk about image classification, but all they do is P300 Target/Non-Target... I don't see how they will bring this to the next level or a multi-class...",,Yannick,[TBD],,Parekh2018
,EEGNet: A Compact Convolutional Neural Network for EEG-based Brain-Computer Interfaces,2018,"Lawhern, Solon, Waytowich, Gordon, Hung & Lance",Journal of Neural Engineering,Yes,"U.S. Army Lab,DCS Corporation, Columbia University, Georgetown University Medical Center",17,,Classification of EEG signals,BCI,Active & Reactive,MI & ERP,Novel Approach: DN that can be used for different BCI paradigms,Compare EEGNet with SOTA ML for different BCI Paradigms,"Visual P300 
ERN
Movement-related cortical potentials
Sensory Motor Rhythms",Allows robust feature extraction,,Biosemi,No,"1) P300 
2) ERN
3) Movement-related cortical potentials
4) SMR","Internal Recordings;
Kaggle: Inria BCI challenge;
Internal Recordings;
BCI Competition IV - IIa",Both,"P300: 15
ERN: 26
MRCP: 13
SMR: 9","P300: 64
ERN: 56
MRCP: 64 / 256
SMR: 22","1) 512
2) 600
3) 1024
4) 250","1) ~2000/subject
2) 340/subject
3) ~1100/subject
4) 288/subject",Offline,,"1) Rereferencing (linked mastoids or earlobes)
2) Bandpass filter (1 - 40 Hz, 0.1-40 Hz or 4-40 Hz) 
3) Downsampled to 128 Hz
(** Different approaches! e.g. Used PREP Pipeline for #3)",No,Raw EEG,Raw EEG,Exponential moving average,,Keras + Tensorflow,CNN,CNN,"Layer 1: 1D spatial filters
Layer 2: Depthwise 2D Conv
Layer 3: Separable 2D Conv","Depthwise: Inspired in part by the Filter-Bank Common Spatial Pattern (FBCSP) algorithm. 
Separable: explicitly decoupling the relationship within and across feature maps by first learning a kernel summarizing each feature map individually, then optimally merging the outputs afterwards",Yes,Channels x Time,3,ELU,"Dropout, weight decay","P300: 2
ERN: 2
MRCP: 2
SMR: 4","P300: Target/Non-target
ERN: Error/No error
MRCP: Left/Right hand
SMR: left hand/right hand/feet/tongue","(depends on the task)
(softmax)","1) 1,066 
2) 1,082 
3) 1,098 
4) 796   ","Within-Subject and Cross-Subject
If classes are umbalanced, we apply class-weight to the loss function whenever the data is imbalanced",Adam,N/M,N/M,N/M,N/M,"Categorical cross-entropy
+ Class weight if unbalanced",Intra and inter,"Intrasubject: 4-Fold CV
Intersubject: Leave some subjects out 
(per task)","varies, depending on the task and if cross-subject or within-subject",,"Accuracy
AUC","accuracy, AUC",NVidia Quadro M6000,,N/M,"See paper for full breakdown. TLDR;
Doesn't outperform or underperform anything by a lot.","DeepConvNet (Schirrmeister, 2017)
ShallowConvNet (Schirrmeister, 2017)
Riemannian EEG (Barachant, 2015)
FBCSP",DL & Trad.,Repeated-measures ANOVA,"1) Summarizing averaged outputs of hidden unit activations. 
2) Visualizing the convolutional kernel weights. 
3) Calculating single-trial feature relevance on the classification decision
Also used DeepLIFT (Shrikumar 2017)","In this work we proposed EEGNet, a compact convolutional neural network for EEG-based BCIs that can generalize across different BCI paradigms in the presence of limited data and can produce interpretable features.
To the best of our knowledge, this represents the first work that has validated the use of a single network architecture across multiple BCI datasets, each with their own feature characteristics and data set sizes. Finally, through the use of feature visualization and ablation analysis, we show that neurophysiologically interpretable features can be extracted from the EEGNet model",N/M,Yes,GitHub,No,"Great paper, but quite long and hard to ""review"" because of the 4 paradigms and all the tests/comparisons they do...
Nice appendix on the effect of different tricks (batch norm, dropout, dense layer)",,Yannick,Hubert,,Lawhern2018
,A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series,2018,"Chambon, Galtier, Arnal, Wainrib & Gramfort",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,Yes,"Telecom ParisTech, Inria, Université Paris-Saclay",12,,Classification of EEG signals,Clinical,Sleep,Staging,Improve State-of-the-Art,,Sleep,,,N/M*,No,Sleep events,MASS,Public,61,"20 EEG
2 EOG
3 EMG",128,N/M*,,,1) Low-pass @30Hz,,Raw EEG + EOG and raw EMG,Raw EEG,z-score,,Keras + Tensorflow,ConvNet,CNN,3 conv layers + dense (per modality),"Layer 1: spatial filter
Layers 2, 3: temporal filters",Yes,Nb channels * 30 s,4,"Linear, ReLU, Softmax",25% (last layer),,,5,<10^5,"1) Training on a single 30-s epoch
2) Freezing net, and train last layer on multi-epochs",Adam,,,,No,Categorical cross-entropy,,"Leave-p-subject-out
5 random permutations
67-16.4-16.4",,,"Balanced accuracy
F1-score, Precision, Sensitivity, Specificity, Confusion matrix","balanced accuracy, f1-score, precision, sensitivity, specificity, confusion matrix",N/M*,,~250 s,"Acc: ~80%
Bal. acc.: ~80%
Kappa: ~0.7
F1 score: ~0.71","Gradient boosting on time domain and freq. domain features
Univariatie ConvNets from Tsinalis et al. (2016) and Supratak et al. (2017)
",DL & Trad.,,Occlusion sensitivity,"1D convolution provided a speed-up vs. 2D convolutions
Smaller number of parameters than other studies
Temporal context helps for some classes, but not for others; recurrent architectures could help
Size of dataset matters",,No,N/A,Yes,Extensive justification of design choices; discussion is pretty detailed,,Hubert,[TBD],,Chambon2018
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,A convolutional neural network for SSVEP classifcation under ambulatory environment,2017,"Kwak, Muller & Lee",PLOS One,,"Korea University, TU Berlin",,,Classification of EEG signals,BCI,Reactive,SSVEP,Improve SOTA,Improve robustness of SSVEP BCIs for exoskeleton control in ambulatory conditions,SSVEP,-,,MOVE system (Brain Products GmbH),No,SSVEP,Internal Recordings,Private,7,8,1000,"Static condition: 350
Ambulatory condition: 1750",,,"1) Notch filter @60Hz
2) Band pass from 4-40 Hz",,FFT bins from 5-35 Hz,Frequency-domain,min-max,,N/M,CNN or MLP,CNN,"1) CNN (3 layers) 
2) CNN (4 layers)
3) MLP (3 layers)","First conv layer: spatial filter
Second conv layer: spectral filter",Yes,120 x 8,"1) 3
2) 4
3) 3",Sigmoid,N/M,,,5,N/M,Standard optimization,Stochastic gradient descent,Learning rate: 0.1,N/M,N/M,N/M,N/M,,"10 fold
Chronological split","Train: 90%
Test: 10%",,Accuracy,accuracy,N/M,,N/M,"Static condition: up to 99.28%
Ambulatory condition: up to 94.03%","CCA, MSI, CCA + kNN",Traditional pipeline,,Visual presentation of learned features,"CNN-1 (3 layers) was the most robust.
Since architecture is pretty simple, no regularization is used.",Artefacts in ambulatory settings,No,N/A,No,-,,Hubert,[TBD],,[TBD]
,"Mental Tasks Classification using EEG signal, Discrete Wavelet Transform and Neural Network",2017,"Padmanabh, Shastri & Biradar",Discovery,,Savitribai Phule Pune University,,,Classification of EEG signals,BCI,Active,Mental tasks,"[Classification of 5 different mental tasks, via Wavelet & ANNs (PNN & MLP)]",,"5 Mental Tasks (Baseline, Multiplication, Rotation, Counting, Letter composition)",,,Grass 7P511 Amplifier,,,"Keirn & Aunon, 1989",Public,5,6,250Hz,,,,1) Band-Pass filter: 0.1-100Hz,,,Frequency-domain,,,MATLAB & NNtool,"MLP
PNN",FC,,,No,200x1,"2
(20; 15)",,,,,,,,Learning Rate: 0.9,,,,No,MSE,,N/M*,,,accuracy,accuracy,,,,"MLP: 92%
NPP: 100%",None,None,,,,,No,N/A,No,,,Yannick,[TBD],,Padmanabh2017
,Cross-session classification of mental workload levels using EEG and an adaptive deep learning model,2017,Yin & Zhang,Biomedical Signal Processing and Control,,"University of Shanghai for Science and Technology
East China University of Science and Technology",,,Classification of EEG signals,Monitoring,Cognitive,Mental workload,New approach,,ACAMS (Automation-enhanced Cabin Air Management System),,,Nihon Kohden Biomed. Amplifier,,PSD,Internal Recordings,Private,7,11,500,N/M*,,,"1) Low-Pass filter: 40Hz
2) ICA for EOG artifacts",,"PSD
Avg. Power:  T (5–7.5 Hz), A (8–13.5 Hz), B1 (14–20 Hz), 
B2 (20.5–30 Hz), G (30.5–40 Hz)",Frequency-domain,,,MATLAB,SDAE,AE,Adaptive Stacked Denoising AutoEncoder,,Yes,"55x1
EEG PSD Features",6,,,,,2,N/M*,,,,,,"Gaussian noise
on Freq features",N/M*,,"66% training, 33% validation.",,,"accuracy, confusion matrix, sensitivity, specificity","accuracy, confusion matrix, sensitivity, specificity",,,N/M*,"[Complicated ... read me again ...]
SDAE > State of the art.","ANN, NB, kNN, SVMlin, SVMrbf, BSV, SDAE",DL & Trad.,,,It is evident that the proposed method is superior to those shallow and static classifiers when the comprehensive cortical information is adopted as the network inputs.,,No,N/A,No,They want to explore recording on multiple (different) days to capture the non-stationary neural physiological data distributions.,,Yannick,[TBD],,Yin2017a
,Generative Adversarial Networks Conditioned by Brain Signals,2017,"Palazzo, Spampinato, Kavasidis, Giordano & Shah",ICCV,No,"University of Catalania, University of Central Florida",9,,Generation of data,Generating images conditioned on EEG,,,New approach: generating images conditioned on EEG,Generating images using GANs conditioned by EEG representation,Visual presentation of images,Allows image generation,,actiCAP,No,Raw EEG,Internal Recordings,Private,6,128,1000,"11,466",,,"1) Hardware notch filter: 49-51 Hz
2) Band-pass filter: 14-70 Hz
3) Non-uniform quantization of the voltage values",N/M,Raw EEG,Raw EEG,N/M,,N/M*,"1) LSTM for EEG encoder 
2) DCGAN for image generation",Other,Conditional DCGAN (conditioning G and D),N/M,Yes,Nb channels * 0.5 s,"1) 2
2) 5 (generator), 6 (discriminator)","1) ReLU
2) ReLU",N/M,,,"1) 40
2) 64 x 64",N/M,"1) Train encoder to predict image category from raw EEG
2a) Train GAN on images without EEG features
2b) Train GAN condtioned on average (across subs) EEG representation learned by the encoder",Adam (lr=0.001),"1) N/M
2) Batch normalization","1) 16
2) N/M",N/M,"1) Nothing on EEG
2) Resizing + Flipping on Images","1) categorical cross-entropy. 
2) non-saturating ",,"1) N/M
2) ",1) 80%-10%-10%,,"1) Accuracy
2) Inception score, Inception accuracy","accuracy, inception score, inception accuracy",2 Titan X Pascal,,N/M,"Encoder: 83.9%
GAN: IS: 4-6.5, acc: 43%",No,None,,N/M,"Conditioning vector (i.e. EEG representations) are noisy, which makes harder to learn how an appropriate conditioning vector. 
 ","Suffers from classes with high internal variability
Dataset is small",No,N/A,No,Nice results for classes with low internal variability.,,Isabela,Hubert,,Palazzo2017
,The effects of pre-filtering and individualizing components for electroencephalography neural network classification,2017,Major & Conrad,IEEE SoutheastCon,No,University of North Carolina (Charlotte),6,,Classification of EEG signals,BCI,Active,Motor imagery,Improve State-of-the-Art: Exploring impact of ICA preprocessing,Analyze effectiveness of using ICA to enhance EEG that will be processed by a neural network,Motor imagery,"""Since every brain computer interface (BCI) has to be tailored for each person it is advantageous to use a neural network""",,N/M,No,Raw EEG,eegmmidb,Public,109,64,160,"12x 2min (tasks)
+ 2x 1min (baseline)
per subject",Offline,,1) Band pass filter: 8-30Hz,Yes,Raw EEG,Raw EEG,N/M,,Matlab,MLP,FC,N/M,N/M,Yes,16x ?,10,N/M,N/M,2,"Left Grasp
Right Grasp",2,N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,Inter,N/M,"Train: 2/3
Test: 1/3",,Accuracy,accuracy,N/M,,N/M,"With ICA: 68%
Without ICA: 56%",No,None,No,No,Applying ICA to raw data improves the neural network performance.,N/M,No,N/A,No,"Very limited paper. They used a neural network but didn't specify number of layers, or any other aspect. The focus of the paper is on whether using ICA helps or not.",,Isabela,Yannick,,Major2017
,Convolutional neural network-based transfer learning and knowledge distillation using multi-subject data in motor imagery BCI,2017,Sakhavi & Guan,IEEE Conference on Neural Engineering,,NUS & NTU,4,,Classification of EEG signals,BCI,Active,Motor imagery,Transfer learning (from one subject to another),Reduce calibration time in a BCI using transfer learning,Motor imagery,Reduce BCI's calibration time,,N/M,No,Raw EEG,BCI Competition IV - IIa,Public,9,22 + 3 EOG,250,5184,,,"1) Bandpass between 0.5-100 Hz
2) Notch filter @50 Hz",,"FBCSP in 9 frequency bands, then extracting envelope",Frequency-domain,weird z-scoring,,Torch7,CNN + MLP,CNN,"CNN: 5 layers 
MLP: 1 layer",-,Yes,"CNN: 32x40
MLP: 32","CNN: 4 conv, 1 FC
MLP: 1 FC",ReLU,N/M,,,"CNN: 128
MLP: 128",N/M,"1) Pre-train CNN+MLP on N-1 subjects
2) Fine-tune pre-trained network on 1 subject",Adam,N/M,N/M,N/M,N/M,KL divergence,,Leave-N-samples-out," N=5, 10, 20",,Test set accuracy,accuracy,N/M,,N/M,Average acc: 69.71%,SVM,Traditional pipeline,,-,"Best results (average across subjects) show significant improvement with respect to SVM. However, there is high variability  ",Choosing hyperparameter lambda,No,N/A,No,"Proposed approach applied knowledge distillation, but discussion is very poor",,Hubert,Isabela,,Sakhavi2017
,Single-trial EEG classification of motor imagery using deep convolutional neural networks,2017,"Tang, Li & Sun",Optik - International Journal for Light and Electron Optics,,Zhejiang University of Technology,,,Classification of EEG signals,BCI,Active,Motor imagery,New Approach: CNN for MI on Single Trial,,Motor Imagery,,,BioSemi,,SMR - ERD/ERS,Internal Recordings,Private,2,28,1000,"Left-Hand: 230
Right-Hand: 230",,,"1) [Hardware] Notch Filter: 50Hz
2) [Hardware] Band-Pass Filter: 0.5-100Hz
3) [Software] Band-Pass Filter: 8-30Hz",,,Frequency-domain,,,N/M*,CNN,CNN,Activation Function: Hyperbolic Tangent,,Yes,"28x60
Channels x Time Points ","2 Conv
1 FC",,,,,2,N/M*,,N/M*,,,,No,N/M*,,10-Fold CV,80% Training 20% Testing,,"confusion matrix, accuracy, ROC, precision, recall, f-score","confusion matrix, accuracy, ROC, precision, recall, f-score",,,N/M*,86.41%,"Power+SVM
CSP+SVM
AR+SVM",Traditional pipeline,,,The results demonstrate that CNN can further improve classification performance compared with other three conventional methods.,,No,N/A,No,,,Yannick,[TBD],,Tang2017
,Pattern Recognition of Momentary Mental Workload Based on Multi-Channel Electrophysiological Data and Ensemble Convolutional Neural Networks,2017,"Zhang, Li & Wang",Frontiers in Neuroscience,,East China University of Science and Technology,16,,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art,MWL classification with CNN & ECNN,ACAMS (Automation-enhanced Cabin Air Management System),N/M,,Nihon Kohden Biomed. Amplifier,No,PSD,Internal Recordings,Private,6,"10? 
11?",500,"50 min / case (2) / participant
20 min baseline (unloaded)
+ 30 min tasks (MWL)",Offline,,1) Low-Pass filter: 40Hz,No,"PSD (STFT)
Avg. Power:  D (1-4Hz), T (5–8 Hz), A (9–13 Hz), B1 (14–16 Hz), B2 (17–30 Hz), G (31–40 Hz)",Frequency-domain,N/M,,"Python
Matlab","CNN
ECNN",CNN,Many architectures tested,N/M,Yes,"102x10
(not clear what x what)","[2, 10]
(tested many)",ReLU,N/M,4 and 7,Low/Normal/High/ - Unloaded - Very Low/Low/Medium/High/Very High/Overloaded,4 and 7,N/M,N/M,"Nesterov Momentum
Adagrad
Adadelta
Adam","(see paper, they describe each optimizer params)",N/M,N/M,N/M,Cross-Entropy,Inter,"5-Fold CV
(when Stacking)",50% - 50%,,"Accuracy
Precision
F-Measure
G-Measure","accuracy, precision, f-measure, g-measure","Single Intel core i5 CPU, 4-GB memory, Windows",,N/M,93%,"LDA
NB
SDA",Traditional pipeline,N/M,N/M,"""It was found that the deeper CNN model with the small convolutional kernels leads to improved classification performance.""
[YR] --> Like in other fields...",N/M,No,N/A,No,"They compared 5 CNNs and 4 Optimizers...
Then build an Ensemble from these 20.
(Nesterov Momentum gives better results!)",,Yannick,[TBD],,Zhang2017
,Deep RNN learning for EEG based functional brain state inference,2017,"Patnaik, Moharkar & Chaudhari","International Conference on Advances in Computing, Communication and Control (ICAC3)",,"Xavier Institute of Engineering, Mahim, Mumbai
M G M Inst. of Health Sciences, Navi Mumbai
",,,Classification of EEG signals,BCI,Active,Mental tasks,New Approach: Brain State Inference with RNN using Alpha Phase Coherence,,"5 Tasks: Baseline, Multiplications, Rotations, Letter Composition, Visual Counting (not using baseline)",,,N/M*,No,"ERD/ERS
(looking at Alpha Cross Coherence - Occipital/Center)","Keirn and Aunon, 1989",Public,7,6,250,N/M*,,,"1) Band-Pass Filter: 0.1-100Hz (Hardware)
2) ICA for EOG Artifacts
3) DWT to get Alpha Sub-Bands
4) Hilbert Transform (no-overlap) for Phase Coherence",,"Alpha Sub-Bands 
Phase Coherence",Frequency-domain,,,N/M*,"Elman's RNN
with Bottlenect",RNN,A 5-layer network with 53-400 - 50-200-20-T,,Yes,[Shape Not Mentioned],5,,,,,4 Classes,N/M*,,N/M*,,,,No,N/M*,,N/M*,,,Accuracy,accuracy,,,N/M*,"90% for two tasks
82% for three tasks
77% for all the four tasks",No,None,,,"""In this research, a RNN model is trained to identify the phase coherence patterns of EEG alpha-bands. Difference between EEG signals from central and occipital (C1-O1 & C2- O2) locations is considered to compute phase coherence patterns for various activities.""",,No,N/A,No,N/M*,,Yannick,[TBD],,Patnaik2017
,Deep Convolutional Neural Networks for Interpretable Analysis of EEG Sleep Stage Scoring,2017,"Vilamala, Madsen & Hansen",IEEE International Workshop on Machine Learning for Signal Processing,Yes,"Technical University of Denmark
Danish Research Centre for Magnetic Resonance",,,Classification of EEG signals,Clinical,Sleep,Staging,New Approach: CNN for Sleep Stages,,Sleep,,,N/M*,,PSD,Sleep EDF,Public,20,1,100,N/M*,,,Multitaper Spectral Estimation,,"Spectrogram log values
(from Multitaper Spectral Estim.)",Frequency-domain,,,N/M*,CNN,CNN,"VGGNET
Activation Function: ReLU & Softmax
Xavier’s initialisation.",,No,"224x224
(RGB Image)",16,,Dropout,,,"5
(Sleep Stage)",N/M*,,Adam,"Learning Rate: 10^-5
Mini-batch: 250
Decay Rate 1st & 2nd moments 0.9 & 0.999",,,No,Categorical cross-entropy,,"Leave-one-subject-out
4 Subjects for Validation
15 Subjects for Training",,,"Precision 
Sensitivity 
F1-score 
Accuracy","precision, sensitivity, f1-score, accuracy",,,N/M*,"[VGG-FE] Precision: 91, Sensitivity: 73, F1-S: 81, Accuracy: 83
[VGG-FT] Precision: 93, Sensitivity: 78, F1-S: 84, Accuracy: 86","SSAE, CNN",DL,,,Further improvement of the method includes better hyperparameter optimisation when generating the spectral images,,No,N/A,Yes,"Pretty much on par with the 2 papers from Tsinalis et al., 2016",,Yannick,[TBD],,Vilamala2017
,Deep long short-term memory structures model temporal dependencies improving cognitive workload estimation,2017,"Hefron, Borghetti, Christensen & Kabban",Pattern Recognition Letters,,"Air Force Institute
Air Force Research Laboratory",,,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art: MWL classification with RNNs (LSTM).,,Multi-Attribute Task Battery (MATB) environment,,,N/M*,No,"PSD
(Raw EEG)",Internal Recordings,Private,"6
(out of 8)
(over 5 days)",19,256Hz,approximately 9000 observations per individual for the five day period,,,The power spectral density was determined for 30 points spread out over a logspace from 3 Hz to 55 Hz by extracting power from complex Morlet wavelets [9] . Each wavelet was 2 s in length,,"Mean, Variance, Skewness, Kurtosis of PSD (delta (1–4), theta (4–8), alpha (8–14), beta (15–30), and gamma (30–55)) + all possible combinations of M, V, S, K.",Frequency-domain,,,"Keras, Theano",LSTM,RNN,N/M*,,Yes,"600 x 30 x F
(batch size, temporal depth in seconds, and number of features)
(F varies between 90 and 380 features)","2 LSTM Layers
(50 and 10 units",,,,,"1
(low or high WL)",N/M*,,"Mini-batch gradient descent (600 obs. per batch)
Adam, Dropout 20%",,,,No,Binary Cross-Entropy,,4-Fold Cross-Validation,,,Accuracy,accuracy,,,N/M*,"93% (using all measures: M/V/S/K)
 ","linear SVM (SVM-L), Radial Basis Function (RBF) SVM (SVM-R), feedforward ANN (ANN), deeply stacked simple RNN (RNN-D), single LSTM (LSTM-S), and deeply stacked LSTM (LSTM-D)",DL & Trad.,,,"There is an abundance of future work to be pursued in this area. Due to time constraints and computational complexity, only a select number of deep architectures were examined during this re- search. A thorough evaluation of different deep RNN architectures to include variations in the depth of hidden layer recurrent con- nections, stacking of different sized LSTM layers, and interleaving fully-connected feedforward layers between sequence-to-sequence recurrent layers may yield additional improvement.",,No,N/A,No,N/M*,,Yannick,[TBD],,Hefron2017
,The signature of robot action success in EEG signals of a human observer: Decoding and visualization using deep convolutional neural networks,2017,"Behncke, Schirrmeister, Burgard & Ball",Arxiv,Yes,"Albert-Ludwigs-University Freiburg
University Medical Center Freiburg",6,,Classification of EEG signals,BCI,Reactive,ERP,Novel Approach: DL for Robot Error Detection,Comparing CNN to rLDA and FB-CSP (both state of the art) for error detection in human-robot interaction,"Participant watching short videos of robots ""performing naturalistic actions either in a correct or an erroneous manner""",Deep Learning has been tried for other EEG decoding tasks,,N/M,No,Error Potential,Internal Recordings,Private,17,128,N/M,"KPO: 720+ trials
RGO: 800+ trials
per participants",Offline,,"1) Re-reference to common average (CAR)
2) Downsampled to 250 Hz",No,Raw EEG,Raw EEG,Electrode-wise exponential moving standardization,,Braindecode,CNN,CNN,Deep ConvNet from braindecode paper,"Layer 1: temporal filtering, Layer 2: spatial filtering, with no non-linearity in-between (Braindecode)",No,Time x channels,5,ELU,"Dropout
Early stopping",2,"Error
No error",2,N/M,Standard optimization,Adam,N/M,N/M,N/M,N/M,Categorical cross-entropy,Intra,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"KPO Error (2.5-5s): (78.2 ± 8.4) %
KPO Error (3.3-7.5s): (71.9 ± 7.6) %
RGO Error (4.8-6.3s): (59.6 ± 6.4) %
RGO Error (4-7s): (64.6 ± 6.1) %","rLDA
FB-CSP

(CNN is better)",Traditional pipeline,"Permutation test on individual decoding results
Wilcoxon signed-rank tests",Correlation of changes in ConvNet predictions with perturbation changes in 1) input spectral amplitudes and 2) time domain signals to obtain information about what the deep ConvNets learned from the data,"""Among other recent advances in the field of deep learning research, automatic hyperparameter optimization and architecture search, including recurrent and residual network architectures, data augmentation, using 3-D convolutions, or increasing the amount of training data all have the potential to further increase ConvNet performance.""",N/M,No,N/A,No,"Most of the architecture/training information is not given in the paper, but the reader is referred to the braindecode paper. The applicable information was therefore copied over from the braindecode paper instead of writing N/M (given our end goal is to find out what the trends are).
Also, I'm confused by the visualization. I don't see what's going on at 3.1 and 3.7 s (as they highlight in the text).",,Yannick,Hubert,,Behncke2017
,Deep learning with convolutional neural networks for EEG decoding and visualization,2017,"Schirrmeister, Springenberg, Fiederer, Glasstetter, Eggensperger, Tangermann, Hutter, Burgard, Ball",Human Brain Mapping,Yes,University of Freiburg,30,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Find out best CNN architecture for EEG decoding,Motor imagery/execution,Can learn from raw data,,"1)
2)
3)
4)",No,None,"BCI Competition IV - IIa;
Internal Recordings;
BCI Competition IV - IIb;
Mixed Imagery Dataset",Both,"1) 9
2) 14
3) 9
4) 4","1) 22
2) 44 (out of 128)
3) 3
4) 64 (out of 128)","1) 250
2) 250
3) 250
4) 250","1) 9 * 2 * 288 = 5184
2) 14000
3) 9 * 5 (400 + 320) = 32400
4) 675 + 2172 + 698 + 464 = 4009",,,"BCI Competition Datasets:
1) Lowpass @38 Hz","Yes
(removed trials with at least one channel > 800 uV)",Raw EEG,Raw EEG,Electrode-wise exponential moving standardization,,Lasagne,CNN,CNN,"1) Deep ConvNet
2) Shallow ConvNet
3) Hybrid of 1) and 2) with 2 dense layers
4) ResNet","1) Layer 1: temporal filtering, Layer 2: spatial filtering, with no non-linearity in-between
2) Embedding FBCSP in a ConvNet
3) Combining 1 and 2
4) 2 layers like in 1)",Yes,,"1) 2
2) 5
3) max(2, 5) + 2 = 7
4) 31","1) ELU
2) Square, log
3) ELU, square & log
4) ELU","Dropout (0.5)
Early stopping",,,2 or 4,N/M,Standard optimization,Adam,Batch norm,N/M,N/M,"Crops 
(sliding windows within 1 trial)","Categorical cross-entropy
For cropped training: ""Tied loss function""",,None,"1) 288 - 288
2) 880 - 160
3) 400 - 320
4) Variable per subject",,"Accuracy
Confusion matrices","accuracy, confusion matrix","Geforce GTX Titan Black
Intel Xeon @2.60 GHz with 32 cores
128 GB RAM",,N/M,,Filter bank common spatial patterns,Traditional pipeline,,"Input-feature unit-output correlation maps (visualization of correlation between spectral bands and receptive fields)
Input-perturbation network-prediction correlation map (perturbing the input and visualizing change in output of net)","ConvNets reached FBCSP accuracies
ConvNet design choices substantially affects decoding accuracies
Recent DL advances substantially increases accuracies
ResNet performed worse than deep ConvNet
Cropped training strategy improves performance on higher frequencies
And much more!","ConvNets can be too flexible, especially if there is a specific type of brain activity that a user should use",Yes,GitHub,Yes,Best DL + EEG ever.,,Hubert,[TBD],,Schirrmeister2017
,Optimal Feature Selection and Deep Learning Ensembles Method for Emotion Recognition From Human Brain EEG Sensors,2017,"Mehmood, Du & Lee",IEEE Access,,"Chonbuk National University, Nanjing University of Posts and Telecommunications",10,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Ensemble Method with DL and others to improve SOTA in EEG emotion classification,"Watching ""Emotional"" Images from IAPS database.",Using ensemble approach.,,Emotiv,No,Emotions,Internal Recordings,Private,21,14,128,368s x2 sessions / subject,,,"1) Artifact Removal (cites: Gómez-Herrero et al., 2006)
2) Filtering (cites: Widmann et al., 2012)
3) Epoching",Yes,"Hjorth parameters for different frequency ranges
+ ANOVA feature selection",Frequency-domain,N/M,,"EEGLAB
Matlab
WEKA","""Deep Learning""

(they don't even specify)",NS,"Ensemble: LDA, KNN, SVM, Naive/Bayes-Net, DT, RF, Deep Learning

They don't describe the DL model at all",N/M,Yes,"3 Hjorth params for each of the 5 frequencies
(?)",N/M,N/M,N/M,,,N/M,N/M,Pre-Training and Fine Tuning,N/M,N/M,N/M,N/M,No,N/M,,10-Fold CV,"Train: 9/10
Valid: 1/10",,Accuracy,accuracy,"SOTA Server
4 TITAN-X (Pascal)",,N/M,Accuracy: 76.62%,"Jirayucharoensak et al., 2014 (SAE): 46/50%
Chanel et al., 2006 (FDA, Naive Bayes): 72% 
Khalili et al., 2008 (LDA, KNN): 61%
Horlings et al., 2008 (SVM): 37/32% 
Jenke et al., 2014 (...): 45%
Yin et al., 2017 (SAE, Ensemble): 84/83%
Atkinson et al., 2016 (...): 73/73%",DL & Trad.,,N/M,"Comparatively, the proposed method performs better than existing emotion recognition methods. The proposed feature selection method OF obtained the best emotion recognition rates of 76.6% for Voting ensembles method. Based on our results, we conclude that optimal feature selection is a good choice for enhancing the performance of EEG-based emotion recognition.","To further improve emotion recognition performance, we need to explore additional feature combinations with more emotional classes in the arousal–valence domain.",No,N/A,No,"Not really a DL paper... They don't even describe their ""Deep Learning"" model. They just put it there as one of the methods of the ensemble...",,Yannick,[TBD],,Mehmood2017
,Converting Your Thoughts to Texts: Enabling Brain Typing via Deep Feature Learning of EEG Signals,2017,"Zhang, Yao, Sheng, Kanhere, Gu, Zhang",Arxiv,Yes,"University of New South Wales
Macquarie University
RMIT University",10,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Joint CNN & LSTM + AE for Motor Imagery (5 classes),"Motor Imagery (5 classes)
(see eegmmidb dataset)","EEG processing is time-consuming and depend on human expertise.
SOTA models achieve 70-80% which is not enough.
",,"1) N/M
2) Emotiv",No,Motor Imagery,"eegmmidb;
Internal Recordings",Public,"1) 10
2) 7","1) 64
2) 14","1) 160
2) 128","1) 28,000 samples / subject
2) 34,560 samples / subject",Offline and Online,,N/M,No,"Raw EEG
(None)",Raw EEG,N/M,,N/M,"CNN + LSTM + linear AE
+ XGB (classification)",Other,"CNN & LSTM are parallel, then combined for the AE then XGB classifier",CNN for Spatial and RNN for Sequential info,Yes,"1 x 64
(sample x channels)","LSTM: 6 layers
CNN: 2 Conv + 2 FC","ReLU, Sigmoid, tanh",L2,5,"eegmmidb: eye closed, left hand, right hand, both hands, both feet
emotiv: up arrow, down arrow, left arrow, right arrow, eye closed",5,N/M,Standard optimization,"LSTM & CNN: Adam
AE: RMSProp",Full table on optim params,7000,"N/M
(they have tried many config, manually I suppose)",N/M,"LSTM + CNN: Cross-Entropy
AE: MSE",Intra,N/M,"Train: 75%
Test: 25%",,"accuracy, precision, recall, F1 score, ROC curve, and AUC","accuracy, precision, recall, f1-score, ROC, AUC",N/M,,2000 s,"DS #1 - Accuracy: 0.955
DS #2 - Accuracy: 0.9427","Baselines: KNN, SVM, RF, LDA, AdaBoost, RNN, CNN
Externals: Almoari, Sun, Mohammad, Major, Shenoy, Tonic, Rashid, Ward, Sita, Pinheiro.
(all different papers, see Table IV)",DL & Trad.,N/M,N/M,"The classification accuracy of the public dataset (eegmmidb) is consistently higher than the local real-world dataset (emotiv). Our future work will focus on improving the accuracy in the person-independent scenario, wherein some subjects participate in the training and the rest of subjects involve in the testing.",N/M,Yes,GitHub,No,"Data Available here: https://drive.google.com/drive/folders/0B9MuJb6Xx2PIM0otakxuVHpkWkk
Code also available - Should try to reproduce!",,Yannick,Hubert,,Zhang2017g
,Emotion Recognition based on EEG using LSTM Recurrent Neural Network,2017,"Alhagry, Fahmy & El-Khoribi",International Journal of Advanced Computer Science and Applications (IJACSA),,Cairo University,,,Classification of EEG signals,Monitoring,Affective,Emotion,"Improve SOTA: Using LSTM on raw EEG to classify emotions (arousal, valence, liking)",,"Emotion Classification on DEAP 
(Like or Dislike video)",,,[see DEAP Dataset],No,Raw EEG,DEAP,Public,32,32,512,N/M*,,,"1) Downsampled to 128Hz  (in the dataset)
2) Re-reference to Common Average  (in the dataset)
3) Eye Artifacts Removed  (in the dataset)
4) High-Pass Filter [freq not mentioned]",,"Raw EEG
(None)",Raw EEG,,,"Keras, TensorFlow",LSTM,RNN,AF: ReLU and Sigmoid,,Yes,"5s segments x 32 channels
(672 x 32)","2 LSTM Layers (64,32) + 1 Dropout (0.2) + 1 FC",,,,,3 Classes,5534113,,"RMSProp, LR:0.001",,,,No,N/M*,,"4-Fold Cross-Validation
Train: 75%
Test: 25%",,,Average Accuracy,accuracy,,,N/M*," Arousal: 85.65%
Valence: 85.45%
Liking: 87.99%","Traditional pipelines
Koelstra et al., [2]: 62 | 56 | 55 %
Atkinson ... [3]: 73 | 73 | - %
Yoon and Chung [6]: 70 | 70 | - %  
Naser and Saha [7]: 66 | 64 | 70 %  
proposed method: 86 | 85 | 88 %",Traditional pipeline,,,"Results show that the proposed method is a very promising choice for emotion recognition, because of its powerful ability to learn features from raw data directly. 
It achieves high average accuracy over participants compared to the traditional feature extraction techniques.",,No,N/A,No,N/M*,,Yannick,[TBD],,Alhagry2017
,Intent Recognition in Smart Living Through Deep Recurrent Neural Networks,2017,"Zhang, Yao, Huang, Sheng & Wang",International Conference on Neural Information Processing (ICONIP),Yes,"University of New South Wales, AU
Macquarie University, AU
Singapore Management University, Singapore",11,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA: Using LSTM on multiclass BCI,"Using LSTM on multiclass BCI open dataset
Use hyperparameter fine-tuning method","Motor Imagery
(see eegmmidb dataset)",Explore multiclass as opposed to binary classification like many others. BCI at home will be multiclasses.,,"N/M
(check eegmmidb dataset)",No,Intent / Motor Imagery,eegmmidb,Public,10,64,160,"28,000 samples / subject",,,None,,"Raw EEG
(None)",Raw EEG,N/A,,N/M,LSTM,RNN,N/A,N/M,Yes,"64 channels x ?
(not clear...)",5,Sigmoid,L2,,,"5 Classes
(the format isn't clear)",N/M,N/M,Adam,"LR: 0.004
Lambda: 0.005",N/M,Orthogonal Array (OA) experiment method,N/M,Cross-Entropy,,N/M,"Train: 75%
Test: 25%",,"Accuracy
Recall
F1 Score
AUC","accuracy, recall, f1-score, AUC",N/M,,N/M,"Accuracy: 0.9545 
Recall:      0.9228 
F1:            0.9382 
AUC:        0.9985","Almoari [2] 0.7497, Sun [13] 0.65, Major [4] 0.68, Shenoy [12] 0.8206, Tolic [16] 0.6821, Ward [19] 0.8, Pinheiro [10] 0.8505 
KNN (k=3) 0.8369, SVM 0.5082, RF 0.7739, LDA 0.5127, AdaBoost 0.3431, CNN 0.8409",DL & Trad.,,N/M,"To achieve optimal recognition accuracy, we employ OA to op- timize the hyper-parameters. In this paper, we select five most common hyper-parameters including λ (the coefficient of L2 norm), lr (learning rate), Ki(the hid- den layer nodes size), I (the number of layers), and nb (the number of batches).",N/A,Yes,Website,No,"Great results (too good to be true?)
Need to reproduce. The code is suposed to be available!",,Yannick,[TBD],,Zhang2017d
,Deep Recurrent Neural Networks for seizure detection and early seizure detection systems,2017,Talathi,Arxiv,Yes,Lawrence Livermore National Lab,,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA: Using RNN for early seizure dectection,Using GRU-RNN for early seizure detection,"Resting State, Eyes Open, Eyes Closed, Seizures.",Using available data to test RNNs for seizure detection.,,N/M,No,Seizures,Bonn University,Public,15,1,173.6,N/M*,,,None (see dataset preprocessing steps),,"Raw EEG
(None)",Raw EEG,N/A,,Keras,"GRU
(RNN)",RNN,GRU -> FC -> GRU,"GRU for RNN long-term dependencies, but control the vanishing gradient",Yes,"51 x 80 x 1
(51 EEG sub-segment x 80 values x 1 channel)","GRU: 2
FC: 1",N/M,N/M,,,"3
(Logistic Regression with Softmax)","In the order of 100,000","(1) We train the RNN in stateful-mode*.
(2) Rescaling the learning rate by factor 0.1 at each 100th epoch",Adam,LR: 0.01,N/M,N/M,N/M,N/M,,N/M,"Train: 50%
Test: 50%",,Accuracy,accuracy,N/M,,N/M,"98% Accuracy within the first 5 sec
(3 classes: Healthy vs Ictal vs InterIctal)","They mentioned (A. T. Tzallas et al., 2007) getting 98% accuracy (ANN).",Traditional pipeline,,-,This findings offers a strong support to the utility of GRU-RNN model for use in early-seizure detection system that can be extremely useful for developing closed loop seizure control systems where timely intervention can be leveraged to abate seizure progression,-,No,N/A,No,-,,Yannick,[TBD],,Talathi2017
,DeepSleepNet: a Model for Automatic Sleep Stage Scoring based on Raw Single-Channel EEG,2017,"Supratak, Dong, Wu & Guo",Arxiv,Yes,Imperial College London,11,,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA: Using CNN+LSTM for Sleep Stage Scoring from Raw EEG,Combining CNN + LSTM for Raw EEG and testing it on 2 different existing datasets,Sleep,Using RNN (LSTM) to capture time depencies in sleep stages.,,"N/M
(see dataset paper)",No,Sleep Stages,"MASS;
Sleep EDF",Public,"1) 62
2) 20","1) 20
2) 2","1) 256
2) 100","1) 58600
2) 41950",,,"1) Notch filter: 60Hz
2) Band-pass filter: 0.30 - 100Hz",No,"Raw EEG
(None)",Raw EEG,N/M,,"TensorLayer
eTRIKS",CNN + bi-LSTM,CNN+RNN,"1D Conv, Batch Norm, Max Pooling","First part is representation learning, which can be trained to learn filters to extract time-invariant features from each of raw single-channel EEG epochs. The second part is sequence residual learning, which can be trained to encode the temporal information.",Yes,"30s EEG Epoch
(2 diff sampling freq)","2 CNN
2 bi-LSTM",ReLU,"L2
Dropout (50%)",,,"5 Sleep Stages
(Softmax)",N/M,"The two-step training algorithm (their technique) to prevent from suffering from class imbalance.
The algorithm first pre-trains the representation learning part of the model and then fine-tunes the whole model using two different learning rates.",Adam,"LR: 0.0001
b1: 0.9
b2: 0.999",100,N/M,"Oversampling to balance classes
(duplicating minority sleep stages)",Cross-Entropy,,"k-Fold CV
1) 31-Fold 
2) 20-Fold",N/M,,"Precision (PR)
Recall (RE)
F1-score (F1)
macro-averaging F1-score (MF1)
Accuracy (ACC)
Cohen’s Kappa coefficient (κ)","precision, recall, f1-score, macro-averaging f1-score, accuracy, Cohen's kappa","NVIDIA
GeForce GTX980",,The training time for each validation fold was approximately 3 hours on each node,"Sleep EDF - Acc: 82.0 
Sleep EDF - MF1: 76.9
Sleep EDF - k: 0.76 

MASS - Acc: 86.2
MASS - MF1: 81.7
MASS - k: 0.80","Traditional pipelines & DL
Sleep EDF: Y.-L. Hsu et al., 2013
Sleep EDF: R. Sharma et al., 2017
Sleep EDF: A. R. Hassan et al., 2017
Sleep EDF: O. Tsinalis et al., 2016a
Sleep EDF: O. Tsinalis et al., 2016b

MASS: H. Dong et al., 2016",DL & Trad.,,"Yes (read paper for more info)
We found several memory cells of the forward LSTMs that were interpretable. For instance, several cells were keeping track of the wakefulness or the sleep onset, which reset their values to positive numbers (i.e., active) when a subject was in the stage W or N1 respectively.","It achieved similar overall accuracy and macro F1-score compared to the state-of-the-art hand-engineering methods on both the MASS and Sleep-EDF datasets, which have different properties such as sampling rate and scoring standards (AASM and R&K).",N/M,Yes,GitHub,No,"Interesting architecture with code on github! <3
Results are average. On par with others.",,Yannick,[TBD],,Supratak2017
,Mixed Neural Network Approach for Temporal Sleep Stage Classification,2017,"Dong, Supratak, Pan, Wu, Matthews & Guo",IEEE Transaction on Neural Systems and Rehabilitation Engineering,Yes,Imperial College London,11,,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA: Using Mixed NN on 1 channel EEG for Sleep Stage Scoring,Combining MLP + LSTM on 1-Channel Raw EEG from an existing (open) dataset,Sleep,"Using RNN (LSTM) to capture time depencies in sleep stages and using a single, frontal (skin) electrode.",,"N/M
(see dataset paper)",No,Sleep Stages,MASS,Public,62,"1
(out of 20)",256,494 hours,,,"N/M
Seems to directly do SFTF for freq features",No,PSD Features,Frequency-domain,N/M,,Theano,"Mixed NN (MNN)
MLP + LSTM",RNN,N/M,"Our MNN is composed of a rectifier neural network which suitable for detecting naturally sparse patterns [18], and a long short-term memory (LSTM) for detection of temporally sequential patterns [19]",Yes,30s EEG Epoch PSD,"MLP: [2,5]
LSTM: 1 (200-1000)",ReLU,Dropout,,,"5 Sleep Stages
(Softmax)",N/M,N/M,SGD,"LR: 0.01
Momentum: 0.9
no weight decay",500,Manual fine tune,Oversampling to balance classes,Cross-Entropy,,31-Fold CV,N/M,,"Macro F1-score (MF1)
Accuracy (ACC)
Recall (RE)
Precision (PR)","macro f1-score, accuracy, recall, precision",NVIDIA 630,,2 days,"MF1: 80.50
ACC: 85.92","SVM: 75.01 | 79.70 (best with sequence 2) 
RF: 72.44 | 81.67 (best with sequence 3) 
MLP: 77.23 | 81.43 (best with sequence 4) 
",Traditional pipeline,,N/M,"(1) In terms of convenience, wearing the F4 channel near the hair line is imperfect. Other frontal EEG channels such as Fp2 and Fpz are easier to wear, but these channels have lesser information about stage W, N1, N2 and N3. (2) In our experiment, we tried to add fully connected layers between LSTM and softmax, and vary their hidden sizes, but no improvement was found.","Less inofrmation in low frontal (skin) channels
(They've identified 3 challenges)
Challenge 1. Heterogeneity
Challenge 2. Temporal Pattern Recognition
Challenge 3. Comfort",No,N/A,No,Should be reproducible. Data open and architecture rather simple / vanilla,,Yannick,[TBD],,dong2018mixed
,SLEEPNET: Automated Sleep Staging System via Deep Learning,2017,"Biswal, Kulas, Sun, Goparaju, Westover, Bianchi & Sun",Arxiv,Yes,"Georgia Institute of Technology
Nanyang Technological University
Massachusetts General Hospital",17,,Classification of EEG signals,Clinical,Sleep,Staging,"Improve SOTA: Using CNN, RNN, CRNN for Sleep Stage Scoring","Trying CNN, LSTM, RCNN on 10,000 subjects on Raw EEG, Expert Feature Set and Freq Bands for Sleep Stage Scoring",Sleep,"Leveraging huge dataset (3.2TB) of 10,000 subjects to apply deep learning",,N/M,No,Sleep Stages,Internal Recordings,Private,10000,6,200,"80000 hours
(3.2TB of data!)",,,None,No,"3 Sets of Features:

1) Raw EEG
2) Experts Defined Features
3) Spectrogram",Combination,N/M,,"Tensorflow
CUDA 8.0","1) CNN
2) RNN
3) RCNN",CNN+RNN,"1) CNN: 1D Conv for Raw EEG / 2D Conv for Freq Features
2) RNN: Look back steps in RNN : [3,5,10,20,30]","By combining a RNN with CNN, we can have a hybrid model, namely, Recurrent-Convolutional Neural Networks (RCNN), which is able to extract features present in a spectrogram and preserve the long-term temporal relationship present in the EEG data",No,"30s EEG Epoch
(depending on feature set)

",RNN: 5 LSTM (1000),ReLU,Dropout,,,5 Classes,N/M,N/M,N/M,LR: [0.01 - 0.00001],N/M,"We performed 50 iterations of random search over a set of parameter choices for hyper-parameter
tuning",N/M,Categorical Cross-Entropy,,N/M,"Train: 8700 patients
Valid: 300 patients
Test: 1000 patients",,"Accuracy
Cohen's Kappa","accuracy, Cohen's kappa","Intel Xeon E5-2640, 256GB RAM, 
four Nvidia Titan X",,between 40 -100 min,"[RNN] - Expert Defined Features: [Acc] 85.76 |  79.46 [k]
 [RNN] - Spectrogram Features: [Acc] 79.21 | 73.83 [k]
[RNN] - Waveform Features: [Acc] 79.46 | 72.46 [k]  
---
[RCNN] - Expert Defined Features: [Acc] 81.67 |  76.38 [k]
 [RCNN] - Spectrogram Features: [Acc] 81.47 |  74.37 [k]
[RCNN] - Waveform Features: [Acc] 79.81 | 73.52 [k]  ","Logistic Regression
Tree Boosting
MLP
CNN
RNN
RCNN",DL & Trad.,,We evaluate model performance with different look-back steps in RNN. Figure 8a shows that performance of the model increases as the number of lookback steps. This indicates that long-term temporal dependency does help improving sleep stage classification.,"On 1000 held-out testing patients, the best performing algorithm achieved an expert-algorithm level of inter-rater agreement of 85.76% with Kappa value 79.46%, exceeding previously reported levels of expert-expert inter-rater agreement for sleep EEG staging.",N/M,No,N/A,No,3.2 TB of data!!! ,,Yannick,[TBD],,Biswal2017
,MindID: Person Identification from Brain Waves through Attention-based Recurrent Neural Network,2017,"Zhang, Yao, Kanhere, Liu, Gu & Chen",Arxiv,Yes,"University of New South Wales, Australia
Tsinghua University
RMIT University, Australia",20,,Classification of EEG signals,Personal trait/attribute,Person identification,,Improve SOTA: EEG for Person Identification,Use RNN on EEG for Person Indentification,"3 Different Datasets.
(they claim that Delta has the most personal info)",The DL motivation is not clear. They want to improve SOTA.,,"1) Emotiv
2) N/M
3) N/M",No,Delta Band*,"Internal Recordings;
eegmmidb",Both,"1) 8
2) 8
3) 8","1) 14
2) 14
3) 64","1) 128Hz
2) 128Hz
3) 160Hz","1) 168,000 Samples
2) 56,000 Samples
3) 56,000 Samples",,,"1) Remove DC Offset (substract)
2) Band-Pass Filter: 0.5 - 4Hz  (using only Delta)",No,Delta Band,Frequency-domain,z-score,,Matlab,"Attention-based Encoder-Decoder RNN
+ XGB Classifier",RNN,"Encoder, Decoder, Attention Module
+ XGB Classifier",N/M,Yes,"1x14 
Delta Bands / Channel

(not clear about the dimensionality)","Encoder: 
3 FC (164) + 1 LSTM (164)

Decoder:
1 FC (164)",N/M,L2,,,"8

One-Hot Label
(ID - 8 Subjects)",N/M,N/M,Adam,LR: ,"21,000 samples

(?)",N/M,N/M,Cross-Entropy,,N/M,"Test/All Samples

DS #1: 21,000 / 168000 
DS #2: 7000 / 56000
DS #3: 7000 / 56000",,"Precision
Recall
F1-Score","precision, recall, f1-score","Nvidia Titan X Pascal
768G memory 
145 TB PCIe SSD",,N/M,"Precision | Recall | F1-Score
DS #1: 0.982 | 0.982 | 0.982
DS #2: 0.988 | 0.988 | 0.988
DS #3: 0.999 | 0.999 | 0.999","SVM, RF, KNN, AdaBoost, LDA, XGB, RNN",DL & Trad.,,N/M,"Moreover, the pre-trained model should be updated for a period of time since the user’s EEG data is gradually changed with the environmental factors such as age, mental state, and living style. One of our future work is to develop an online learning system which is enabled to automatically update the training dataset based on the testing data which is collected during the operating period.","Limited by the local experimental conditions, our study only gathered EEG data from 8 subjects with few trials. The dataset is only divided into two categories (Multi and Single), which is not enough to explore the change trend of the identification accuracy with the increase of data trials.",Yes,GDrive,Yes,"Code + Data available... Should be reproducible!
Very high results on an 8 class problem. 
Based only on Delta band...
Same group as DeepKey",,Yannick,[TBD],,Zhang2017e
,DeepKey: An EEG and Gait Based Dual-Authentication System,2017,"Zhang, Yao, Chen, Wang, Sheng & Gu",Arxiv,Yes,"University of New SouthWales
Macquarie University
RMIT University",20,,Classification of EEG signals,Personal trait/attribute,Person identification,,Improve SOTA: EEG for Person Identification,Use AR+RNN+SVM on EEG+Gait for Person Identification,"Motor Imagery
(see eegmmidb dataset)

+ Gait (PAMAP2 dataset)",The DL motivation is not clear. They want to improve SOTA.,,BCI2000 Instruments,No,Raw EEG,eegmmidb,Public,8,64,160,"1,200",,,None (AR),No,Raw EEG,Raw EEG,N/M,,N/M,AR + RNN + SVM,RNN,N/M,"AR for pre-processing, RNN for feature extracting, and SVM for classification. Auto-regressive Coefficients (AR) is one of the most widely used pre-processing methods on EEG data",Yes,"150x13x64
(150 segments, 13 coefficients (AR), 64 features/nodes)",5 RNN (64),N/M,L2,,,"8

One-Hot Label
(ID - 8 Subjects)",N/M,N/M,Adam,lambda is set as 0.004 while learning rate is set as 0.005,"8 mini-batch with the shape of [150, 13, 64]",Orthogonal Array Experiment Method,N/M,Log Loss Function,,N/M,"7:1

Train:Test",,Accuracy,accuracy,N/M,,N/M,"Highest Accuracy: 0.9841

Gait: 0.999
Combined: 0.983 ","[45]: PSD + cross-correlation values, [8]: Customized Threshold, [17]: Low-pass filter+wavelets+ ANN, [3]: Bandpass FIR filter +ECOC + SVM, [44]: IAF + delta band EEG + Cross-correlation & mahalobonis, [22]: CSP +LDA, [23]: AR + SVM",Traditional pipeline,,N/M,"The Gait Identification Model adopts a 7-layer deep learning model to process gait data and classify subjects’ IDs, achieving an accuracy of 0.999. The EEG Identification Model combines three components (auto-regressive coefficients, the RNN structure, and an SVM classifier) and achieves the accuracy of 0.9841 on a public dataset. Overall, the DeepKey authentication system obtains a FAR of 0 and a FRR of 0.019.",N/M,Yes,GitHub,No,"Code + Data available... Should be reproducible!
Very high results on an 8 class problem. 
Same group as MindID.
** Only the EEG part is reported. Not gait",,Yannick,[TBD],,Zhang2017c
,Multi-Person Brain Activity Recognition via Comprehensive EEG Signal Analysis,2017,"Zhang, Yao, Zhang, Wang, Sheng, Gu",Arxiv,Yes,"University of New South Wales, Australia
Singapore Management University
Macquarie University, Australia
RMIT University, Australia",10,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use AE + XGB for BCI-MI 5 classes (eegmmidb + internal recordings),"Motor Imagery
(see eegmmidb dataset)","Deep learning should be able to generalize better across subjects and across classes, instead of binary classif.",,BCI2000 Instruments,No,Motor Imagery,eegmmidb,Public,20,64,160,"560,000 samples",,,N/M,No,"Raw EEG
(None)",Raw EEG,z-score,,N/M,"AE 
+ XGB Classifier",AE,"Encoder, Decoder + XGB Classifier",N/M,Yes,"64x??

Channels x Raw EEG time window","1 (64)

Input - Encoder - Decoder - Classifier (XGB)",N/M,L2,,,5,N/M,N/M,RMSProp,LR: 0.01,"There are 9 mini-batches and the batch size is 17,280.",N/M,N/M,MSE,,N/M,"Train: 532,000
Test: 28,000",,"Accuracy
Precision
Recall
F1-Score
ROC
AUC","accuracy, precision, recall, f1-score, ROC, AUC","Nvidia Titan X Pascal
768G memory 
145 TB PCIe SSD",,See charts,"Accuracy: 0.794
Precision: 0.7991
Recall: 0.781
F1 score: 0.7883
AUC: 0.9456","SVM, RNN, LDA, RNN+SVM, CNN, DT, AdaBoost, RF

XGBoost, PCA+XGBoost, PCA+AE+XGBoost, EIG+AE+XGBoost, EIG+PCA+XGBoost, DWT+XGBoost, SAE+XGBoost, AE+XGBoost",DL & Trad.,,N/M,"As part of our future work, we will build multi-view model of multi-class EEG signals to improve the classification performance. In particular, we plan to establish multiple models with each single model dealing with a single class. Following this philosophy, the correlation between test sample and each model can be calculated in the test stage and the sample can be classified to the class with minimum correlation coefficient.",N/M,No,N/A,No,"They also did it on an Emotiv internal experiment that they've been using a couple of papers now.
It would be interesting to get that dataset and reproduce results!",,Yannick,[TBD],,Zhang2017a
,Neurology-as-a-Service for the Developing World,2017,"Dharamsi, Das, Pedapati, Bramble, Muthusamy, Samulowitz, Varshney, Rajamanickam, Thomas & Dauwels",Arxiv,Yes,"IBM Research AI
Nanyang Technological University",5,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA: Use DL on the Cloud,Use DL on the Cloud for developing countries. Starting with a BCI Tasks (MI),"MI: Feet and Hands, real / imagined.",To develop neurology-as-a-service to learn features automatically from the data. This would help developing countries,,"N/M
(see EEG-MMIDB paper)",No,Motor Imagery,eegmmidb,Public,103,64,160,1500 trials / subject,,,"1) Bandpass: 3 - 30Hz
2) Generate Spectrogram: Hanning window & NFFT (128)","No
(mention it, but only filters)",Spectrograms,Frequency-domain,N/A,,"N/M
(Cloud)",CNN,CNN,N/M,N/M,No,"3D
(channels x freq x time)","[1-3 3D CNN]
[0-2 FC]",N/M,Dropout,,,N/M,N/M,N/M,(hyperparameters are automatically fine-tuned using an optimizer),LR: 0.001,N/M,Random Optimizer,N/M,N/M,,N/M,"7:3
Train:Test",,Accuracy,accuracy,"N/M
(Cloud)",,N/M,Best accuracy: 63.4%,PCA-SVM,Traditional pipeline,,N/M,"As part of our next steps, we plan to use this framework on a dataset aimed at classification of epileptic seizures and/or pathological/normal EEG. We would also like to see how the framework performs using other hyperparameter optimization techniques including Bayesian optimization.",N/M,No,N/A,No,Nothing really new... DL with CNN on the cloud from eegmmidb,,Yannick,[TBD],,Dharamsi2017
,Deep Architectures for Automated Seizure Detection in Scalp EEGs,2017,"Golmohammadi, Ziyabari, Shah, de Diego, Obeid, Picone",Arxiv,Yes,"Neural Engineering Data Consortium, Temple University",8,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA: Comparing different deep architectures,"Compare HMM+sAE, HMM+LSTM, IPCA+LSTM, CNN+MLP, CNN+LSTM","Ongoing EEG recording, with and without seizures.",With big EEG corpus now available we can explore deep learning.,,"1) Natus EEG Equipment 
2) Nihon Kohden",No,Seizures,"TUH;
Duke Seizure Corpus",Both,"1) Train: 64 
1) Eval: 50
2) Eval: 45","1) 22
2) ? (see ds paper)","1) 250
2) ? (see ds paper)",(see ds papers),,,N/M,,LFCCs + First & Second Derivative of LFCCs,Other,N/A,,N/M,"1) HMM + sAE
2) HMM + LSTM
3) IPCA + LSTM
4) CNN + MLP
5) CNN + LSTM",CNN+RNN,2D Conv Layers -> Flatten -> 1D Conv Layer -> LSTM (output 1s data) -> LSTM -> 2-way sigmoid,"They tried different architectures trying to capture Spatio-Temporal information.
They also use Time-Freq Features, 
not raw EEG as is.",Yes,"210 @ 22 x 26 x 1
(Frames @ Channels * Features * 1)

(to be reviewed)","3x 2D CNN 
+ 1x 1D FC CNN
+ 2x Bi-LSTM
(CNN + LSTM)
(see paper for others)",ELU,Dropout,,,2-way Sigmoid,N/M,"Trained + Eval on TUSZ and 
only Eval on DUSZ",Adam,N/M,N/M,N/M,N/M,MSE,,N/M,N/M,,"Sensitivity
Specificity","sensitivity, specificity",N/M,,N/M,"CNN + LSTM gave the best results.

TUSZ   -   Sensitivity: 30.83%   |   Specificity: 96.86%
DUSZ   -   Sensitivity: 33.71%   |   Specificity: 70.72%","HMM + Gaussian mixture + AE
They compared 7 Optimizer Methods. (e.g. Adam, SGD, etc.)
They compared 6 Activation Functions. (e.g. Tanh, Sigmoid, etc.)
CNN + LSTM, Adam, ELU is the best combinaison",DL,,N/M,This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology.,Access to labeled data and $ to label the data and make it public.,No,N/A,Yes,"I love these guys' architecture graphs! They have one for all of their difference approaches!

If only they'd have their code open source, they'd be stealing the show!",,Yannick,[TBD],,Golmohammadi2017a
,Neonatal Seizure Detection using Convolutional Neural Networks,2017,"O'Shea, Lightbody, Boylan, Temko",IEEE 27th International Workshop on Machine Learning for Signal Processing,Yes,"Irish Centre for Fetal and Neonatal Translational Research, University College Cork",6,,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach,CNN on (preprocessed) raw EEG for epilepsy classification,"Ongoing EEG recording, with and without seizures.","CNN works well on audio signal, why not on EEG.",,N/M,No,Seizure,Internal Recordings,Private,18,8,256,N/M,,,"Band-pass filter: 0.5 - 12.8Hz
Down sampled: 32Hz
EEG Split into 8s windows (50% overlap)",,Raw EEG,Raw EEG,N/A,,Keras,1D - CNN,CNN,"Conv - Batch Norm. - Pooling
Output Layer: GAP (not dense)","""...1D CNNs wide convolutional filters (1-4s, 32-128 samples) significantly improved the performance"". Sample size filters were used. In contrast to larger filter lengths allow the learning the various filters in a hierarchical manner [21].",Yes,"256x1
(1s x 1 channel)",6,RELU,Batch Norm,,,"2
(Seizure vs Non-seizure)","16,930",N/M,SGD,"LR: 0.003
LR -= 10% every 
20 iterations
Nesterov Momentum: 0.9",2048,N/M,"Sliding Window
(Shifted by 1s, 7/8 overlap)",Categorical Cross-Entropy,,"Leave-one-subject-out
(LOO)",N/M,,AUC,AUC,N/M,,N/M,"AUC: 97.1%
AUC90: 82.9%",SVM,Traditional pipeline,,N/M,"""We have also tried max pooling, which led to slightly inferior results in our experiments.""
""Initially, the EEG was converted to time-frequency images (spectrograms) and 2D CNNs were utilized, adopted from the area of image processing [17] – this architecture proved unsuccessful in the seizure detection task.""",N/M,No,N/A,No,"No.
(YR to ask for their dataset!)",,Yannick,[TBD],,Oshea2017
,Improving classification accuracy of feedforward neural networks for spiking neuromorphic chips,2017,"Yepes, Tang & Mashford",International Joint Conference on Artificial Intelligence,Yes,"IBM Research, VIC, Australia",7,,Improvement of processing tools,Hardware optimization,Neuromorphic chips,,New Approach: Running DL on Neuromorphic Chips,"Compare constrained network for a neuromorphic chip on 2 datasets, vs unconstrained version of NN ","MNIST & EEG Data from Nurse et al., 2015 (BCI-MI)",Implement DL/DNNs on a chip.,,"N/M
(see dataset paper)",No,Motor Imagery,"Nurse et al., 2015",Public,5,N/M,"N/M

(1000Hz?)",1109,,,N/M,No,N/M,NS,"[0, 1]",,Matlab,"[Esser et al., 2015]",NS,"[Esser et al., 2015]","[Esser et al., 2015]",No,N/M,"Small Network: 3
Large Network: 4",N/M,N/M,,,2,N/M,N/M,N/M,LR: 0.1,25,N/M,No,N/M,,N/M,"Train: 480/468
Test: 66/95
(class1/class2)",,Accuracy,accuracy,"TrueNorth
(IBM Chip)",,(see paper),"EEG Data: 86%
MNIST: 98-99%","On the TrueNorth Chip (constrained)
vs
Traditional Methods (Unconstrained)",Traditional pipeline,,N/M,"Furthermore, analysis of the learnt parameters pro- vide insights that might complement hardware design, thus providing a more efficient deployment of the trained models. The trained models use a small portion of the TrueNorth chip (30 cores vs. 4096 avail- able in the current version of the chip), thus requiring a much less than 70mW to work, which makes these models suitable for portable autonomous devices with large autonomy.",N/M,No,N/A,No,IBM Research is really into porting DL on neuromorphic chips. They have a couple of papers on it.,,Yannick,[TBD],,Yepes2017
,Automatic Analysis of EEGs Using Big Data and Hybrid Deep Learning Architectures,2017,"Golmohammadi, Hossein, Torbati, Lopez De Diego, Obeid & Picone",Arxiv,,"Temple University
Jibo, Inc., Redwood City",20,,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach: Hybrid HMM & SdA for Epilepsy,"Using an Hybrid 3 Passes Model, combining HMM & Stacked Denoising AutoEncoders for Epilepsy classification","Ongoing EEG recording, with and without seizures.
(TUH Dataset)",Deep Learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction,,"Natus Medical Inc.’s
Nicolet",No,Seizure,TUH,Public,"Total: 16,000",[20-128],[250-1024],"30,000 sessions",,,PCA,No,Cepstral coefficient-based feature extraction approach based on Linear Frequency Cepstral Coefficients (LFCCs),Other,N/M,,Theano,3x Stacked denoising Autoencoders (SdA),AE,"3 Passes. 
(1) HMM -> (2) SdAs -> (3) NLP

(2) PCA -> Out of Sample -> 3 SdAs in parallel -> Enhancer (combining 3 SdAs)",Not you typical DL-EEG approach...,Yes,,3 [Nodes from 100-800],N/M,N/M,,,6 Classes,N/M,Training of these three SdA networks is done in two steps: pre-training and fine-tuning. Denoising autoencoders are stacked to form a deep network. The unsupervised pre-training of such an architecture is done one layer at a time.,Minibatch Stochastic Gradient Descent,LR: [0.1-0.5],[100-300],N/M,"Out-of-sample technique 
(van der Maaten, 2009)",Cross-Entropy,,N/M,"Train: 84,032
Test: 29,421",,"Sensitivity
Specificity","sensitivity, specificity",N/M,,N/M,"Pass: Sensitivity | Specificity
1 (HMM): 86.78 | 17.70
2 (SdA): 78.93 | 4.40
3 (SLM): 90.10 | 4.88",N/M,None,,N/M,A summary of the results for different stages of processing is shown in Table 12. The overall performance of the multi-pass hybrid HMM/deep learning classification system is promising: more than 90% sensitivity and less than 5% specificity.,N/M,No,N/A,No,A little uncommon.,,Yannick,[TBD],,Golmohammadi2017
,Multimodal deep learning approach for joint EEG-EMG data compression and classification,2017,"Ben Said, Mohamed, Elfouly, Harras & Wang",IEEE Wireless Communications and Networking Conference,,"Qatar University
Carnegie Melon University
University of British Columbia",6,,Classification of EEG signals,Monitoring,Affective,Emotion,New Approach: Compressing joint EEG-EMG with an autoencoder,Compression & Classification of joint EMG + EEG on DEAP dataset with SAE,"Watching music videos
(DEAP Dataset)",Deep learning approach has emerged as one of the possible techniques to exploit the correlation of the data from multiple modalities. Compression for mobile health data.,,N/M,No,Emotions,DEAP,Public,32,N/M,128Hz,"23040 Samples
(for both EMG & EEG)",,,"1) 6s Windows
2) Whitened
3) Normalized",,"Raw EEG + EMG
(None)",Raw EEG,z-score,,N/M,SAE,AE,N/M,Deep learning approach has emerged as one of the possible techniques to exploit the correlation ofthe data from multiple modalities,No,N/M,2 SAE,Sigmoid,"L2
(to be confirmed)",,,"N/M
1) Compressed data
2) Classification",N/M,Greedy-layer wise,N/M,N/M,N/M,N/M,"Duplicated multimodal data keeping values from 1 modality, setting the other modality to 0. 
And vice-versa.",Square Euclidean Distance,,N/M,"1) Compress: 50-50
2) Classif: 75-25",,"1) Compression: Distortion
2) Classification: Accuracy","distortion, accuracy",N/M,,N/M,"1) [Compression] Distortion: EMG = 13.85% |  EEG = 12%
2) [Classification] Accuracy: 78.1%","Discrete Wavelet Transform (DWT) [26]
Compressed Sensing (CS) [27] (distortion: 22% | 17.21%)
2D compression approach which is based on SPIHT and FastICA [28]",Traditional pipeline,,N/M,"1) Compression: Distortion
2) Classification",N/M,No,N/A,No,-,,Yannick,[TBD],,BenSaid2017a
,Deep Learning for Fatigue Estimation on the Basis of Multimodal Human-Machine Interactions,2017,"Gordienko, Stirenko, Kochura, Alienin, Novotarskiy & Gordienko",Arxiv,Yes,National Technical University of Ukraine,12,,Classification of EEG signals,Monitoring,Physical,Exercise,New Approach,Multi-modal fatigue (and activity) estimation,Different activities (sports) while having different sensors,Use Multimodal Models. to combine different modalities with a NN.,,OpenBCI,No,Multimodal,Internal Recordings,Private,"Not clear.
(1 ?)","not clear
(OpenBCI?)",N/M,N/M,,,N/M,N/M,N/M,NS,N/M,,N/M,DNN,NS,N/M,N/M,No,N/M,N/M,N/M,N/M,,,N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,"Mean Residual Deviance (MRD) 
Mean Absolute Error (MAE)",,N/M,N/M,,"Mean Residual Deviance (MRD) 
Mean Absolute Error (MAE)","mean residual deviance, mean absolute error",N/M,,N/M,"See Paper
(not really relevant / meaningful for this paper)",N/M,None,,N/M,The main achievement is the multimodal data measured can be used as a training dataset for measuring and recognizing the intensity and physical load on the person by means of the machine learning approaches.,N/M,No,N/A,No,Terrible paper.,,Yannick,[TBD],,Gordienko2017
,Towards Deep Modeling of Music Semantics using EEG Regularizers,2017,"Raposo, Matos, Ribeiro, Tang & Yu",Arxiv,Yes,Universidade de Lisboa,5,,Classification of EEG signals,Music semantics,,,Improve SOTA on music semantics,Modeling of music audio semantics,Listening to music,Previous success of CNNs in music audio modeling,,OpenBCI,No,None,Internal Recordings,Private,18,16,250Hz,N/M,,,"1) Highpass 0.5Hz 
2) Notch at 50Hz",Yes,Raw EEG + Audio embeddings,Raw EEG,"Rescaled [-1, 1]",,N/M,CNN,CNN,N/M,N/M,Yes,N/M,5,ReLU,No,,,128,N/M,"1) Train audio+lyrics embeddings model
2) Train audio embeddings+EEG embeddings model",N/M,N/M,102,N/M,N/M,CCA between embeddings,,5-fold,N/M,,"Mean Reciprocal
Rank (MRR)",mean reciprocal rank,GeForce GTX 1080,,20 minutes,"Outperformed Spotfiy by ~1%, but did not perform better than the SOTA (by a small margin)",Spotify embeddings and current SOTA (Choi),DL & Trad.,,N/M,"Proposed approach did not outperformed SOTA but SOTA was trained on more
than 2083 hours of music, whereas the proposed method needs less than 3 hours of both music and EEG",N/M,No,N/A,No,Did not outperformed SOTA by a small margin and it seems there is a lot of room for improvement,,Isabela,[TBD],,Raposo2017
,Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals,2017,"Acharya, Oh, Hagiwara, Tan & Adeli",Computers in Biology and Medicine,,"Ngee Ann Polytechnic, Singapore
SUSS University, Singapore
University of Malaya, Malaysia
The Ohio State University, US",,,Classification of EEG signals,Clinical,Epilepsy,Detection,"New Approach: CNN for Epilepsy
(claiming its a new approach, but it's not...)",13-Layers CNN for Epilepsy,"Ongoing EEG recording, with and without seizures.",To develop a computer-aided diagnosis (CAD) to classify EEG,,N/M,No,Seizures,Bonn University,Public,15,1,173.6,N/M,,,None,,Raw EEG,Raw EEG,z-score,,N/M,CNN,CNN,"1D CNN
Conv / Max Pooling",,Yes,4097x1,"1D CNN: 10
FC: 2",ReLU,"L1 ? 
(To be confirmed)",,,"3
(Softmax with 3 classes)",N/M,A conventional backpropagation (BP) [32] with a batch size of 3 is employed in this work to train CNN.,"The parameters used to train the CNN model are (i) lambda (regularization), (ii) learning rate, and (iii) momentum","Lambda: 0.7
LR: 1x10^-3
Momentum: 0.3",3,Trial and Error,No,N/M,,10-Fold CV,"Train: 90%
Test: 10%",,"Accuracy
Sensitivity
Sensibility","accuracy, sensitivity, sensibility","Intel Xeon 2.40 GHz (E5620)  
24 GB RAM",,"150 epochs
12.8s / epochs
=  32 min","Accuracy: 88.7% 
Sensitivity: 95% 
Specificity: 90%","Many other SOTA
(check paper)
They performed worse than most previous SOTA",Traditional pipeline,,N/M,"The advantage of the model presented in this paper, however, is separate steps of feature extraction and feature selection are not required in this work. Nevertheless, the main drawback of this work is the lack of huge EEG database",Amount of data,No,N/A,Yes,"Bad results compared to SOTA, but interesting...
13 layers would probably need more data.",,Yannick,[TBD],,Acharya2017
,Electroencephalogram-based decoding cognitive states using convolutional neural network and likelihood ratio based score fusion,2017,"Zafar, Dass & Malik",Plos One,No,Universiti Teknologu PETRONAS,23,,Classification of EEG signals,BCI,Reactive,RSVP,Improve SOTA,Decode seen images by extracting features with a CNN,Watching natural images from 5 classes,Features learned automatically can be more efficient,,EGI,No,None,Internal Recordings,Private,26 (30 initially),128,250,6760,,,"[Hardware: Bandpass from 0.1 to 100 Hz]
1) Bandpass from 0.3 to 30 Hz
2) Removal of eye artefacts",,Raw EEG,Raw EEG,N/M,,N/M,CNN,CNN,"Modified LeNet
CNN is *just* for feature extraction (feature selection and classification is done separately)",Temporal 1D conv in first layer,Yes,128 x 250,2,"Sigmoid, tanh",N/M,,,128 x 11 x 100,N/M,???,N/M,N/M,N/M,N/M,N/M,N/M,,Monte-Carlo 100-fold CV (sampled with replacement),"Train: 90%
Test: 10%",,"Accuracy
Sensitivity
Sensibility","accuracy, sensitivity, sensibility",N/M,,N/M,"Accuracy (across participants, 5-class): 40%",Discrete Wavelet Transform + SVM,Traditional pipeline,,NM,,Amount of data,No,N/A,No,"Very verbose. Actually only 2 layers.
They used a CNN to extract features, and applied feature selection and classification separately. I'm confused as to how they trained the CNN...",,Hubert,[TBD],,Zafar2017
,Deep Convolutional Neural Network for Emotion Recognition Using EEG and Peripheral Physiological Signal,2017,"Lin, Li & Sun",International Conference on Image and Graphics,,"College of Computer Science of Zhejiang University, Hangzhou, China",,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA: AlexNet on DEAP,AlexNet on Images (Raw EEG + Freq Bands) + other physiological sensors,"Watching videos
(check out DEAP details)",Using AlexNet on DEAP,,N/M,No,Emotions,DEAP,Public,32,32,512,N/M,,,"1) Downsampling to 128Hz
2) Band-Pass Filter: 4.0 - 45Hz
3) Average to Common Reference* (?)",,"EEG -> 6 gray images (Raw EEG + Freq Bands)
+ 81 features from other physiological sensors",Frequency-domain,z-score,,N/M,CNN,CNN,AlexNet,"AlexNet is great for images, frequency bands can be converted to images...",Yes,6 Gray Images (2D),"5 CNN
1 FC (81+500)",N/M,N/M,,,"2
Softmax",N/M,-,SGD,"LR: 0.001
(decreases every 500 iterations)",200,Empirically,N/M,N/M,,10-Fold CV,N/M,,"Accuracy
F1-Score","accuracy, f1-score",N/M,,N/M,"Arousal - Accuracy:  87.30%
Arousal - F1-Score:  78.24%
Valence - Accuracy:  85.50%
Valence - F1-Score:  80.06%","Many other SOTA
(check paper)
They outperform all others.",Traditional pipeline,,N/M,"To achieve better performances, data preprocessing of the original signal was also adopted. The provided experimental results prove the effectiveness and validate the proposed contributions of our method by achieving superior performance over the existing methods on DEAP Dataset.",N/M,No,N/A,No,Intriguing... I'll try to reproduce.,,Yannick,[TBD],,Lin2017
,Cross-subject recognition of operator functional states via EEG and switching deep belief networks with adaptive weights,2017,Yin & Zhang,Neurocomputing,No,University of Shanghai,18,,Classification of EEG signals,Monitoring,Cognitive,Mental workload & fatigue,Improve SOTA on cross-subject operator functional state recogntion ,"Exploit ""new"" improvements in deep learning",Cabin air management simulation (AutoCAMS),Using switching deep belief network with adaptive weights,,Nihon Kohden,No,None,Internal Recordings,Private,8,11,500Hz,"8640
1080/subject 8)",Offline,,1) Adaptive exponential smooth (to remove outliers),Yes,"Centroid frequency, log-energy entropy, mean, five power components, Shannon entropy, sum of energy, variance, zero-crossing rate of each channel and power differences between channel pairs",Frequency-domain,z-score,,Matlab 2011b,"Switching
DBN",DBN,One DBN per subject,The member DBN is switched at different time instants to fit the non-stationarity of the EEG features recorded from a novel testing subjects.,Yes,152x1,4,Sigmoid,N/M,3,"Low MW
Medium MW
High MW","Isabela: 2
Yannick: 3",N/M,Unsupervised pre-training of DBNs to learn representation of features for each subject (layer by layer). Supervised fine-tuning of the complete model. ,N/M,"Pre-training: 0.1
Fine-tuning: 1",10,N/M,Gaussian noise to feature vector,N/M,Inter,Leave-one-subject out,N/M,,"Accuracy
True positive
True negative
False positive
False negative","accuracy, true positives, true negatives, false positives, false negatives ","AMD4CPU 1.9GHz, 8G RAM",,N/M,"Mental workload: 77%
Mental fatigure: 68%
MW+MF: 54%","KNN, Naive Bayes, Logistic Regression, LSSVM, SAE, DBN 
(all with and without PCA) ",DL & Trad.,"Yes
Two-tailed Wilcoxon sign-rank test",N/M,"Results of the proposed method outperform all baselines. When the number of subjects increases, the performance gap between SDBN and baselines increases, suggesting that the number of subjects plays a fundamental role. ",Number of subjects is crucial to obtain a good performance ,No,N/A,No,"Paper is really nice, though presentation of the proposed approach and results could be better (it is a bit messy).",,Isabela,Yannick,,Yin2017
,Vowel classification from imagined speech using sub-band EEG frequencies and deep belief networks,2017,Sree & Kavita,"IEEE International Conference on Signal Processing, Communications and Networking ",No,SSN College of Engineering,4,,Classification of EEG signals,BCI,Active,Speech decoding,Improve SOTA on vowel classification,Use DBNs to extract EEG features,Speech imagery ,N/M,,RMS EEG-32 super spec,No,None,Internal Recordings,Private,5,32,128Hz,N/M,,,1) Band-pass 1-60Hz,No,"Energy features of Wavelet transform: Root Mean Square, Mean Absolute Value, Integrated EEG, Simple Square Integral, Variance of EEG, Average Amplitude Change",Frequency-domain,z-score,,N/M,DBN,DBN,N/M,N/M,No,N/M,7,N/M,N/M,,,N/M,N/M,N/M,N/M,LR: 0.002,N/M,N/M,N/M,Log-likelihood,,N/M,"Train: 80%
Test: 20%",,Accuracy,accuracy,N/M,,N/M,~87.5% (I believe this the average value for all vowels and EEG bands) ,No,None,,N/M,Vowels were more accurately classified in the theta and gamma bands,N/M,No,N/A,No,"Paper is limited, specially the results. Did not compared with other methods, which makes hard to analyze the extent of the contribution.",,Isabela,[TBD],,Sree2017
,Bullying incidences identification within an immersive environment using HD EEG-based analysis: A Swarm Decomposition and Deep Learning approach,2017,"Baltatzis, Bintsi, Apostolidis & Hadjileontiadis",Nature Scientific Reports,No,"Aristotle University of Thessaloniki, Khalifa University of Science and Technology",8,,Classification of EEG signals,Monitoring,Affective,Bullying incidents,New task: classifying bullying stimuli,Classifying bullying stimuli in 2D or VR presentation,Watching stimuli (2D or in VR) of bullying situations,N/M,,Geodesics EEG 400,No,None,Internal Recordings,On request,17,256,250,510,,,"1) Bandpass 0.3-30 Hz
2) Artefact detection, bad channel replacement, baseline correction
3) Channel-wise normalization (- mean, / max)
4) Highpass @7Hz
5) Downsample to 128 Hz",Yes,"1) Swarm decomposition to get oscillatory modes
2) k-means clustering to re-order channels based on the respective distance to each other",Other,N/M,,N/M,CNN,CNN,N/M,N/M,Yes,256 x 128,2,ReLU,N/M,,,2 or 4,N/M,Standard optimization,N/M,N/M,N/M,N/M,N/M,"""Softmax""",,10-Fold CV,"Train: 90%
Test: 10%",,"Accuracy
Precision
Recall
AUC","accuracy, precision, recall, AUC",N/M,,N/M,"2-class:
Accuracy, precision, recall, AUC (test): 0.937, 0.9403, 0.9395, 0.9869
4-class:
Accuracy, precision, recall, AUC (test): 0.8858, 0.8775. 0.87475, 0.975","No Swarm decomposition or clustering
Just clustering
Just Swarm decomposition",Traditional pipeline,,N/M,"Swarm Decomposition was an important step in getting high accuracy.
Withouth k-means clustering the network was overfitting.",Larger nets take more resources,No,N/A,No,"Interesting task. Although the use a CNN, it's not really deep, and it relies on substantial signal processing before being fed into the net.",,Hubert,[TBD],,Baltatzis2017
,Classification and discrimination of focal and non-focal EEG signals based on deep neural network,2017,"Taqi, Al-Azzo, Mariofanna & Al-Saadi",International Conference on Current Research in Computer Science and Information Technology (ICCIT),,"University of Arkansas at Little Rock
Asiacell Company for Telecommunication, Iraq",7,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,"Detecting Focal vs Non-Focal Seizures with existing Deep Nets: AlexNet, LeNet, GoogleNet",Seizures (Bern-Barcelona Dataset),"deep neural network (DNN) is a high-res model that get sophisticated hierarchical features. (e.g. AlexNet, LeNet, GoogleNet)",,"N/M
(see dataset paper)",No,Seizures,Bern-Barcelona EEG DB,Public,5,N/M,256,300 of each class,,,None,No,"None
(Raw EEG)",Raw EEG,N/M,,Caffe,"N/M
(pre-trained models)",NS,"N/M
(pre-trained models)","Using SOTA Networks in Vision/Images for EEG.
(AlexNet, LeNet, GoogleNet)",No,256x256 (images),"N/M
(pre-trained models)","N/M
(pre-trained models)","N/M
(pre-trained models)",,,2,N/M,"pre-trained models
(AlexNet, LeNet, GoogleNet)","N/M
(pre-trained models)",N/M,N/M,N/M,N/M,N/M,,N/M,"Train: 75%
Test: 25%",,Accuracy,accuracy,NVidia GPUs,,N/M,"LeNet, AlexNet, GoogleNet
100%  (with different numbers of TEs)

LeNet is the best compromise","Anindya et al., 2016 : 89.4%
(EMD-DWT domain, K-nearest neighbor classifier)
R. Sharma et al.,2015 : 84%
(DWT domain, KNN, PNN, fuzzy and LS-SVM)
R. Sharma et al.,2014 : 85%
(EMD domain, LS-SVM classifier)",Traditional pipeline,,N/M,"As a future task, we are looking forward to investigating approaches for EEG signals classification of other diseases, drunk people, or ECG signals classification",N/M,No,N/A,No,"Not a very good paper. From the language, to the wording...",,Yannick,[TBD],,Taqi2017
,Deep Transfer Learning for Cross-subject and Cross-experiment Prediction of Image Rapid Serial Visual Presentation Events from EEG Data,2017,"Hajinoroozi, Mao & Lin",Augmented Cognition. Neurocognition and Machine Learning ,,"University of Texas at San Antonio
National Sun Yat-sen University, Tawain",11,,Classification of EEG signals,BCI,Reactive,RSVP,Novel Approach: Transfer Learning,"Transfer learning on RSVP task with CNN on Raw EEG:
(1) Cross-Suject 
(2) Cross-Experiment","RSVP (3 datasets from 1990, 1999, 2013)",Transfer learning has a lot of potential for BCI training.,,Biosemi,No,RSVP,"USA DoD (1999);
USA Army (1990);
Touryan et al. (2013)",Private,"1) 15
2) 16
3) 10","1) 64
2) 64
3) 256","1) 512
3) 512
3) 512","1) 65,831
2) 62,553
3) 21,680",,,"1) Bandpass filter: 0.1 - 55 Hz
2) Downsampled to 128 Hz
3) Epoching: 1s window",No,"None
(Raw EEG)",Raw EEG,N/M,,N/M,"STCNN
(Spatial-Temporal CNN)",CNN,"Pretty much a CNN with a fancy name.
2 Conv Layers + 3 FC
with dropout",Trying to capture Spatial and Temporal information from Raw EEG,Yes,64x128,"CNN: 2
FC: 3",ReLU,Dropout,,,"2
Target / Non-Target
(softmax)",N/M,"The paper is about transfer learning.
Training on 1 dataset, then fine-tuning (or not) on the other.",N/M,N/M,N/M,N/M,N/M,N/M,,10x 10-Fold CV,N/M,,AUC,AUC,N/M,,N/M,"Ranging from 73-77%, depending on source / target datasets and transfer type (Cross-Subject or Cross-Experiment)","Bagging, XLDA, LDA",Traditional pipeline,,"Yes (read paper for full description)
All Layers: Subject Specific Info.
CNN Layers: Mostly Subj. Specific Info.
All Layers: General Info as well.",This study represents the first comprehensive investigation of CNN transferability for EEG based classification and our results provide important information that will guide the design of more sophisticated deep transfer learning algorithms for EEG based classifications in BCI applications.,N/M,No,N/A,No,"Very interesting paper on transfer learning!
You need to ""fine-tune"" to get good results on new data, otherwise the more layers the less transfer.",,Yannick,[TBD],,Hajinoroozi2017
,Transformation of EEG Signal for Emotion Analysis and Dataset Construction for DNN Learning,2017,"Kwon, Nan, & Shin Dug",Advances in Computer Science and Ubiquitous Computing ,,Yonsei University,6,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Use DNN on Frequency features for emotion classification,Watching Videos (not much details on the videos),DNN shows strong modeling ability for more complex cases,,EPOC,No,"Emotions
(PSD)",Internal Recordings,Private,N/M,14,128,,Offline,,"1) Remove DC offset
2) High-pass filter: 4Hz",No,Frequency Bands,Frequency-domain,N/M,,N/M,DNN,NS,N/M,N/M,Yes,"9
(not sure why 9...)","2
(100 and 50 nodes)",N/M,N/M,2,"Happy, Neutral",2,N/M,N/M,N/M,N/M,396,N/M,N/M,N/M,N/M,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"Stacking each row: 92%  (after ~3000 epochs)
Batch size 396: 86.5% (after 50000 epochs)",N/M,None,N/M,N/M,"We have found that the placement of the input data is as important as the preprocessing of the raw data. In our emotion classification experiment, we showed superior performances when we learn by stacking one row at a time than learning happy data matrix and neutral data matrix sequentially",N/M,No,N/A,No,"Not a good paper. Very little information. Not even the number of participants nor the length of the session, unless the 5 minutes is the full duration including both classes... Which is very little data.",,Yannick,[TBD],,Kwon2017
,The Analysis and Classify of Sleep Stage Using Deep Learning Network from Single-Channel EEG Signal,2017,"Xie, Li, Xie, Wang & Duan",International Conference on Neural Information Processing,No,"Northwestern Polytechnical University, China",7,,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use CNN on Frequency features for sleep stage classification,Sleep (Sleep-EDF dataset),CNN has been proved to be very good at discovering the intricate structures in complex data.,,"N/M
(see dataset paper)",No,Sleep,Sleep EDF,Public,11,1,"N/M
(see dataset paper)",N/M,,,"1) Bandpass filter: 1 - 40 Hz
2) Epoch of 30s windows
3) Epochs with artifacts removed
4) STFT for Freq Band Features",Yes,Frequency,Frequency-domain,z-score,,N/M,CNN,CNN,"Pooling ""layers""",CNN for Time-Frequency Image,Yes,"20x40 pixels
(Time-Frequency Image)",2,Sigmoid,N/M,,,"4
(4 Sleep Stages)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,,Leave-one-out,N/M,,"Accuracy
Sensitivity
Specificity","accuracy, sensitivity, sensibility",N/M,,N/M,"Accuracy: 
Specificity: 
Sensitivity: ","MI+SOM: ~70%
PSS+ANN: ~81%
SF+AdaBoost: ~82%",Traditional pipeline,,N/M,"In comparison with several recently available methods on the single channel classification of sleep stages, the present study has certain advantages with 88.83% in terms of the accuracy.",N/M,No,N/A,No,Very short paper. Not much details,,Yannick,[TBD],,Xie2017
,Deep Models for Engagement Assessment With Scarce Label Information,2017,"Li, Zhang, Wang, Xu, Schnell, Wen, McKenzie & Li",IEEE Transaction on Human-Machine Systems,,"Old Dominion University, Norfolk, VA
Intelligent Automation, Inc., Rockville, MD
University of Iowa, Iowa
Georgia Institute of Technology, Atlanta, GA",8,,Classification of EEG signals,Monitoring,Cognitive,Engagement,Improve SOTA,Use Deep Classifier & Deep Autoencoder on a Flight Simulator task for engagement classification,Flight Simulator (4h flight) with specific and controlled events,Unsupervised and semisupervised algorithms can utilize unlabeled data for training and thus improve the generalization capability of the model [15]–[17].,,ActiCap,No,"Engagement
(via PSD)",Internal Recordings,Private,15,"8
(out of 32)",200,"10 min of Engaged 
+ 10 min of Disengaged 
x 15 pilots",,,"1) Visual Inspection & Artifact Removal
2) High-Pass filter: 0.5Hz
3) Notch filter: 60Hz
4) Wavelet-based method to remove physiological noise",Yes,1-Hz bin PSDs,Frequency-domain,N/M,,N/M,RBM,RBM,"We used Gaussian–Bernoulli RBMs for training the first layer that contains real-valued visible units [34]. 
We utilized Bernoulli–Bernoulli RBMs for training higher layers that contain binary visible and hidden units.",N/M,Yes,"312 Features
(39 Freq Bins * 8 Channels)",2,Sigmoid,Dropout,,,"1
Engaged / Disengaged
(SVM)",N/M,Pre-training,N/M,N/M,N/M,Tested different hyperparameters by performing fivefold CV and compared performance results from these combinations.,N/M,not clear,,5-Fold CV,not clear,,Accuracy,accuracy,"HP Z800 Workstation
2x Intel Xeon x5660
48Go Ram
GeForce GTX 780",,10 min / subject,Accuracy: 97.53%,"Compared 10 Methods + 3 other papers
Shen et al., 2008 (SVM)
Trejo et al., 2007
Lan et al., 2003",Traditional pipeline,,N/M,"This paper has studied engagement assessment of pilots under com- plex tasks with limited labeled EEG data. We developed deep learning models that were able to learn valuable high-level features by taking advantage of both unlabeled and labeled data. Two deep models (a deep classifier and a deep autoencoder) have been studied, and both models outperformed two traditional methods when label information was limited for training.","1) We did not study the physiological significance of the learned high-level representations.
2) We did not address the in-dividual variations among subjects
(We have developed systematic methods to handle the issue, and a separate paper is under preparation)",No,N/A,Yes,A little hard to follow.,,Yannick,[TBD],,Li2017
,Deep Learning Representation from Electroencephalography of Early-Stage Creutzfeldt-Jakob Disease and Features for Differentiation from Rapidly Progressive Dementia,2017,"Morabito, Campolo, Mammone, Versaci, Franceschetti, Tagliavini, Sofia, Fatuzzo, Gambardella, Labate, Mumoli, Tripodi, Gasparini, Cianci, Sueri, Ferlazzo & Aguglia",International Journal of Neural Systems,No,"University Mediterranea of Reggio Calabria, Italy
Neurologic Institute “Carlo Besta”, Milan, Italy
Institute of Neurology, University of Catania, Italy
Magna Græcia University, Catanzaro, Italy
Bianchi-Melacrino-Morelli Hospital Reggio Calabria",15,,Classification of EEG signals,Clinical,Dementia,,Novel Approach,"Use DL for Creutzfeldt-Jakob Disease.
3 binary classifications on 4 classes using SAE+MLP",EEG Recording of Patients with different diagnosis related to Creutzfeldt-Jakob.,"Hierarchical network models, such as the DL transform observed variables (input of the procedure) in latent variables, which express both the relevant aspects of the given data and the underlying feature-generation process.",,N/M,No,"Raw EEG
(looking for changes in time-freq power)",Internal Recordings,Private,76,19,N/M,N/M,,,"1) High-pass filter: 0.5Hz
2) Low-pass filter: 70Hz
3) Notch filter: 50Hz
4) Visual Inspection and removal of artifacts
5) Windows of 5s",Yes,"Time-Frequency 
(CWT)",Frequency-domain,N/M,,"Matlab
NeuralWorks Professional II Plus, NeuralWare","Stacked AE
+ MLP or SVM",AE,"Contractive Encodings (?)
AE reducing features to 20 ""super features"" in an unsupervised fashion","Although the averaging step reduces the impact of local (time) distribution of frequencies, so partially limiting the usefulness of the same time-freq analysis, the availability of the three estimated statistical quantities gives synthetic information on the underlying probabilistic distribution.",Yes,"12 x 19
(Features x Channels)","SAE: 2
FC: 2 ",Sigmoid,L2,,,"2
(3x Binary Comp. for 4 classes)
",N/M,"1) SAE (Unsupervised)
2) Fine-tune for MLP on Top of Encoder (Supervised)",N/M,Annealing procedure for the learning rates that basically starts from high values (0.1) to reach very small values (0.01),N/M,Trial-and-Error,N/M,RMS,,Leave-one-out,"Train: 75%
Test: 25%",,"Accuracy
Sensitivity
Specificity","accuracy, sensitivity, sensibility",N/M,,N/M,"                                   Acc | Sens | Spec
CJD versus RPD:      89  |   92   |  89 
CJD versus AD:        88  |   94   |  85
CJD versus HC:        87  |   86   |  84","SVM (on top of AE)
                                   Acc | Sens | Spec
CJD versus RPD:      77  |   76   |  81 
CJD versus AD:        83  |   93   |  73
CJD versus HC:        76  |   74   |  72",Traditional pipeline,,N/M,"The unsupervised training of the auto-encoder has the additional advantage of simplifying the train- ing of the full DL scheme, since it moves the weights of the representation to a region more related to the actual inputs: in other words, the “gradient dilu- tion” effect, often met during training of deep many- layered NN, is largely reduced","1) One of the limitations of the presented DL approach is that the “super-features” identified as output of the two-layer auto-encoder are difficult to be used in clinical settings, being a nonlinear combination of averaged time-frequency quantities.
2) Small dataset",No,N/A,Yes,"It would be nice to have access to the dataset! 
Overall good paper, good description...",,Yannick,[TBD],,Morabito2017
,SGDR: Stochastic Gradient Descent with Warm Restarts,2017,Loshchilov & Hutter,International Conference on Learning Representations  2017,Yes,University of Freiburg,16,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use SGD with warm restarts to for 2-classes motor imagery classification,Motor imagery,Automatic feature learning,,N/M,No,None,N/M,Public,14,"N/M
(see dataset paper)","N/M
(see dataset paper)",14*1000,,,N/M,N/M,Raw EEG,Raw EEG,N/M,,Lasagne,CNN,CNN,N/M,Used same architecture as Schirrmeister et al. ,No,N/M,N/M,N/M,N/M,,,N/M,N/M,"When 30 epochs were considered, lr is dropped by a factor of 10 at epoch indexes 10, 15 and 20",SGD with warm restarts,lr=0.025 and 0.05,N/M,N/M,N/M,N/M,,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,Improvement of 1-2% and 2-3%,Schirrmeister et al.,DL,,No,SGDR provides a similar final performance w.r.t a budget proportional schedule while having a better anytime performance without defining the total budget of epochs beforehand,N/M,Yes,GitHub,No,This paper mostly provides an improvement to SGD and uses a 2-classes motor imagery in one of the experiments. Re-used the architecture of Schirrmeister et al. (people from the same university). ,,Isabela,[TBD],,Loshchilov2017
,Deep Learning Human Mind for Automated Visual Classification,2017,"Spampinato, Palazzo, Kavasidis, Giordano, Souly & Shah",IEEE Conference on Computer Vision and Pattern Recognition (CVPR),Yes,"PeRCeiVe Lab Viale Andrea Doria, Italy
University of Central Florida",9,,Classification of EEG signals,BCI,Reactive,RSVP,Novel Approach - Vision,"Identify Image Class from brain responses.
Using DL on EEG while watching images from ImageNet",Looking at Images from ImageNet while recording EEG,"Deep learning performs well for computer vision, but could we use the human brain instead, leveraging DL on EEG + Images",,"ActiCap
(Brainvision)",No,Raw EEG,Internal Recordings,Public,6,128,1000,"12,000",Offline,,"1) Notch filter: 49 - 51 Hz
2) Band-pass (2nd Order Butterworth): 14 - 71 Hz",No,"None
(Raw EEG)",Raw EEG,z-score,,"Torch
Caffe",LSTM + CNN,CNN+RNN,"Yes.
Combined network for: EEG + Image
2 classifications
(See Figure 2 for more details)","LSTM: Temporal Dynamics
CNN: To capture the Image features from both the Image and the EEG feature space (from LSTM)",Yes,"128x440
(channels x time)",(not clear),ReLU,N/M,,,"Not clear. 
Should be 40 classes (softmax)",N/M,"1) End-to-End
2) Deep feature extraction followed by regressor training",N/M,N/M,N/M,N/M,N/M,N/M,,N/M,"Train: 80%
Valid: 10%
Test: 10%",,"Accuracy
MSE","accuracy, MSE",NVidia Titan X,,N/M,"RNN Part: 83%
CNN Part: (Not clear, using MSE as metric)
Combined Part: 89%
(wtf, these can't be on 40 classes...) ","Kaneshiro et al., 2015  (29% over 12 classes)",DL,,No,"As future work, we plan a) to develop more complex deep learning approaches for distinguishing brain signals generated from a larger number of image classes, and b) to interpret/decode EEG-learned features in order to identify brain activation areas, band frequencies, and other relevant information necessary to uncover human neural underpinnings involved in the visual classification",N/M,Yes,Website,No,"Awesome webpage explaining the paper, access to the data, the code, the pretrained models... That's where we need to go as a field! 
The results can't be on 40 classes of images...",,Yannick,[TBD],,Spampinato2017
,Deep Learning Using EEG Data in Time and Frequency Domains for Sleep Stage Classification,2017,"Manzano, Guillén, Rojas & Herrera",Advances in Neural Networks – ISNN,,University of Granada,10,,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use CNN on Time domain and DNN on Frequency domain for Seep Stage classification on a single channel,Sleep (ongoing Polysomnography),Novel and interesting,,"N/M
(see dataset paper)",No,"Raw EEG
(Sleep)",UCDDB,Public,25,1,128,"20075 (total)
(173.2h; ~6.9h/subject)",Offline,,"1) Notch filter: 50Hz
2) High-pass filter: 0.3Hz
3) Downsampled to 64Hz",No,"(1) Raw EEG
(2) Frequencies",Raw EEG,N/M,,N/M,"1) CNN
2) NN",CNN,N/M,N/M,Yes,Not sure they mention it,"CNN: 2
FC: 1",N/M,"Dropout
(0.5)",5,Sleep Stages,5,N/M,N/M,N/M,LR: 0.01,512,Trial and Error,N/M,N/M,Inter,"Leave-one-out
(LOO)",N/M,,"Accuracy
F1-Measure","accuracy, f1-score",N/M,,N/M,"                                       Accuracy  |  F1-measure
Time domain:           68.6%   |   54% 
Frequency Domain:    68.9%   |   57.5%","Tsinalis et al., 2016 : 74%
Zhang et al., 2015 : 91%",DL,N/M,N/M,68.9% obtained in patient-cross-validation is considered very promising taking into account that it uses a single EEG channel with no more information,N/M,No,N/A,No,"Below other results, but mention that others are using more data, more chanels, etc. It makes it hard to compare, at least having all the results next to one another online will help. But even then, the leaderboard won't be perfect...",,Yannick,[TBD],,Manzano2017a
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Using Deep Neural Networks for Natural Saccade Classification from Electroencephalograms,2016,Drouin-Picaro & Falk,2016 IEEE EMBS International Student Conference (ISC),No,"INRS-EMT, Université du Québec",4,,Classification of EEG signals,BCI,,Detection,Improve state-of-the-art,Using CNN for saccade classification from EEG,Watching fragment of movies and observing images,Deep neural networks can learn more complex latent representation of the data,,"N/M
(see dataset paper)",No,Raw EEG,MAHNOB HCI-Tagging,Public,"N/M
(see dataset paper)",2,256,3000 for each class (4x3000 = 12000),Offline,,"1) Band-pass filter: 0.1-36Hz
2) Zero padding to produce samples with uniform length
3) Concatenate the two channels",No,Raw EEG (100ms before onset and 200ms after saccade offset),Raw EEG,N/M,,Pylearn2,"1) MLP
2) CNN",,N/M,N/M,No,N/M,"CNN: 2
MLP: 5",N/M,Dropout,4,"Left, right, up, and down",N/M,N/M,Standard optimization,N/M,[see paper],N/M,Grid search,Oversampling minority vertical saccades to balance classes,N/M,Inter-subject,N/M,"Train: 80%
Validation: 10%
Test: 10% ",,"Accuracy, kappa coefficient","accuracy, Cohen's kappa",N/M,,N/M,"CNN: 70.94%, 0.6127
MLP: 72.92%, 0.6398 ","Baseline 1: 51.80%, 0.3576
Baseline 2: 50.72%, 0.3437",Traditional pipeline,N/M,N/M,"""Despite the lower performances achieved relative to previously-published results with controlled datasets, our features greatly outperformed the benchmark ones, thus showing their power in realistic scenarios.""",The dataset was no collect with the focus on saccade analysis,No,N/A,No,MLPs were better in classying horizontal saccades while CNN presented better performance for vertical saccades,,Isabela,,,drouin2016using
,EEG-based prediction of driver's cognitive performance by deep convolutional neural network,2016,"Hajinoroozi, Mao, Jung, Lin & Huang",Signal Processing: Image Communication,,"University of Texas at San Antonio
UCSD
National Chiao Tung University",,,Classification of EEG signals,Monitoring,Cognitive,Fatigue,"New Approach: CCNN & CCNN-R
CCNN:      Channel-wise CNN
CCNN-R:  Channel-wise CNN + RBM",,Driving Simulation,,,Neuroscan EEG Headset (30 channels),,Raw EEG,Internal Recordings,Private,37,30,250,"Good Driving: 35 000
Bad Driving: 25 000",,,"1) Downsampled to 250Hz
2) Band-Pass filter (FIR): 1-50Hz",,"1) Raw EEG (30 channels)
2) ICAs (30 ICs)",Raw EEG,,,"Caffe, MATLAB","CCNN
CCNN-R",CNN,"Activation Function: Sigmoid
Kernel Size (conv): 1x250",,Yes,[read me again],"1 Conv
2 FC",,,,,[read me again],N/M*,,"CCNN: Drop-out 50%
CCNN-R: Drop-out 90%",,,,No,N/M*,Both,,,,AUC,AUC,,,N/M*,"[Within-subject] CCNN: 86.08%      |      CCNN-R: 80.67%
[Cross-subject] CCNN: 63.39%      |      CCNN-R: 76.72%","LDA, SVM, PCA+LDA, PCA+SVM, PSD SVM, PCA+DNN, CSP+DNN, XDAWN+DNN, DNN, CNN",DL & Trad.,,,,,No,N/A,No,,,Yannick,[TBD],,Hajinoroozi2016
,Wearable seizure detection using convolutional neural networks with transfer learning,2016,"Page, Shea & Mohsenin",IEEE International Symposion on Circuits and Systems,,"University of Maryland, Baltimore County (UMBC)",4,,Classification of EEG signals,Clinical,Epilepsy,Prediction,Improve state-of-the-art,Using CNN for seizure prediction,Seizure detection,Exploring Max-Pooling CNN with end-to-end training for seizure prediction and measure computer power required. (to make low power devices),,"N/M
(see dataset paper)",No,Seizures,CHB-MIT,Public,23,23,256,"N/M
(see dataset)",,,"1) Downsampling to 64Hz
2) Filtering Line Noise (freq N/M)",No,Raw EEG,Raw EEG,N/A,,N/M,CNN,CNN,Max Pooling,N/M,No,"N/M

15s time windows 
(raw EEG)","CNN: [1-3]
FC: [1-3]",N/M,Dropout,,,"1
(Softmax)",N/M,"For HM: Secondly, during training only the last 1-2 fully connected layers’ weights are adjusted",N/M,N/M,"Yes
(# N/M)",Random Hyperparam selection,Randomly mirroring left-to-right channel and adding Gaussian noise,N/M,,"GM: Leave-one-patient-out
PM: Leave-one-record-out
HM: Leave-one-record-out","Train: 75%
Test: 25%",,"Onset Sensitivity
False Alarm Rate
Latency","sensitivity, false positive rate",NVIDIA Jetson TK1,,N/M,"GM: [AUC] 0.926 | [FAR] 9 /day | [Onset Sens.] Failed for 3 subjects
PM: [AUC] 0.946 | [FAR] 6 /day | [Onset Sens.] 100%
HM: [AUC] 0.967 | [FAR] 3 /day | [Onset Sens.] 100%","Nothing external. Only their own approaches:
PM vs GM vs HM",Traditional pipeline,,N/M,The plots reveal that HM generally requires less training data to perform well and with less variance.,N/M,No,N/A,Yes,"Transfer learning, but within the same dataset. Would have been nice to see across datasets...",,Yannick,[TBD],,Page2016
,Learning robust features using deep learning for automatic seizure detection,2016,"Thodoroff, Pineau & Lim",1st Machine Learning for Healthcare Conference,Yes,"McGill, UofT",,,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach: Using a Recurrent CNN with Image Based Features. (based on Bashivan et al. (2016) model),"Using Recurrent CNN on images (RGB 16x16 pixel, reprensenting spatial & frequency) for Epilepsy",Seizure detection,Using Bashivan et al. (2016) approach for epilepsy,,"N/M
(see dataset paper)",No,Seizures,CHB-MIT,Public,22,23,256,"N/M
(see dataset)",, ,"1) 3D Coordinates to 2D (Polar Projection)
2) FFT for 3 Freq Bands",,"3 Frequency Bands to RGB 16x16 pixels
(0-7Hz, 7-14Hz, 14-49Hz)
Bashivan et al. (2016)",Frequency-domain,N/A,,N/M,CNN-R,CNN,Recurrent convolutional neural network using image-based representation of EEG,"3D Electodes to 2D Plan
3 Frequency Bands to R,G,B",Yes,"3x16x16
(RGB Image 16x16 pixel)","CNN: 4
LSTM: 128 HU
FC: 1 (512 HU)",N/M,N/A,,,1,N/M,"Pre-training
1) Trained CNN Layers alone
2) Then trained full network
3) Using transfer learning, train on a specific subject
4) Use Ensemble with 3 identical network with different initialization",RMSProp,"Dropout = False
LR = 0.001",128,Sampled uniformly randomly over the hyper-parameter space to optimize the parameters of the model,Subsampling majority class to balance classes,N/M,,Leave-one-out,N/A,,"Sensitivity
False Positive","sensitivity, false positives",N/M,,N/M,"Avg. Sensitivity: 85%
False Positive: 0.8/h","Patient Specific: Shoeb (2009) detector
Across Patients: REVEAL (Wilson et al., 2004)
REVEAL is a commercial algo",Traditional pipeline,,N/M,"Another advantage of this architecture lies in its ability to detect where a seizure is happening in the brain. Indeed, by occluding part of the image and testing the model’s ability to predict the correct label we can define which area of the brain is responsible for the activation.
However, our neural model turns out to be significantly more robust to missing channel as observed in Figure 6.","Amount of Data and Seizures
(despite using the largest publci dataset)",No,N/A,Yes,"Nice description of Epilepsy
Nice Graphs
Compared with results from 2009...
I'm he could have compared with more recent",,Yannick,[TBD],,Thodoroff2016
,Single-trial EEG RSVP classification using convolutional neural networks,2016,"Shamwell, Lee, Kwon, Marathe, Lawhern & Nothwang","Proc. SPIE 9836, Micro- and Nanotechnology Sensors, Systems and Applications",,"Army Research Laboratory, USA",10,,Classification of EEG signals,BCI,Active,RSVP,Improve state-of-the-art,Using CNN for Single-Trial RSVP from raw EEG,RSVP blocks of 5 images and the participant press a button if an image is part of a specific class,"Low SNR + High Dimensionality, Deep Learning with Large Dataset can find patterns. As opposed to pre-defined ones.",,Biosemi,No,"Raw EEG
(RSVP)",Internal Recordings,Private,18,"64
(out of 256)",1024,N/M,,,"1) Downsampled to 256Hz
2) Bandpass filter: 0.5 - 50Hz",No,None,Raw EEG,N/M,,N/M,CNN,CNN,Local response normalization (LRN) layers are included after each convolutional layer to normalize each layer’s filter responses.,"1) The first layer was thus chosen to span a 250 ms window to allow the network to learn feature maps over an extended temporal window
2) 2nd conv layer is another a temporal filter
3) 3rd conv layer computes spatial filters across
4) Final conv layer is a filter over the spatiotemporal responses",Yes,"250ms window
(raw EEG)","CNN: 4
FC: 2",ReLU,Dropout,,,"2
(softmax)",N/M,"We followed (Krizhevsky et al., 2012) by monitoring the network loss and lowering the learning rate whenever the loss began to flatten. However we instead lowered the learning rate by a factor of 5 instead of 10.",SGD,LR,N/M,,Downsampling majority non-target class to balance classes,Cross-Entropy,,N/M,"Train: 50%
Test: 50%

First half of the experiment for all subjects / second half for all subjects.",,AUC,AUC,N/M,,N/M,AUC: 0.7252,"CSP: 0.6261 *
HDCA: 0.66 *
XD+BLDA: 0.7151 *
CNN: 0.7252

* Trained and Tested per subject, not across subjects.",DL & Trad.,,Yes,"We found that stochastic gradient descent (SGD) does not perform well with class imbalances. With greatly imbalanced numbers of target and non-target, SGD may result in the network learning the distribution over the number of targets versus non-targets rather than the true desired distribution over targets versus non-targets.",N/M,No,N/A,No,-,,Yannick,[TBD],,Shamwell2016
,Affective states classification using EEG and semi-supervised deep learning approaches,2016,"Xu, Plataniotis",18th IEEE International Workshop on Multimedia Signal Processing (MMSP),,University of Toronto,,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve state-of-the-art,,Affective States (Arousal/Valence/Liking) on DEAP,,,N/M*,,PSD,DEAP,Public,32,32,512Hz,N/M*,,,"1) Re-reference: Common Average.
2) Downsampled to 256Hz
3) Band-Pass filter: 4-45Hz",,"PSD
15 narrow-bands",Frequency-domain,,,N/M*,"SDAE
BDN",AE,[read comments],,Yes,"480x1
(32 channels x 15 bands)","SDAE: 2
BDN: 3",,,,,3 (softmax),N/M*,,N/M*,,,,No,"SDAE: RMSE
BDN: Cross-Entropy",Intra,5:1 Training:Validation,,,"Accuracy
f1 score","accuracy, f1-score",,,N/M*,"[Arousal]  DBN: 86.67%   |   SDAE: ~81% 
[Valence]  DBN: 86.60%   |   SDAE: ~82% 
[Liking States]  DBN: 86.69%   |   SDAE: ~81% ",SVM,Traditional pipeline,,,[...] With only less than 15% of the input data were labeled,,No,N/A,No,,,Yannick,[TBD],,Xu2016
,Automatic Sleep Stage Scoring with Single-Channel EEG Using Convolutional Neural Networks,2016,"Tsinalis, Matthews, Guo, Zafeiriou",Arxiv,Yes,Imperial College London,12,,Classification of EEG signals,Clinical,Sleep,Staging,Improve state-of-the-art,Automatic sleep scoring using single channel EEG,Sleep (PSG),,,N/M*,No,Raw EEG,Sleep EDF,Public,20,1,100Hz,N/M*,,,None,,Raw EEG,Raw EEG,N/M,,Theano+Lasagne,CNN,CNN,Stacking (reshaping) layer between 1st and 2nd conv layer ,N/M,Yes,15000x1,"Conv: 2
FC: 2
Stacking: 1 ",ReLU,L2,,,5 (softmax),N/M,N/M,SGD,N/M,N/M,N/M,N/M,Categorical cross-entropy,,20-fold,"Train: 19 subjects
Test: 1 subject",,"Overal accuracy 
Per-stage accuracy 
F1-score
Precision
Sensitivity","accuracy, f1-score, precision, sensitivity",N/M,,N/M,"Stage N3 presented highest accuracy (~90%).
When comparing to the baselines, there is not much improvement in terms of accuracy, sensitivity, and precision.
",Previous work (CNN with Morlet wavelets as input and stacked autoencoder with hand-engineered features as input),DL,,Yes,"""However, we observe that the 95% confidence intervals across subjects
overlap across the three models, across almost all of
the metrics"". 
""[...] hand-engineering of features based on the AASM manual (SAE model) may have better performance than automatic filter learning (CNN model)"".",,No,N/A,No,"Paper is nice (cool analysis of learned parameters), but proposed method doesn't bring too much novelty or improvement to SOTA obtained by the same group.",,Isabela,[TBD],,[TBD]
,Mental State Recognition via Wearable EEG,2016,"Bashivan, Rish & Heisig",Arxiv,Yes,University of Memphis,10,,Classification of EEG signals,Monitoring,Cognitive vs. Affective,,Proof-of-concept,Monitor mental states using a wearable device,EEG recording while subjects watched movies,,,Muse,No,Raw EEG,Internal Recordings,Private,13,4,220Hz,N/M,,,None,Yes,Spectral power and connectivity (correlation between power in different bands),Frequency-domain,N/M,,N/M,DBN,DBN,-,N/M,No,N/M*,3,N/M,L1,,,2 (softmax),N/M, Parameters of each layer of DBN were greedily pre-trained,SGD,N/M,N/M,N/M,N/M,N/M,,"2-fold
Leave-one subject-out (13-fold)",N/M,,"False-negative rate
False-positive rate
Combined error rates","false negative rate, false positive rate, combined error rates",N/M,,N/M,"Intra-subject: SVM was the best (FPR: 31.5%, FNR:
19.8%)
Inter-suject: DBN (FPR:38.3%, FNR:6.2%) and LR (FPR: 27.9%, FNR: 23.3%) were the best.","Logistic regression, SVM, Random Forest",Traditional pipeline,,No,"Surprisingly, the logistic regression model preferred connectivity features instead of spectral ones. ",N/M,No,N/A,No,Paper is very preliminar. The focus is more in showing that it is possible to classify mental states with data from a wearable devices than in neural networks. Discussion and analysis focused on feature engineering aspects.,,Isabela,[TBD],,Bashivan2016b
,Neural networks based EEG-Speech Models,2016,Sun & Qin,Arxiv,Yes,Southern Illinois University Carbondale,10,,Classification of EEG signals,BCI,Active,Speech decoding,Novel Approach - Speech,Classify Speech from EEG,"3 modalities (EEG, face tracking, and audio) during imagined and vocalized phonemic and single-word prompts. Looking a the monitor, participants were asked to do the phonemes as instructed. (imagined and/or spoken)",To better model the non-linearity between the brain signals and speech,,Neuroscan Quick-Cap,No,Speech,KARA ONE,Public,14,64,N/M,132 / participant,,,"1) ICA for ocular artifacts
2) Band-pass filter: 1 - 200 Hz
3) Mean value substracted for the signal
4) Epoched
5) Normalized",Yes,"None
(Raw EEG)",Raw EEG,z-score,,Matlab,"1) NES-I
2) NES-B
3) NES-G
(RBM based models)",RBM,"(read paper for more info, lots of maths)","(read paper for more info, lots of maths)",No,"62/10 x ?

They try with 62 and 10 channels",(not clear),Sigmoid,N/M,,,"2 or 11
(softmax)",N/M,N/M,"N/M
(but has momentum, wd, lr)","Weigh Decay: 0.0001
LR: 0.1
Momentum: 0.5",2000,N/M,N/M,N/M,,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"Binary Classif : C/V | Nasal | Bilab | /iy | /uw/      
               INES: 0.25 | 0.47 | 0.53 | 0.53 | 0.74 
        IANES-B: 0.27 | 0.59 | 0.52 | 0.62 | 0.78
        IANES-G: 0.41 | 0.74 | 0.71 | 0.76 | 0.87
[All Phonemes] Mean Accuracy: 41.5%  (11 classes!)","SVM: 0.18 | 0.64 | 0.57 | 0.59 | 0.79   (Zhao et al., 2015)
DBN: 0.87 |  − −  |  − −  |  − −  | 0.82   (Zhao et al., 2015)",DL & Trad.,,No,"The EEG based speech classification results indicate that the proposed NES models outperform a baseline method SVMmulti for 11 phonological categories. In the binary classification task, the proposed NES-G model overall achieves the best performance than nonlinear SVM classifier.",N/M,No,N/A,No,Not super clear in term of the EEG signal -> input. (dimensionality wise),,Yannick,[TBD],,Sun2016
,Combining Generative and Discriminative Neural Networks for Sleep Stages Classification,2016,"Giri, Fanany & Arymurthy",Arxiv,Yes,"Universitas Indonesia
Bogor Agricultural University",13,,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use DBN + LSTM for sleep stage classification,Sleep,Combining the power of generative and discriminative DL models.,,N/M,No,Sleep Stages,"Benchmark Dataset (not clear);
MKG Dataset (can't find)",Public,"N/M

(10 night sleep)",N/M,N/M,N/M,,,"N/M

(probably same as Langkvist et al., 2012)","N/M

(probably same as Langkvist et al., 2012)","28 features

(Langkvist et al., 2012)",Other,N/M,,"Matlab
Python
Keras
Tensorflow",DBN + LSTM,RNN,-,The main idea is to fuse generative ability on DBN to extract multi-level hierarchical features and determine the final label of class prediction using the time series discrimination capability of LSTM.,Yes,28 Features,"DBN: 2
LSTM: 5",N/M,N/M,,,"5
(softmax)
(Sleep Stages)",N/M,"(Pre)Train DBN first, then LSTM",RMSProp,Epoch 100,500,N/M,N/M,Categorical Cross-Entropy,,Leave-one-out CV,"5:1

(I think that like many people, we confuse Validation and Test)",,"Accuracy
F1-Score","accuracy, f1-score","- (DBN) -
Intel i7-4700HQ
2.6 GHz
4 GB
- (LSTM) -
4x NVidia GTX Titan
128GB",,"Yes, nice explanation and graphs.
LSTM = Fast
DBN = Slow (17h on the full MKG dataset)","REM (99.63%) 
WAKE (98.64%)
SWS (98.27%)
S1 (98.24%)
S2 (97.69%)","[Internal]              DBN
[Internal]   DBN+HMM
[Internal]            LSTM
 [Internal]  DBN+LSTM*

Zhang et al., 2015 (supposed to be SOTA)  [External]",DL,,,"Our experiments showed that the combination of DBN with LSTM gives better overall accuracy 98.75% (Fscore=0.9875) for benchmark dataset and 98.94% (Fscore=0.9894) for MKG dataset. This result is better than the state of the art of sleep stages classification that was 91.31%.
From it, we can conclude DBN successfully boost the accuracy level for LSTM, because when the LSTM not using DBN, we only get the accuracy value on 0.636 (F-score 0.655). On the other hand, if we use only DBN the accuracy just 0.515.","Our model still needs input in the form of ”handcrafted” feature extraction procedure. On the other hand, the state of the art directly using raw data so that the flexibility of state of the art may be better than our proposed DBN+LSTM model.",No,N/A,No,"Nice description of the ""time"" to run these algos.",,Yannick,[TBD],,Giri2016
,Multimodal Emotion Recognition Using Multimodal Deep Learning,2016,"Liu, Zheng & Lu",International Conference on Neural Information Processing,Yes,Shanghai Jiao Tong University,7,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Use multimodal deep learning algorithms,Watching video clips,,,N/M,No,None,"DEAP;
SEED",Public,"32
15","32
62","1000Hz
250Hz",N/M*,,,"DEAP: same as DEAP paper
SEED: None",No,"None
PSD and differential entropy",Raw EEG,min-max,,N/M,AE,AE,"When eye-tracking data is available, a bi-modal AE was used",N/M,Yes,N/M,3,N/M,N/M,,,N/M,N/M,"First, a RBM was trained and its weights were used as initialization for the AE ",N/M,N/M,N/M,N/M,N/M,N/M,,N/M,N/M,,Accuracy ,accuracy,N/M,,N/M,"DEAP:  85.2% (valence), 80.5% (arousal), 84.9% (dominance), 82.4% (liking) 
SEED: 89.94%",Two previous works (didn't mentioned if those were SOTA),Traditional pipeline,,No,Using the bi-modal AE provided better results even when no eye-tracking data was available,N/M,No,N/A,No,I found the paper a bit confusing. Results are messy and apparently no cross-validation was used. ,,Isabela,[TBD],,Liu2016
,Interpretable Deep Neural Networks for Single-Trial EEG Classification,2016,"Sturm, Bach, Samek & Müller",Arxiv,Yes,"Berlin Institute of Technology
Fraunhofer Heinrich Hertz Institute
Korea University",5,,Improvement of processing tools,Model interpretability,Model visualization,,Novel Approach,Introducing Layer-wise Relevance Propagation (LRP) for DL-EEG (vizualisation),Demonstrated on the BCI-MI Competition III dataset IVa,"DNN are black boxes, but with this approach, we could see what features they are learning.",,"N/M
(see dataset paper)",No,Motor Imagery,BCI Competition III - IVa,Public,5+5,"N/M
(see dataset paper)","N/M
(see dataset paper)","N/M
(see dataset paper)",,,"1) Downsampled to 100Hz
2) Bandpass filter: 9-13Hz",No,"None
(Raw EEG)",Raw EEG,N/M,,N/M,DNN,NS,"(basic DNN, but the network itself is not relevant, the paper is about LPR)",N/M,No,"301x118
(time points x channels)",2,N/M,N/M,,,"2
(right/left hand)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,,Leave-one-out,N/M,,Accuracy,accuracy,N/M,,N/M,"Mean Accuracy: 71.6%  (DS #1)
Mean Accuracy: 78.2%  (DS #2)
(not very relevant as the paper is not about the model, but LPR)","CSP-LDA
(didn't do better on average, but did better on low performing subjects)",Traditional pipeline,,No,"For instance, this substantially increased classification accuracy in a subject with particularly low accuracy. This is a first hint that DNN technology may be beneficial for subject-to-subject transfer of learned neural rep- resentations, and, ultimately, may advance subject-independent zero training strategies in BCI [18].",N/M,No,N/A,No,"Didn't really explained the LPR. I will investigate more, but it seems quite interesting!",,Yannick,[TBD],,Sturm2016
,Ischemic stroke identification based on EEG and EOG using 1D convolutional neural network and batch normalization,2016,"Giri, Fanany, Arymurthy",IEEE International Conference on Advanced Computer Science and Information Systems ,Yes,"Bogor Agricultural University
Universitas Indonesia",8,,Classification of EEG signals,Clinical,Ischemic stroke,,Improve SOTA,Use DL for Stroke classification,On going EEG recording: Stroke Patients vs Healthy Patients,"Other ML approaches have been tried and show encouraging results, but yet nothing good enough to be used reliably",,Xltek & Biologic,No,"Lowering of Frequencies
(due to stroke)",Internal Recordings,Private,"32 Stroke
30 Healthy","EEG: 2 (out of 33)
EOG: 2",512 & 256,15 min / subject,,,1) Downsample to 64Hz,No,"24 Handcraft features
(relative power band frequency, variance, correlation aspect, kurtosis, entropy, spectral mean, and exponent of fractal)",Other,N/M,,"Keras, Theano, Python",1D CNN,CNN,Batch norm,1D conv. operation is useful to extract the important local feature in between neighbouring element value of feature vector.,Yes,"62x24
(? x Features)","1DCNN: 2
FC: 1",N/M,N/M,,,2,N/M,Early stopping,N/M,N/M,N/M,N/M,N/M,N/M,,Leave-one-out,N/M,,"Accuracy, Sensitivity, Specificity, F1-Score, Precision, Recall","accuracy, sensitivity, specificity, f1-score, precision, recall",Quad Core i7 CPU 2.4GHz with 4GB of RAM,,N/M,"Accuracy: 0.861, F1-Score: 0.861
Sensitivity: 0.861, Specificity: 0.865
Precision: 0.870, Recall: 0.861","NB, CT, RF, NN, kNN, Logreg",Traditional pipeline,,No,"In this study, we apply early stopping and Batch Normalization techniques to accelerate training process of our classification model. The results of the experiment show that deep learning approach IDCNN has managed to be the best model to distinguishing task between EEG stroke data to the EEG.",N/M,No,N/A,No,-,,Yannick,[TBD],,Giri2016a
,Deep convolutional neural networks for classification of mild cognitive impaired and Alzheimer's disease patients from scalp EEG recordings,2016,"Morabito, Campolo, Ieracitano, Ebadi, Bonanno, Bramanti, De Salvo, Mammone & Bramanti  ",2nd IEEE International Forum on Research and Technologies for Society and Industry Leveraging a better tomorrow,No,"Mediterranean University of Reggio Calabria
Chabahar Maritime University
Centro Neurolesi Bonino-Pulejo",6,,Classification of EEG signals,Clinical,Alzheimer's disease,,Extraction of features that can be used for Alzheimer's early diagnosis,Distinguish Alzheimer's disease from mild cognitive impairment and healty patients,Resting state,Latent feature learning + analysis of big amount of data,,N/M,No,None,Internal Recordings,Private,119,19,1024Hz,N/M*,,,"1) Notch at 50Hz
2) Band-pass 0.1-30Hz",No,Time-frequency representation,Frequency-domain,N/M,,N/M,"CNN
AE
MLP",CNN,N/A,N/M,Yes,228*,"Conv: 2
FC: 1",Sigmoid,N/M,,,3 (softmax),N/M,AE's bottleneck is used as input for the classification stage ,N/M,N/M,N/M,N/M,N/M,N/M,,4-fold,N/M,,"Accuracy
Sensitivity
Specificity","accuracy, sensitivity, specificity",N/M,,N/M,"AD-MCI-HC (acc, sens, spec): 82%, 83%, 75%
MCI-HC (acc, sens, spec): 85%, 84%, 81%
AD-HC (acc, sens, spec): 85%, 85%, 82%
MCI-AD (acc, sens, spec): 78%, 78%, 75%",No,None,,No,"As expected, the proposed model achieves better results when trying to disguinsh AD from healthy condition. Worst accuracy is obtained when classifying AD vs MCI ","""An ongoing effort is carried out within our research groups to generate a large database for both MCI and AD patients, also adding a similar number of HC.""",No,N/A,Yes,"There was no comparison with other methods, not even a linear model.",,Isabela,[TBD],,Morabito2016
,EEG Based Eye State Classification using Deep Belief Network and Stacked AutoEncoder,2016,"Narejo, Pasero & Kulsoom",International Journal of Electrical and Computer Engineering,No,"Politecnico Di Torino, University of Pavia",11,,Classification of EEG signals,Monitoring,Cognitive,Eyes closed/open,Improve SOTA,Classify eye movements with a DBN and SAE,"Eye movement (""state"") classification: eyes open vs. eyes closed",It works well on other stuff,,Emotiv,No,None,EEG Eye State,Public,1,14,128,1,,,?,Yes,Discrete Wavelet Transform,Frequency-domain,N/M,,N/M,"1. DBN
2. SAE",DBN,N/A,N/M,Yes,70,"1) 4
2) 4","1) Sigmoid
2) logsig and linear","1) N/M
2) L2 and ""sparsity regularization""",,,2,N/M,Layer-wise training,N/M,1) learning rate: 0.01,1) 2,N/M,N/M,1) cross-entropy for fine-tuning,,N/M,N/M,,"Accuracy
Sensitivity
Specificity","accuracy, sensitivity, specificity",N/M,,N/M,"DBN (acc, spec, sens): 97.1, 0.99, 0.89
SAE (acc, spec, sens): 98.9, 0.94, 0.99","LDA + SAE
K*+Regularized Random Forest
K*
Neuro-fuzzy",Traditional pipeline,,N/M,Next steps are implementing Denoising/Contrastive AEs.,N/M,No,N/A,No,"Basic paper, some missing information.",,Hubert,[TBD],,Narejo2016
,Removal of EOG artifacts from EEG using a cascade of sparse autoencoder and recursive least squares adaptive filter,2016,"Yang, Duan & Zhang",Neurocomputing,No,Shanghai University,8,,Improvement of processing tools,Signal cleaning,Artifact handling,,Novel approach from removing EOG artifacts,Remove EOG from EEG data,Motor imagery,Auto-encoders have shown to be able to extract powerful features from other modalities,,N/M,No,None,BCI Competition IV,Public,9,3,250,N/M,,,1) Band-pass 0.5-100 Hz,No,None,Raw EEG,min-max,,Matlab 2013,Sparse AE,AE,N/A,N/A,Yes,1000,3,N/M,Sparsity penalty,,,1000,N/M,Train sparse AE on EOG data (offline) and then use EEG data as input ,N/M,N/M,N/M,N/M,N/M,N/M,,N/M,N/M,,Accuracy,accuracy,"Intel Core i3-4130
CPU3.4 GHz processor, 3 GB RAM",,N/M,SAE+adaptive filter outperformed ICA by 8% and ICA+adaptive filter by 5.8%,"ICA
ICA+adaptive filter",Traditional pipeline,,No,"The proposed method performs better, is more efficient and need less to channels to work properly.",NM,No,N/A,No,The deep neural network here is used to learn a representation of EOG that is used to clean EEG,,Isabela,[TBD],,Yang2016a
,Recognition of Cognitive Task Load levels using single channel EEG and Stacked Denoising Autoencoder,2016,Yin & Zhang,Proceedings of the 35th chinese control conference,,University of Shanghai for Science and Technology,6,,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve SOTA,Use DL (sdAE) on single channel EEG for workload classification (low/high),Automation-Enhanced Cabin Air Management System (aCAMS),Deep architectures appear to be fit for representing stable higher-level abstractions,,N/M,No,Raw EEG,Internal Recordings,Private,8,11,500,"100 min / session
(2 sessions per subject)",,,"1) Band-pass 1.5 - 40 Hz
2) ICA for EOG Artifacts
3) 2s window
4) FFT for Freq Features",Yes,80 Power Features for each channel,Frequency-domain,N/M,,N/M,Stacked Denoising AE,AE,N/M,N/M,Yes,"80x1
(80 Freq Features)",5,Sigmoid,,,,"2
(High/Low CTL)",N/M,(Greedy Search for structure),N/M,N/M,N/M,Greedy Search,N/M,N/M,,N/M,N/M,,"Sensitivity, Specificity, Precision, Accuracy, Kappa, 
Negative Predictive Value","sensitivity, specificity, precision, accuracy, kappa, negative predictive value",N/M,,N/M,"Mean Accuracy: 0.7429 | Mean Kappa: 0.5418
Mean Sensitivity: 0.6104 | Mean Specificity: 0.8754
Mean Precision: 0.8236 | Mean NPV: 0.7070",N/M,None,,NM,NM,NM,No,N/A,No,"Average results, as it's to be expected with their own internal recordings on 8 subjects.",,Yannick,[TBD],,[TBD]
,Hand motion identification of grasp-and-lift task from electroencephalography recordings using recurrent neural networks,2016,An & Cho,IEEE International Conference on Big Data and Smart Computing,No,Seoul National University,3,,Classification of EEG signals,BCI,Active,Grasp and lift,Improve SOTA,Use RNNs for BCI classification (Grasp-and-Lift task),Grasp-and-Lift BCI,"DL gave rise to an end-to-end framework, incorporating automatic feature extraction",,"N/M
(see dataset paper)",No,Raw EEG,WAY-EEG-GAL,Public,12,32,500,298 trials per subjects,Offline,,1) Bandpass 1 - 30 Hz,No,None,Raw EEG,N/M,,N/M,"MUT
RNN from 
(Jozefowicz et al., 2015)",RNN,N/M,"For consistent and smooth predictions of phases during transitions, we used moving averages of predictions instead of using just the prediction for one point",Yes,32,"RNN: 2
FC: 1",N/M,Dropout,6,"Idle
Reach
Load and reach
Load and Hold
Load and retract
Retract","6
(softmax)",N/M,Standard optimization,N/M,N/M,N/M,N/M,N/M,N/M,Intra,N/M,"Train: 200
Valid: 44
Test: 54",,Accuracy,accuracy,N/M,,N/M,"LSTM  |  GRU  |  MUT1  |  MUT2  |  MUT3
87.98% | 88.6% | 86.54% | 88.21% | 88.82%","LSTM, GRU, MUT1, MUT2, MUT3",DL,No,N/M,"Dropout improved performance of RNNs by an average of 4 percentage point. Smoothing the predictions with moving average helped making consistent
predictions, eliminating abrupt and incongruous prediction errors.",N/M,No,N/A,No,"Short paper, but most important infomation is there...",,Yannick,Hubert,,An2016
,Decoding EEG and LFP signals using deep learning: heading TrueNorth,2016,"Nurse, Mashford, Yepes, Kiral-Kornek, Harrer & Freestone",ACM International Conference on Computing Frontiers,No,"University of Melbourne, IBM Research Australia",8,,Improvement of processing tools,Hardware optimization,Neuromorphic chips,,Improve SOTA,Performing decoding on a neuromorphic chip,"Self-paced hand squeeze task, left vs. right",Learns on its own a good description,,SynAmps2,No,None,Internal Recordings,Public,1 (picked out of 5),46,1000,1109,,,"1) Bandpass 0.1-100 Hz
2) Notch filter @50 Hz
3) Downsample to 250 Hz",Yes?,None,Raw EEG,N/M,,Caffe,CNN,CNN,N/A,N/M,Yes,46 x 46,3,N/M,N/M,,,2,N/M,Standard optimization,Stochastic gradient descent,learning rate: 0.01,N/M,N/M,N/M,N/M,,N/M,"Train: 86.9%
Validation: 13.1%",,Accuracy,accuracy,TrueNorth,,N/M,76%,"N/M
(previous paper on same dataset: 86%)",None,,Visualization of learned filters,"Accuracy not as good as previous paper, but there was extensive hyperparams search in previous paper.
Need more data and training.",Not enough data,No,N/A,Yes,"The DL side is a bit limited, as if they decided their first try was good enough?",,Hubert,[TBD],,Nurse2016
,A novel deep learning approach for classifcation of EEG motor imagery signals,2016,Tabar & Halici,Journal of Neural Engineering,,"Middle East Technical University, Ankara, Turkey",11,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,"Exploring CNN, SAE & Combined CNN-SAE on BCI-MI Datasets",Motor Imagery (BCI Competition datasets),"""deep learning methods are known to provide better classification performance by increasing the size of training data""",,"N/M
(see dataset paper)",No,Motor Imagery,"BCI Competition II - III;
BCI Competition IV - IIb",Public,"1) 1
2) 9",3,"1) 128
2) 250","1) 280
2) 400",,,"Short time Fourier transform (STFT)
Extracted: 6-13Hz and 17-30Hz",No,"Frequencies
6-13Hz & 17-30Hz",Frequency-domain,N/M,,"Matlab
Deep Learning Toolbox","1) CNN
2) SAE
3) CNN + SAE",CNN,"1D Filters
Max pooling","In our data, frequency, time and electrode 
location information are used together",Yes,"93x32
31 (freq) x 3 (channels) 
x 32 (time)","CNN: 1
SAE: 6
FC: 2",ReLU,N/M,,,2,N/M,"Each AE layer is trained separately in an unsupervised manner. After this pre-training step, supervised fine-tuning step is applied to the whole network",N/M,N/M,50,N/M,N/M,N/M,,"10x10 Cross-Validation
(10-Fold CV on 10 Subjects)","Train: 90%
Test: 10%",,"Kappa
Accuracy","Cohen's kappa, accuracy",4.00 GHz Core i7 PC with 16 GB of RAM,,1157s,"[DS #1] CNN: 72.4 | SAE: 70.3 | CNN-SAE: 75.1  (Accuracy)
[DS #2] CNN: 89.3 | SAE: 60.0 | CNN-SAE 90.0  (Accuracy)
[DS #2] (Lemm et al., 2004): 89.3 | (Ren et al., 2014): 88.2 (Accuracy)
[DS #2] CNN: 0.786 | SAE: 0.20 | CNN-SAE 0.80  (Kappa)
[DS #2] (Lemm et al., 2004): 0.783 | (Ren et al., 2014): 0.764 (Kappa)","(Lemm et al., 2004) - Winner of Competition
(Ren et al., 2014) - DL
",DL & Trad.,,Filters learned in CNN takes into account the activation in the neighboring regions but CNN does not provide any information on which filter contributes to classification performance more than the others.,"(1) We designed a new input form by using time, frequency and location information of EEG signals. (2) To our knowledge, our approach yields the best accuracy performance on BCI competition IV dataset 2b. The accuracy result of the CNN-SAE on dataset III is 90.0% that is higher than the winner algorithm. (3) The effect of filter size was investigated and Nh × 3 filter yielded the best perf. Also, the best value for epoch size was found as 300.",The result of our proposed system can be improved by using large datasets in such BCI system. We used only one convolution and one pooling layer. The performance may be increased if further convolution-pooling layers are used.,No,N/A,Yes,Seems reproducable. Nothing too fancy. Public data.,,Yannick,[TBD],,[TBD]
,Semi-automated Annotation of Signal Events in Clinical EEG Data,2016,"Yang, Lopex, Golmohammadi, Obeid & Picone",IEEE Signal Processing in Medicine and Biology Symposium,No,Temple University,5,,Classification of EEG signals,Clinical,Epilepsy,Event annotation,New Approach,To developed a self-training approach to iteratively annotate a large EEG corpus,Epilepsy data (ongoing EEG),To explore semi-supervised learning methods such as self-training [3] and active learning [4].,,N/M,No,Seizures,TUH,Public,"N/M
(see dataset info)","N/M
(see dataset info)","N/M
(see dataset info)","N/M
(see dataset info)",,,"See Harati et al., 2015 
(their previous paper)","(Harati et al., 2015)","See Harati et al., 2015 
(their previous paper)",NS,N/M,,N/M,"See Harati et al., 2015 
(their previous paper)",NS,"See Harati et al., 2015 
(their previous paper)","See Harati et al., 2015 
(their previous paper)",Yes,"See Harati et al., 2015 
(their previous paper)","See Harati et al., 2015 
(their previous paper)",N/M,"See Harati et al., 2015 
(their previous paper)",6,"Spike and/or sharp waves
Periodic lateralized epileptiform discharges
Generalized periodic epileptiform discharges
Artifacts
Eye movements
Background","See Harati et al., 2015 
(their previous paper)","See Harati et al., 2015 
(their previous paper)","The whole paper is kinda about ""training"" in the sense that they are training/retraining on the data until they get high level of confidence.","See Harati et al., 2015 
(their previous paper)",N/M,N/M,N/M,"Yes, the whole paper is kinda about data augmentation in the sense that they are training/retraining on the data until they get high level of confidence.",N/M,,N/M,N/M,,Sensitivity,sensitivitiy,N/M,,N/M,"GPED: 52.8% ->  56.5%
PLED: 54.2%  60.4%
SPSW: 41.6%  49.6%
EYEM: 81.8% -> 82.1%
BCKG: 72.1% -> 71.2%
ARTF: 41.2% -> 39.1%","Before and After
(no benchmark)",None,,N/M,"The proposed method is based on a limited amount of manually annotated data and updates the training models by iteratively re-training and re-decoding. This pilot study shows after a few iterations we are able to not only label more EEG signals (about 30,000 new SPSW labels) but also improve recognition accuracy about 2%.",Number of label samples,No,N/A,No,"Very different paper. Using a previous DL model (Harati et al., 2015) this paper is all about self-training to automatically label the data.",,Yannick,[TBD],,Yang2016b
,Learning representations from EEG with deep recurrent-convolutional neural networks,2016,"Bashivan, Rish, Yeason & Codella",International Conference on Learning Representations 2016,Yes,University of Memphis,15,,Improvement of processing tools,Feature learning,,,Finding robust (inter-subject) representations from EEG data,Map EEG time-series to images and use CNNs as they work well for image classification ,Mental load (working memory) levels,CNNs presented good results for image classification,,N/M,No,None,Internal Recordings,Private,13,64,500Hz,3120*,,,"Mapping of EEG time series to images (spectral topography maps).
1) Calculate PSD on theta, alpha, beta
2) Project electrodes 3D position to a 2D mesh
3) Using each frequency band as a color channel, plot PSD as color intensity",,EEG spectral topography maps ,Frequency-domain,N/M,,Theano+Lasagne,"Single frame: CNN with different kernel sizes 
Multi-frame: A,B) CNN
 C,D) CNN+LSTM",CNN,"A) Max-pooling across time frames
B) Temporal convolution (1D conv in time)
C) LSTM 
D) Temporal convolution + LSTM",,Yes,"Single-frame: 32 x 32 x 3
Multi-frame: #frames x 32 x 32 x 3","Conv: 7
LSTM: 2
FC: 1",Sigmoid*,"50% dropout on FC layers
Early stopping",,,4,10k - 1.62 million,Standard,Adam,"lr=0.001
Beta1 = 0.9
Beta2 = 0.999",20,N/M,"Randomly adding noise to feature image input
Did not improve results",Categorical cross-entropy,,Leave-subject-out,"Train/Valid: 12 subjects (randomly selected samples from this set for validation)
Test: 1 subject",,Test error,test error,N/M,,N/M,"Single-frame: best model (D) improved 0.8% w.r.t. best baseline (DBN)
Multi-frames: best model (D) improved ~6% w.r.t. best baseline (DBN)","SVM, Random Forest, Logisitic regression, Deep belief network",DL & Trad.,,Yes,"""When trained on a pool of data containing multiple individuals, the network extracts features that are maximally informative considering the variability in the training set.""",,Yes,GitHub,Yes,This paper is really nice. The scheme for mapping EEG time-series to image was applied in many posterior works.,,Isabela,[TBD],,Bashivan2016a
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Investigating Critical Frequency Bands and Channels for EEG-Based Emotion Recognition with Deep Neural Networks,2015,Zheng & Lu,IEEE Transactions on Autonomous Mental Development,,Shanghai Jiao Tong University,14,,Classification of EEG signals,Monitoring,Affective,Emotion,New approach,"Using DBN to classify emotions (Positive / Neutral / Negative)
And exploring the relevant frequencies and channels",Watching Movies (emotions),Semi-Supervised DBN can learn from unlabeled data,,NeuroScan System,No,Differential Entropy from multichannel EEG,Internal Recordings,Public,15,62,1000,"3300 x 1s epochs per exp.
2 exp. / subject

(6600 epochs total)",Offline,,"1) Downsampled to 200Hz
2) VI: EMG (too much) contamined channels removed
3) Band-Pass filter: 0.3-50Hz
4) Epoching (lenght of a movie)",Yes,"Differential Entropy (DE)
DASM, RASM",Other,N/M,,MATLAB,BDN,DBN,N/M,To leverage unlabeled data with unsupervised learning,No,"not clear
(the features)",2,Sigmoid,N/M,3,"Positive
Neutral
Negative",3,N/M,"1) unsupervised pretraining of each layer; (greedy layer-wise)
2) unsupervised fine-tuning of all layers with backpropagation; 
3) supervised fine-tuning of all layers with backpropagation",N/M,"Momentum: 0.1
LR (Unsup): 0.5
LR (Sup): 0.6",201,search optimal number of neurons at the first and second layer in the ranges [200:500] and [150:500] with step of 50,N/M,N/M,Intra,N/M,"Train: 9 sessions
Test: 6 sessions",,Accuracy,accuracy,N/M,,N/M,"Mean Accuracy: 86.08%

Lots of results reported (for each feature categories)
(see paper for full details)","Mean Accuracy

KNN: 72.60%
LR: 82.70%
SVM: 83.99%",Traditional pipeline,No,"Yes
Frequencies and Electrodes 
contributing.","(1) Given that DBNs can also learn models in an unsupervised way, the large amounts of unlabeled EEG data may also be conductive to the semi-supervised DBN training paradigm and allow it to learn more sophisticated models than other traditional supervised learners. (2) There is still a lack of publicly available emotional EEG datasets. (3) In our studies, we propose a novel critical channels and frequency bands selection method through the weight distributions learned by deep belief networks.",Emotion Classes is limited to 3 in the study,No,N/A,Yes,"They acknowledge the lack of public datasets for EEG emotions, and they shared their data <3",,Yannick,[TBD],,Zheng2015
,Deep feature learning for EEG recordings,2015,"Stober, Sternin, Owen & Grahn",Arxiv,Yes,University of Western Ontario,24,,Improvement of processing tools,Feature learning,,,Improve SOTA,Automatic feature learning using autoencoders,Music listening or imagery,Use of deep learning achieved good results in other domains ,,BioSemi Active-Two,No,None,OpenMIIR dataset,Public,10,66,512,60 trials/sub,Offline,,"1) Removed and interpolated bad EEG channels
2) Bandpass: 0.5-30 Hz",Yes,Raw EEG,Raw EEG,"[-1,1] 
0 mean",,Theano+Pylearn,Autoencoders,AE,N/M,N/M,No,N/M,N/M,Sigmoid,"Dropout, L1",12,12 music styles (see Table 2),12,N/M,Standard,SGD,N/M,128,Bayesian optimization,N/M,Hinge loss,Inter-subject,9-fold,"Train: 8 subs
Valid: 1 sub
Test: 3rd block of each sub",,Accuracy,accuracy,N/M,,N/M,"SVM: 14.8%, CNN: 18.5%, 26.9%
SVM: 14.8%, CNN: 18.5%, 19.4% 
SVM: 17.6%, CNN: 17.6%, 18.5% 
SVM: 19.4%, CNN: 20.4%, 20.4%
SVM: 16.7%, CNN: 20.4%, 19.4%
SVM: 23.1%, CNN: 23.1%, 22.2%
SVM 20.4%, CNN: 22.2%, 22.2%
SVM: 20.4%, CNN: 25.0%, 27.8%
SVM: 24.1%, CNN: 20.4%, 18.5%
SVM: 22.2%, CNN: 22.2%, 23.1%
SVM: 23.1%, CNN: 27.8%, 26.9%",SVM,Traditional pipeline,"Yes ( Significance values were determined by using the cumulative binomial distribution to estimate the likelihood of observing
a given classification rate by chance)",Yes (visualization of learned convolutional filters),"CNNs outperformed or were equally good as SVM for 10/11 cases. 
""Learned features are
also still simple enough to allow interpretation by domain experts such as cognitive neuroscientists."" ",N/M,Yes,GitHub,No,"The paper is very relevant as they focus on learning good features for different trials. However, I find it a little bit disorganized. One good point about the paper is that they analyzed whether the cost of using high-sampling rate EEG is worth. ",,Isabela,[TBD],,Stober2015
,Convolutional neural network for multi-category rapid serial visual presentation BCI,2015,Manor & Geva,Frontiers in Computational Neuroscience,,Ben-Gurion University,12,,Classification of EEG signals,BCI,Reactive,RSVP,New approach,New spatio-temporal regularization for CNN on RSVP (or P300) BCI,RSVP (5 classes of images),Deep neural networks have shown state of the art performance in computer vision and speech recognition and thus have great promise for other learning tasks.,,BioSemi Active-Two,No,ERPs (P300),"Internal Recordings;
BCI Competition III - IIb",Private,"12 
(out of 15)",64,"256
+ online low-pass 51Hz ","4 Blocks (with diff target)
of 6525 images
(20% were targets)",Offline,,"1) High-Pass filter: 0.1Hz
2) 1s window around image stimuli (100ms before)
3) Blinks removed based on VEOG",Yes,Raw EEG,Raw EEG,z-score,,Caffe,"CNN
+ Spatio-Temporal Regularization",CNN,"Spatio-Temporal Regularization
The penalty term regularizes the spatial filters such that the filters activations will be smooth. Penalizes the higher frequencies and fast changes.","The first convolutional layer performs a spatial convolution by using filters of size 64×1, learning features which represent a spatial distribution across the scalp. The second conv layer captures the temporal information.",Yes,"64x64
(electrodes by 
time samples)","CNN: 3
FC: 2",ReLU,"Dropout
Spatio-Temporal 
(their own regul)",2,"Target
Non Target","2
(softmax)",N/M,N/M,SGD,"LR: 0.001
Momentum: 0.9",No,Empirically,Bootstrapped the minority class to balance classes,Multinomial Logistic Regression,Intra,Random CV,"Train: 80%
Test: 20%",,"Accuracy (balanced)
AUC
Correct, Hits, False Alarms","balanced accuracy, AUC, sensitivity, false positive rate",NVidia GTX 650,,N/M,"(Mean) Balanced Accuracy: 70±4.86
(Mean) AUC: 0.77±0.05
(Mean) Correct: 75±4.4 || Hits: 64.4±5.47 || False Alarms: 23.7±4.36",SWFP algorithm,Traditional pipeline,No,Yes,"We showed that DNN models are an effective tool for single trial P300 classification. Even for a difficult RSVP task with five categories, we achieve impressive classification performance that surpasses our earlier work. The NN model is regularized with a novel spatio-temporal regularizer, which encourages the network to learn smooth features and thus reduces overfitting to noisy samples.",N/M,No,N/A,Yes,"They conclude with: ""Therefore, we should look at building large data sets for EEG which will allow to explore larger and deeper models""",,Yannick,[TBD],,Manor2015
,Parallel convolutional-linear neural network for motor imagery classification,2015,"Sakhavi, Guan & Yan",European Signal Processing Conference,,"BCI Lab, Singapore
National University of Singapore",5,,Classification of EEG signals,BCI,Active,Motor imagery,New approach,Use DL for 4-class motor imagery using dynamic energy,Motor imagery,"Because traditional classifications, such as SVM, cannot handle this dynamical property, we proposed an architecture that inputs a dynamic energy representation of EEG data and utilizes convolutional neural networks for classification",,"N/M
(see dataset paper)",No,Motor imagery,BCI Competition IV - IIa,Public,9,22,250,"144 samples per class
(train:72 and test:72)",Offline,,"1) Filter-Bank CSP (FBCSP)
9 filters from 4 to 40Hz",No,FBCSP,Frequency-domain,N/M,,"MATLAB
Torch","Parallel 1D-CNNs
+ MLP",CNN,Parallel convolutional layers with a one dimensional kernel in time. ,"Average pooling. In CNN architectures for images, max pooling is used because of its spatial invariance-inducing property. But training the EEG data with max pooling re- sulted in poor results. Therefore, average pooling is used.",Yes,"8
? (to be confirmed)",4x 2 CNN + MLP,ReLU,Dropout,4,"Left Hand
Right Hand
Feet
Tongue",4,N/M,N/M,SGD,N/M,N/M,N/M,N/M,"Negative 
Log-Likelihood",Intra,N/M,"Train: 50%
Test: 50%",,Accuracy,accuracy,N/M,,N/M,70%,SVM,Traditional pipeline,"Yes
(Wilcoxon signed-rank test)
CNN vs SVM vs MLP",Yes,"(1) Furthermore, deep architectures, due to there high learning capacity, have gained their success by being trained on large amounts of data. Unfortunately, limitation on gathering data for individual subjects is a barrier in EEG research. (2) Classification aside, there is one other element in BCI research that is valuable: interpretability of learned algorithms.","Our algorithm is not perfect in several aspects and can be improved: heavy pre-processing of data, choice of architecture and network parameters.",No,N/A,Yes,-,,Yannick,[TBD],,Sakhavi2015
,Deep learning of EEG signals for emotion recognition,2015,"Gao, Lee & Mehmood",IEEE International Conference on Multimedia & Expo Workshops (ICMEW),,"Chonbuk National University, Korea",5,,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Use DL (RBMs) for emotion classification,"Not clear...
(4 classes emotions)",To learn features from the data.,,"EPOC?
(not clear)",No,"Raw EEG
(Emotions)",Internal Recordings,Private,21,14,N/M,"180 epochs / subject
45 for each of the 4 classes",Offline,,"1) Manual artifact removal with EEGLAB
2) Filtering  (they don't mention what/how)
3) Epochs Selection
4) Signal Averaging",Yes,Raw EEG,Raw EEG,N/M,,EEGLAB,RBM,RBM,N/M,Pre-training on all subjects with unlabeled data and fine-tuning on individual subject for intra subject classification with labeled data,Yes,192x14,RBM: 3,N/M,N/M,4,"Happy
Calm
Sad
Scared",4,N/M,"(1) Pre-Training across subject 
(unlabeled data)
(2) Fine-Tuning per subject 
(labeled data - backprop)",N/M,N/M,N/M,N/M,N/M,N/M,Intra,"Average of 10 times:  
Train: 160 (random)
Test : 20 (random)
per subject","Train: 160 epochs/subject
Test: 20 epochs/subject",,Accuracy,accuracy,N/M,,N/M,"Subject United: 28.6 %
Subject Tied: 68.4 % 
Channel Selection: 57.2 %","KNN: 51.3 %
SVM: 60.8 %
ANN: 60 %",Traditional pipeline,N/M,No,It differs from the conventional methods as we apply deep learning on the raw signal without hand-crafted feature extraction.,N/M,No,N/A,No,Not much data for deep learning.,,Yannick,[TBD],,[TBD]
,Feature learning from incomplete EEG with denoising autoencoder,2015,"Li, Struzik, Zhang & Cichocki",Neurocomputing,Yes,"RIKEN, Japan
Shanghai Jiao Tong University, China
Polish Academy of Sciences, Poland",9,,Improvement of processing tools,Feature learning,,,New approach,Use DAE or SVM on Lomb–Scargle periodograms for Motor Imagery with missing data (e.g. after artefact removal),Motor imagery,"""a neural network with more layers might possible achieve a better performance through in-depth feature learning""",,N/M,No,Motor imagery,Internal Recordings,Private,3,14,250,"15 trials (of 4s) / session
4 sessions / subject",Offline,,N/M,No,"Lomb–Scargle periodograms
(Freq Bands Power)",Frequency-domain,Relative band powers,,N/M,DAE,AE,N/M,N/M,Yes,56x1,2,Sigmoid,N/M,2,"Right Hand
Left Hand",2,N/M,"1) Pre-training with DAE
2) Fine-tuning with output layer",N/M,"LR (Pre-Training): 0.9
LR (Fine-Tuning): 0.9",25,"Trial and Error*
(assumed, not mentioned)","Overlapping Windows
87.5%",MSE,Intra,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"See papers, it shows results per subject, per session, 
with 10% to 80% of missing data.
Roughly ~60-8X% accuracy","SVM
(on Lomb–Scargle periodogram, no real benchmark)",Traditional pipeline,No,No,"""Therefore, the classification performance using the proposed method for incomplete segments is acceptable for a BCI application system. This means that the segment with noise contamination can still be utilized to output commands after only removing the noisy portion, instead of discarding the whole segment, as is conventionally done in BCI systems.""",N/M,No,N/A,No,-,,Yannick,Hubert,,Li2015
,Superchords: the atoms of thought,2015,Normand & Ferreira,Arxiv,Yes, University of Lisbon,5,,Classification of EEG signals,BCI,Active,Motor imagery,New approach: Brain Orchestra Approach (BOA),"Use DL (H2O) to classify Motor Imagery, using existing dataset ",Motor imagery,"Explore H2O and their BOA. 
The concept of superchords",,"N/M
(see dataset paper)",No,Motor imagery,eegmmidb,Public,109,64,160,N/M,Offline,,1) Splitting each class in 10 datasets (10 to 160 first superchords),"N/M
(see H2O)",Superchords,Other,N/M,,R / R Studio,H2O,NS,N/M,N/M,No,not clear,"N/M
(see H2O)","N/M
(see H2O)","N/M
(see H2O)",5,"Left Hand
Right Hand
Both Hands
Feet
Rest","5 ?
(N/M)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,Intra,N/M,"Train: 50%
Validation: 50%",,"Accuracy
Error = wrong preds / nb preds","accuracy, error",N/M,,N/M,> 80% Accuracy ( < 20% Errors),No,None,No,No,"there are positive indications that superchords are singular to each motor task present on the dataset. The authors do believe it would be possible to expand the concept of singular superchord to other mental activities, like reactions to faces or words.","1) Anticipation (Chavarriaga, 2012)
2) Quality of recordings
3) Sample representativity
4) Paradigm type",No,N/A,No,"They conclude by inviting people who'd like to apply/explore that approach to collaborate
Very very short paper, not much info",,Yannick,[TBD],,Normand2015
,On the use of convolutional neural networks and augmented CSP features for multi-class motor imagery of EEG signals classification,2015,"Yang, Sakhavi, Ang & Guan",IEEE Internation Conference in Medicine and Biology,No,"Agency for Science, Technology and Research (A*STAR)",4,,Classification of EEG signals,BCI,Active,Motor imagery,Improve state-of-the-art,Use CSP + CNN for 5-class motor imagery classification ,Motor imagery,Replace hand-crafted feature selection methods with CNNs to learn structure from CSP features,,"N/M
(see dataset paper)",No,Motor imagery,BCI Competition IV - IIa,Public,9,22,250,N/M,,,None,,Augmented CSP,Frequency-domain,N/M,,N/M,CNN,CNN,"Pooling layers also sub-sampled features maps (the intention was to select features).
3 methods to select features maps were proposed: random, all, and frequency complementary map selection (see paper) ",,Yes,60 x 48 x 1,"Conv: 2
FC: 1",N/M,N/M,,,N/M,N/M,Standard,SGD,lr=0.5,38,N/M,N/M,MSE,,K-fold*,5-fold*,,Accuracy,accuracy,N/M,,N/M,"Random selection of feature maps accuracy was smaller than baseline.
All feature maps and frequency complementary selection improved accuracy in ~1.5% and ~2.5%.
",Filter-bank CSP,Traditional pipeline,,No,There was no significant improvement between frequency complementary selection and using all feature maps.,,No,N/A,No,"Main contribution of the paper relies on the proposed feature map selection scheme. However, statistical testing showed that this method has not improved results w.r.t. using all feature maps.",,Isabela,[TBD],,[TBD]
,Prediction of driver's drowsy and alert states from EEG signals with deep learning,2015,"Hajinoroozi, Mao & Huang",International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP),No,University of Texas at San Antonio,4,,Classification of EEG signals,Monitoring,Cognitive,Drowsiness,Prediction of driver’s cognitive states,Predict drowsiness or alert states,Driving in a virtual reality environment,Explore DL for assessing driver's cognitive state,,N/M,No,None,"Metev and Veiko (1998);
Lin et al. (2005);
Correa et al. (2014)",Private,37,30,250,35074,,,1) ICA,,Raw EEG,Raw EEG,N/M,,N/M,CNN +RBM,RBM,"1) CNN with all channels concatenated in a long vector
2) CNN for 2D inputs with one channel
3) CNN with 1D inputs and 30 channels
4) CNN with 1D inputs and 30 channels and RBM for feature extraction ",,Yes,"7500 x 1 x 1 (W x H x N channels)
250 x 30 x 1 
250 x 1 x 30","Conv: 2
FC: 1",Sigmoid,N/M,,,1,N/M,Standard,GD,N/M,N/M,N/M,N/M,Binary cross-entropy,,Train-valid-test split,"Train: 50 sections
Validation: 10
Test: 10",,AUC,AUC,N/M,,N/M,"All DNNs outperformed baseline methods with and without ICA.
AUC improvement w.r.t. baselines of ~27%",LDA and SVM on raw EEG,Traditional pipeline,,No,CNN-3 presented better results in comparison to other DNNs. ICA decreased the performance of all methods.,,No,N/A,No,Comparison with baselines was not super fair IMO (LDA and SVM with raw EEG),,Isabela,[TBD],,Hajinoroozi2015
,Deep Extreme Learning Machine and Its Application in EEG Classification,2015,"Ding, Zhang, Xu, Guo & Zhang",Mathematical Problems in Engineering,No,"China University of Mining and Technology
Chinese Academy of Sciences",11,,Classification of EEG signals,BCI,Active,Slow cortical potentials,New Approach: DELM for EEG-BCI,"Explore ELM, KELM and DELM for EEG-based BCIs using existing datasets.","BCI Competition II Datasets IA et IB
Slow Coritcal Potentials",Not only does MLELM approximate the complicated function but it also does not need to iterate during the training process.,,N/M,No,(see dataset),"BCI Competition II - Ia;
BCI Competition II - Ib",Public,"N/M
(see dataset paper)","N/M
(see dataset paper)",256,"1) 561
2) 380",,,"N/M
(they say they used ""preprocessed EEG"")",No,Raw EEG,Raw EEG,N/M,,Matlab,"DELM
(Deep Extreme Learning Machine)",NS,"not clear
(to be reviewed)",N/M,Yes,"not clear
(to be reviewed)","not clear
(to be reviewed)","Sigmoid
+ Kernel Functions: Gaussian",N/M,,,"not clear
(to be reviewed)",N/M,"not clear
(to be reviewed)",N/M,N/M,N/M,N/M,N/M,N/M,,N/M,"1) Train: 268 | Test: 293
2) Train: 200 | Test: 180",,"Accuracy
Training Time
Testing Time","accuracy, training time, testing time",N/M,,"1) 6.7s
2) 8.9s","1) [Average] Training:  0.7515  |  Testing:  0.8650
1) [Best] Training:  0.7873  |  Testing:  0.9181
2) [Average] Training:  0.7151  |  Testing:  0.5211
2) [Best] Training:  0.8450  |  Testing:  0.6056",ELM vs KELM vs ML-ELM vs DELM,Traditional pipeline,,No,"In this paper, DELM is used to classify preprocessed EEG data and the feature attributes of preprocessed EEG are not extracted, which has certain effects on the experimental results. Future research is to combine the EEG feature extraction methods and DELM, which will be applied to the EEG classification.",N/M,No,N/A,No,"Hard to find information...
Still not sur I fully understand... (YR)
Someone else should read it and fill the information.",,Yannick,[TBD],,Ding2015
,Emotional Affect Estimation Using Video and EEG Data in Deep Neural Networks,2015,Frydenlund & Rudzicz,Advances in Artificial Intelligence,,University of Toronto,8,,Classification of EEG signals,Monitoring,Affective,Emotion,"New Approach: Reusing downsampling ""wasted"" data for data augmentation","Reusing downsampling ""wasted"" data for data augmentation in a valence/arousal/dominance regression scale on DEAP dataset",Emotion Scale Regression (Arousal/Valence/Dominance) on DEAP ,Not much explanation. Probably for the multimodal aspect.,,"N/M
(see dataset paper)",No,"Emotions
(PSD)",DEAP,Public,22,32,"512 (original)
DS to 1/5 (~102)","N/M
(see dataset paper)",Offline,,"1) Downsampled to 1/5
2) ICA -> Ocular Artifacts removal",Yes,"Frequency Bands 
(Theta, Slow Alpha, Alpha, Beta, Gamma)",Frequency-domain,z-score,,"EEGLAB
Deep Learning Toolbox [11]
Spearmint [15]
modified SPN code from [12]",NN,FC,N/M,N/M,No,"N/M
(multimodal)",2,"Sigmoid (layers)
Softmax (output)",N/M,N/A,"N/A
Regression ""Scale""","Scale [1-9] or [0-1]
(regression)",N/M,N/M,N/M,N/M,N/M,N/M,"Using Acq. Freq. Downsampling 
""throw away"" data
(downsampling 1/5 gives you 5x)",N/M,Inter*,Leave-two-out,N/M,,RMSE,rmse,N/M,,N/M,"Arousal:   [1-9] 1.5778 ± 0.5301  ||   [0-1]  0.1972 ± 0.0663
Valence:  [1-9]  1.5396 ± 0.8797  ||   [0-1]  0.1925 ± 0.1100
Dominance:  [1-9]  0.1925 ± 0.1100  ||   [0-1]   0.2523 ± 0.0561 
Favourability:  [1-9]  2.2366 ± 0.5975  ||   [0-1]  0.2796 ± 0.0747   
Familiarity:  [1-9]  2.0432 ± 0.4010  ||   [0-1]  0.5108 ± 0.1002","Baseline
Linear Regression",Traditional pipeline,"Yes, 1-sided t-test
(NN vs Baseline)",No,"This work acts as a feasibility study for our ‘downsampling extension’ scheme, and further work needs to be done to examine its affect. Feature selection is another possible line of inquiry, since we have selected features based on linear relations, where non-linear relations may be more appropriate for DNNs.",N/M,No,N/A,No,"Interesting approach on ""reusing"" downsampling wasted data... Other studies with more ""comparisons"" are required...",,Yannick,[TBD],,Frydenlund2015
,Detecting Epileptic Seizures from EEG Data using Neural Networks,2015,"Pramod, Page, Mohsenin & Oates",Arxiv,Yes,"University of Maryland, Baltimore County",,,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA: Using Dropout in NN for Seizure Detection,Using Dropout in NN for Seizure Detection,"Ongoing EEG recording, with and without seizures.",Use Dropout on NN for Epilepsy EEG,,"N/M
(see dataset paper)",No,Seizures,CHB-MIT,Public,22,23,256,"N/M
(see dataset paper)",,,1) 1s windows,,"Area, Normalized Decay, Line Length, Mean Energy,Average Peak Amplitude, Average Valley Amplitude, Normalized Peak Number, Peak Variation, and Root Mean Square",Other,z-score,,N/M,"NN*
(FC I suppose)",FC,N/M,N/M,No,"126 features
(9 features x 14 channels)

(1s windows)","[2, 5]",ReLU,"L1
Dropout
([0.2, 0.5])",,,"1
(Softmax)",N/M,Gradient Descent with Early Stopping,N/M,"LR: [0.01, 0.1]",N/M,"Manually, by trying different things",Subsampling minority class to balance classes,N/M,,Leave-one-out,N/M,,"Sensitivity
Specificity
Precision
F-Score","sensitivity, specificity, precision, f1-score",N/M,,N/M,"Mean Sensitivity: 0.9806  (STD: 0.078)
Mean Specificity: 0.9929  (STD: 0.023)
Mean Precision: 0.7329  (STD: 0.33)
 Mean F-Score: 0.7816  (STD: 0.29)",This is an improvement on the most recently reported results on this database by Pinho et al. (2014),Traditional pipeline,,N/M,"Much remains to be improved in terms of precision of the classifier. Also, using the proposed classi- fier to detect seizure onsets is still a work in progress, where such a technique involves aggregating classifier outputs on multiple contiguous segments to achieve higher sensitivity and specificity.",N/M,No,N/A,No,"Among the first DL for Epilepsy. It shows.
The way people report now is way better.",,Yannick,[TBD],,[TBD]
,Adaptive Recurrent Neural Network For Reduction Of Noise And Estimation Of Source From Recorded EEG Signals,2015," Pardede, Turnip, Manalu & Turnip",ARPN Journal of Engineering and Applied Sciences,No," Institut Teknologi Nasional, Indonesia",5,,Improvement of processing tools,Signal cleaning,Artifact handling,,New approach for removing noise and locating brain activity sources,Use an adaptive RNN for cleaning EEG,"""Normal conditions"", eyes closed, and blinking",N/M,,Emotiv,No,None,Internal Recordings,Private,8,6,128Hz,N/M,,,1) Band-pass 0.5-49Hz,No,Raw EEG,Raw EEG,N/A,,N/M,RNN,RNN,N/M,N/M,No,N/M,N/M,N/M,N/M,,,N/M,N/M,Standard*,SGD,N/M,N/M,N/M,N/M,Minimum entropy,,N/M,N/M,,Performance factor defined in the paper,custom,N/M,,N/M,Curves are shown in the paper.,N/M,None,,N/M,The proposed method outperforms baselines for 6 out of 8 subjects.,N/M,No,N/A,No,Terrible paper. For me it is not clear if and how they used a neural network. ,,Isabela,[TBD],,Pardede2015
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,EEG-based emotion classification using deep belief networks,2014,"Zheng, Zhu, Peng & Lu",IEEE International Conference on Multimedia and Expo,,"Shanghai Jiao Tong University, China",6,,Classification of EEG signals,Monitoring,Affective,TBD,Improve SOTA,Use DBN and DBN+HMM on DE features for emotion classification (2 classes: Positive/Negative),Short Movie Clips eliciting positive/negative emotions,The efficiency of DBN model can combine feature ex- traction and feature selection when doing unsupervised and supervised learning.,,"ESI NeuroScan 
System",No,"Emotions
(PSD)",Internal Recordings,Private,6,62,1000,"2 sessions x 12 clips x 4 min
per subject",Offline,,"1) Downsampled to 200Hz
2) Pass-band filter: 0.3 - 50Hz
3) Short-Time FT with 1s Hanning Window -> 5 Freq Bands
4) Differential Entropy for each band",No,"Differential Entropy (DE) of 5 F. Bands (D,T,A,B,G)
62 channels * 5 bands = 310 features
Smoothed with linear dynamic system (LDS)",,z-score,,N/M,DBN-HMM,,DBN + HMM after,"Combining DBN and HMM can help bridge the gap between static and sequence pattern recognition, which has been successfully used in sleep stage classification using EEG [4]",No,310 x 1,2,N/M,N/M,2,"Positive Emotion
Negative Emotion",2,N/M,An efficient greedy layer-wise algorithm is used to pre-train each layer of networks,N/M,LR: 0.05,200,N/M,N/M,"Energy Function
(see paper)",Intra,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"                      Delta | Theta | Alpha |  Beta  | Gamma | Total
   DBN-HMM:   61.45 | 58.39 | 71.57 | 85.45  |  87.33  |  87.62 
   DBN:             61.98 | 58.36 | 69.22 | 85.96  |  88.40  |  86.91 ","                Delta | Theta | Alpha |  Beta  | Gamma | Total
   GELM:   68.37 | 61.63 | 70.88 | 84.60 |  87.99  |  85.67 
     SVM:    56.43 | 59.57 | 66.59 | 82.97 |  85.86  |  84.08  ",,N/M,"No*
(they talk about what frequencies contribute most...)","In this paper, the experiment results show that high frequency-band (beta and gamma) features are more related to emotion recognition, which is consistent with previous work, proposing higher frequency brain activity reflecting emotional and cognitive processes [8] [9].",N/M,No,N/A,No,"They used the different frequency bands, but they would need to combine them (i.e. ratios), not just ""as is"", individually...",,Yannick,[TBD],,Zheng2014
,Deep learning of multifractal attributes from motor imagery induced EEG,2014,Li & Cichocki,International Conference on Neural Information Processing,,"Riken, Japan",8,,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use DAE + DNN on multifractal features for Motor Imagery,Motor Imagery,N/M,,N/M,No,Motor Imagery,Internal Recordings,Private,3,14,N/M,"4 sessions x 15 trials x 4s
per subject",Offline,,"1) Notch Filter: 50Hz
2) Multifractral Feature Extraction",No,"Multifractal Features 
(based on wavelet leaders)
Discrete Wavelet Transform",,N/M,,N/M,DAE + DNN,,Using Stacked DAE to learn initial weights for (FC) DNN,N/M,Yes,12,"SDAE: 3
DNN (FC): 3",Sigmoid,N/M,2,"Left Hand
Right Hand",2,N/M,Stacked DAE layers are trained sequentially with a stop criterion of 30 epochs. Then DNN is fine-tuned in a supervised way with a stop of 50 epochs,N/M,"SDAE LR: 0.5
DNN: LR: 0.2",SDAE: 75,N/M,N/M,MSE,Intra,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"S1: 90.93 | 85.87 | 93.07
S2: 57.60 51.47 70.93
S3: 63.20 68.27 83.47",N/M,,N/M,N/M,"We explored multifractal attributes for motor imagery EEG, and found that characte- ristics of multifractal spectrum D(h) and the statistics cp based on cumulants are dif- ferent between left and right motor imageries. Then, a deep network was built to learn the extracted multifractal attributes.",N/M,No,N/A,No,---,,Yannick,[TBD],,Li2014
,EEG-based emotion recognition using deep learning network with principal component based covariate shift adaptation,2014,"Jirayucharoensak, Pan-Ngum & Israsena",The Scientific World Journal,No,Chulalongkorn University,10,,Classification of EEG signals,Monitoring,Affective,TBD,Improve state-of-the-art,,Emotion Classification on DEAP ,Discover unknown feature correlation between input,,N/M,No,PSD,DEAP,Public,32,32,512Hz,N/M*,,,1) Downsampling to 128Hz,No,PSD,,"1) Subtract baseline
2) Rescale to [0.1,0.9]",,N/M,Stacked autoencoder + MLP,,Stacked autoencoder layers are used for feature extraction. Two softmax layers are used: one for arousal classification and other for valence,N/M,Yes,230 x 1,3,N/M*,L2,,,3,N/M,"Stacked autoencoder layers are trained sequentially for 400 iterations, then the softmax layer is trained for 100 iterations. At last, the whole model is fine-tuned for 200 iterations. ",L-BFGS,N/M,N/M,N/M*,No,MSE,,Leave-one-subject-out,N/M,,Accuracy,accuracy,CPU with RAM 8 GB,,20-25 minutes,"In terms of average accuracy, the model with PCA + covariate shift adaption performed better then the other proposed models and the two baselines for both arousal and valence.",SVM and Naive Bayes,,,No,"The covariate shift adaptation is able to handle nonstationary on EEG signals, but high variability across subjects is still an issue.","""One of the major limitations for performing EEG-based emotion recognition algorithm is dealing with the problem of intersubject variations in their EEG signals""",No,N/A,No,I like the covariate-shift adaptation idea. It would be nice to have something like this in a layer/weight/batch-normalization style. ,,Isabela,[TBD],,Jirayucharoensak2014
,A deep learning method for classification of EEG data based on motor imagery,2014,"An, Kuang, Guo, Zhao & He",International Conference on Intelligent Computing in Bioinformatics,,"Tongji University, Shanghai, China",8,,Classification of EEG signals,BCI,Active,TBD,Improve SOTA,Use DBN + Ada-boost for Motor Imagery,Motor Imagery,DBN can learn the advanced abstract representation from unlabeled data.,,N/M,No,Motor Imagery,Internal Recordings,Private,4,1,250,"30 LH + 30 RH
per subject",Offline,,"1) EOG artifact removal (Neuroscan)
2) Band-pass filter: 8 - 30Hz  (elliptic filter)",Yes,"PSD
(FFT)",,N/M,,Neuroscan,"DBN
+ Ada-boost",,"Single Channel
Tested [4-16] layers. 8-9 layers give the best performances",N/M,Yes,N/M,8,Sigmoid,N/M,2,"Left Hand
Right Hand","N/M
(2 ?)",N/M,Contrastive Divergence (CD),N/M,"LR: 0.07
Weight Decay: 0.002
Momentum: 0.5",N/M,N/M,N/M,N/M,Intra,"Yes
(no detail)",Train: 20 / 60,,Accuracy,accuracy,N/M,,N/M,"With 8 Layers for the 4 sujbects:
85% 65% 77% 95%",SVM,,N/M,No,"Our study suggests that DBN has great potential to be a powerful tool for the BCI research. For the next stage, we’ll try to employ this algorithm into classification of Multi-class based on EEG data, and merge more channels in order to take full use of the EEG data information to achieve better recognition results.",N/M,No,N/A,No,---,,Yannick,[TBD],,An2014
,Single-trial classification of ERPs in rapid serial visual presentation tasks using supervised spatial filtering,2014,"Cecotti, Eckstein & Giesbecht",IEEE Transactions on Neural Networks and Learning Systems,,"University of California, Santa Barbara, USA
University of Ulster, UK",13,,Classification of EEG signals,BCI,Reactive,TBD,Improve SOTA,Use CNN with training based on the maximization of the AUC for single-trial detection of ERP in three RSVP tasks.,RSVP,CNN's first layer act as a spatial filter,,Biosemi,No,RSVP,Internal Recordings,Private,8 + 10,32,512,12000 + 10000 + 4000,Offline,,"1) Band-pass filter: 1 - 10.66Hz
2) Downsampled to 32Hz",No,Raw EEG,,N/M,,C++,CNN,,"Different Combinasions of 
Spatial Filter + Classifier
SP: xDAWN, CSP, CNN
Classifier: BLDA, MLP, SVM","Spatially, could (should) be stationary",No,"4 x 26 = 104
(channels x time points)",2,"Sigmoid
Hyperbolic Tan (L1)
Logistic (L2, Lout)",N/M,2,"Target
Non-Target",2,"4414 to 33402
(depending on the model)",N/M,N/M,N/M,N/M,N/M,N/M,"Max AUC
Min MSE",Intra,5-Fold CV,"N/M
(TBC)",,AUC,AUC,N/M,,N/M,"                            CNN | xDAWN | CSP | T
[AUC] Exp #1 (MLP): 0.932 | 0.910 | 0.822 | 0.917
[AUC] Exp #2 (MLP): 0.845 | 0.865 | 0.720 | 0.809
[AUC] Exp #2 (MLP): 0.816 | 0.845 | 0.728 | 0.810","SVM
Baysian LDA",,"Yes
(Friedman’s test, Wilcoxon sign rank test, t-test, Anova)",No,"After Wilcoxon sign rank tests, CNN was the best preprocessing step, followed successively by xDAWN, the absence of spatial filtering, and CSP ( p < 10e − 4). For classifiers, MLP was better than both SVM (p < 10e−5) and BLDA (p < 10e − 5), and there was no difference between SVM and BLDA.",N/M,No,N/A,No,In depth on spatial filtering. Good paper for that. Stays high-level for deep learning stuff however. They had 3 experiments and good comparison with SOTA spatial filtering and classifier.,,Yannick,[TBD],,[TBD]
,Using convolutional neural networks to recognize rhythm stimuli from EEG recordings,2014,"Stober, Cameron & Grahn",Advances in Neural Information Processing Systems,No,Western University,9,,Classification of EEG signals,Music semantics,Personal trait/attribute,,"Classify 24 different rhythmic stimuli 
(and identify West vs East population)",Use DNN to a 24-classes classification task,Rhythmic stimili,Shown good results in fMRI and limited cases in EEG,,Grass EEG,No,None,Internal Recordings,Private,13,14,400Hz,"12 rhythms * (32s + 4s) 
(4s in between)
per subject",Offline,,1) Removed bad channels for each subject,No,Raw EEG and spectrum,,N/A,,"Theano
Pylearn2
Spearmint",CNN,,Used a DLSVM output layer,N/M,Yes,"33x49
45x49",Conv: 1 and 2,ReLU,Dropout,24,Different Stimuli,24,N/M,N/M,SGD + Momentum,"lr: [0.001, 0.01]
lr decay: [1, 1.1]",100,Bayesian optimization,N/M,Hinge loss,Intra,Train-validation-test,N/M,,"Accuracy
mean reciprocal rank","accuracy, mean reciprocal rank",Tesla C2075 and a Quadro 2000.,,< 48h,"Mean Accuracy - 24 Classes: 24.4% (Chance = 4.17%)
Mean Accuracy - 2 Classes: 77.2% (Chance = 50%)
Proposed method in all configurations outperformed the baseline. 
CNNs with a single layer were as good as CNNs with 2 layers. ",SVM,Traditional pipeline,No,No,"""The results reported here still need to be taken with a grain of salt. Because of the study design, there is only one trial session (of 32 seconds) per stimulus for each subject. Thus, there is the chance that the neural networks learned to identify the individual trials and not the stimuli based on artifacts in the recordings that only occurred sporadically throughout the experiment.""",Only a single trial per stimuli,Yes,GitHub,Yes,---,,Isabela,Yannick,,[TBD]
,Deep Belief Networks used on High Resolution Multichannel Electroencephalography Data for Seizure Detection,2014,"Turner, Page, Mohsenin & Oates",AAAI Spring Symposium,Yes,"University of Maryland, Baltimore County",7,,Classification of EEG signals,Clinical,Epilepsy,TBD,Improve State of the Art,Use DBN for Seizure Prediction,"Ongoing EEG recording, with and without seizures.",Ubiquitous bio-sensing for personalized health monitoring is slowly becoming a reality,,N/M,No,Seizures,CHB-MIT,Public,10/22,23,256,"N/M
(see dataset paper)",,,None,No,"Area, Normalized Decay, Line Length, Mean Energy, Average Peak Amplitude, Average Valley Amplitude, Normalized Peak Number, Peak Variation, Root Mean Square",,z-score,,Theano,DBN,,N/M,Layered learning approaches such as DBN excel in such context,Yes,"23 x 9
(channels x features)","2
(500 nodes)",N/M,N/M,,,"2
(seizure, non-seizure)",N/M,"Training deep belief networks is best done one layer at a time, in a layerwise manner (Bengio et al. 2007).
After the pretraining process of abstraction was completed (without the usage of class la- bels), the logistic regression layer was trained in the finetun- ing process. 16 iterations of finetuning were completed, with a learning rate α = .1",N/M,"lr: 0.001
25 epochs",N/M,N/M,N/M,N/M,,10-Fold CV,"Train: 71.4%
Valid: 14.2% 
Test:14.2%",,"Precision
Recall
F-Measure (F1)","precision, recall, f1-score","Dell Precision M4700
Intel i7-3940XM
16 GB 
 NVIDIA Quadro K2000M",,N/M,(check graphs for each patients - no results in numbers...),"KNN
SVM
Log. Reg.",,,No,"Dealing in the domain of using models of other patients to represent a different patient being tested upon (as was the case in the leave one out training and in real situations), deep belief networks often outperformed the logistic regression algorithm using the same feature set.","Although these are good numbers, it may not always be feasible to have hours of trained data about a patient to use as a model. The more realistic clinical study is the study, where the patients tests were done without any previous knowledge of the patient being tested on.",No,N/A,No,-,,Yannick,[TBD],,Turner2014
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Affective state recognition from EEG with deep belief networks,2013,"Li, Li, Zhang, Zhang",IEEE International Conference on Bioinformatics and Biomedicine,,"State University of New York at Buffalo
Beijing University of Technology",6,,Classification of EEG signals,Monitoring,Affective,TBD,Improve State of the Art,,"Emotion Classification on DEAP 
(Like or Dislike video)",,,N/M*,No,PSD,DEAP,Public,32,32,[DEAP],N/M*,,,"Same as DEAP:
1) Re-reference Common Avg.
2) Downsampled to 256Hz
3) High-Pass Filter: 2Hz
4) Eye artifacts removed with EEGLab AAR",,"PSD?
",,,,N/M*,DBN + RBM,,"DBN for channel selection
then RBM for prediction",,Yes,,,,,,,"2
Like or Dislike",N/M*,,N/M*,,,,No,N/M*,,N/M*,,,AUC,AUC,,,N/M*,~75%,"SVM,  PCA + SVM, SVM + Fisher, PCA + Fisher + SVM, DBN + Fisher + RBM",,,,"Moreover, to handle the small sample problem, the proposed method utilizes the DBN to reduce the dimensionality of the data in each channel while preserving their characteristics.",,No,N/A,Yes,Try to coin: Supervised DBN based Affective State Recognition (SDA) model,,Yannick,[TBD],,Li2013
,Automated Classification of L/R Hand Movement EEG Signals using Advanced Feature Extraction and Machine Learning,2013,"Alomari, Samaha & AlKamha",Arxiv,Yes,"Applied Science University, Jordan",6,,Classification of EEG signals,BCI,Active,TBD,Improve State of the Art,Use NN and SVM for BCI-MI,Motor Imagery (eegmmidb),None,,"N/M
(see eegmmidb info)",No,Motor Imagery,eegmmidb,Public,"6
(out of 108)","8
(out of 64)","N/M
(see eegmmidb info)","6x3x2 min
(subjects x sessions x time)",Offline,,"1) Band-pass filter: 0.5 to 90Hz
2) Notch filer: 50Hz
3) AAR - Artifact Removal Toolbox (EEGLAB)
4) Epoching
5) IIR Band-pass filter: 8 to 30Hz",Yes,"Power, Mean, Energy, Type, Side",,N/M,,"EEGLAB
MATLAB",NN,,N/M,N/M,No,108x26,"[3 - 15]
Best 4",N/M,N/M,2,"Left
Right",2,N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,Intra,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,89.8 %,SVM (97.1%),,N/M,N/M,"Our methodology is not the best, but is somewhat a simplified efficient one that satisfies the needs for researchers in field of neuroscience.

(wow... :/)",N/M,No,N/A,No,Very ordinary paper...,,Yannick,[TBD],,Alomari2013
,Energy Distribution of EEG Signals: EEG Signal Wavelet-Neural Network Classifier,2013,"Omerhodzic, Avdakovic, Nuhanovic & Dizdarevic",Arxiv,Yes,"Clinical Center University of Sarajevo, Bosnia
University of Tuzla, Bosnia",6,,Classification of EEG signals,Clinical,Epilepsy,TBD,Improve State of the Art,Use WNN (Wavelet NN) for Epilepsy,"Ongoing EEG recording, with and without seizures.",None,,"N/M
(see dataset info)",No,Seizures,Bonn University,Public,5,1,173.61,3 (sets) x 100 x 23.6s,Offline,,None,No,"Wavelet
(6 decomposition levels)",,N/M,,Matlab,NN,,N/M,N/M,Yes,"6
(Wavelet Energy Features)",3,Tangent Sigmoid,N/M,3,"Healthy
Epilepsy Syndrome
Seizure",1,N/M,N/M,"Levenberg-Marquard ??
(TBC)",LR: Levenberg-Marquard Backprop Learning Rule,N/M,Trial and Error,N/M,MSE,Inter,N/M,"Train: 250
Test: 50",,Accuracy,accuracy,N/M,,N/M,94%,N/M,,N/M,N/M,"The most important advantage of the proposed method is the reduction of data size as well indicating and recognizing the main characteristics of signal. Furthermore, it can reduce memory space, shorten pre-processing needs, the network size and increase computation speed for the classification of an EEG signal.",N/M,No,N/A,No,-,,Yannick,[TBD],,Omerhodzic2013
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Sleep stage classification using unsupervised feature learning,2012,"Langkvist, Karlsson & Loutfi",Advanced Artificial Neural Systems,,"Orebro University, Sweden",9,,Classification of EEG signals,Clinical,Sleep,TBD,New Approach: Explore DL & Unsupervised learning for Sleep Stage Scoring,Explore DL & Unsupervised learning for Sleep Stage Scoring,Sleep,Unsupervised learning for sleep stage scoring from raw EEG signal,,"1) N/M
2) Embla Titanium PSG",No,Sleep,"UCDDB;
Internal Recordings",Public,"1) 25
2) 1","1) 1 (out of 2)
2) 8","1) 128
2) 256","1) avg of 6.9h / subject
2) ~60h",,,"1) Notch filter: 50Hz
2) Band-Pass filter: 0.3 - 32Hz
3) Downsampled to 64Hz",No,"Raw EEG for raw-DBN
28 Features for feat-DBN",,N/M,,Matlab,DBN,,N/M,N/M,Yes,"1x256 
(1s @ 256Hz)",2 (200 HU),N/M,N/M,,,"5 classes
(Softmax)",N/M,Unsupervised Greedy Layerwise training,N/M,N/M,N/M,N/M,N/M,RMSE,,25-Fold of Leave-one-out CV,"Train: ~250000 samples
Valid: ~50000 samples
Test: ?",,"Accuracy
F1-Score","accuracy, f1-score","Windows 7, 64-bit, quad-core Intel i5 3.1GHz,  nVIDIA GeForce GTX 470",,"10 min
1h
3h","Mean Accuracy Across Datasets
feat-GOHMM: 63.9 ± 10.8
feat-DBN: 72.2 ± 9.7
raw-DBN: 67.4 ± 12.9

F1-score raw-DBN: [A] 0.69 | [S1] 0.36 | [S2] 0.78 | [SWS] 0.83 | [REM] 0.58","feat-GOHMM vs feat-DBN vs raw-DBN

(all internal, not external comparison)",,,[image of features] It can be observed that the learned features are of various amplitudes and frequencies and some resemble known sleep events such as a K-complex or blink artifacts.,"(1) We also noticed a lower performance if sleep stages were not set to equal sizes in the training set. There was also a high variation in the accuracy between patients, even if they came from the same dataset. (2) It has been suggested for multimodal signals to train a separate DBN for each signal first and then train a top DBN with concatenated data [34]. This not only could improve classification accuracy, but also to single out which signal contains the anomalous signal.",N/M,Yes,Website,No,They also have a paper from 2018. They've continued down the DL-Sleep road!,,Yannick,[TBD],,Langkvist2012
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Convolutional neural networks for P300 detection with application to BCIs,2011,Cecotti & Graser,IEEE Transactions on Pattern Analysis and Machine Intelligence,,"University of Bremen, Germany",13,,Classification of EEG signals,BCI,Reactive,TBD,"Improve SOTA
(they say they are the first to do CNN on P300 speller)","Use CNN for P300 speller, using BCI Competition Datasets","P300 Speller, 6x6 Matrix.
BCI Competition III Dataset II",CNN seems to be a good approach for EEG classification as the signal to detect contains a lot of variations over time and persons,,"N/M
(see dataset info)",No,P300,BCI Competition III - II,Public,2,64,240,85 x 2 x 15,Offline,,"0) Band-pass filtered from 0.160Hz (to 240Hz ?) - Hardware
1) Downsampled to 120Hz (1/2)
2) Band-pass filtered: 0.1 - 20 Hz
3) Signal Normalized",No,Raw EEG,,z-score,,N/M,CNN,,N/M,Each map of the first hidden layer is a channel combination. The second hidden layer subsamples and transforms the signal in the time domain.,Yes,"64 x 78
channels x ","
CNN: 2
FC: 1",Sigmoid,N/M,36,"Letters
(6x6 Matrix)","2
(P300 or not)","CNN1: 31,652",N/M,"Gradient Descent
(optimizer: N/M)",N/M,N/M,N/M,N/M,LSE,Intra,N/M,"Train: 2550 + 12750
Test: 3000 + 15000
(per subject)
(Train: 95% T + 5% Valid)",,"Accuracy (Recognition Rate)
Recal, Precision, Silence, Noise, Error, F-Measure","accuracy, recall, precision, silence, noise, error, f-measure","Core 2 Duo T7500 CPU
(no GPU)",,10 min,"Subject A: CNN-1: 70.37% | MCNN-1: 68.99%
Subject B: CNN-1: 78.19% | MCNN-1: 75.86%

(see all results in paper, for all metrics and all networks)","Compare different CNNs, with ESVM [16,40], LDA [42], mLVQ [42]
Yandong [40], Zongtan [40], Hoffman [40, 41]",,N/M,"Yes, in-depth analysis of the different CNNs, the topology, etc. 
(see paper for more)","Its accuracy is equivalent to the best current method on the Data set II of the third BCI competition [16]. It outperforms the best method in two situations: first, when the number of electrodes is restricted to 8; second, when the number of considered epochs is 10.",N/M,No,N/A,No,"Good paper, in-depth analysis of the field and their networks. Also talk about the importance of Datasets like BCI Competition to push the field further!",,Yannick,[TBD],,Cecotti2011
,Modeling EEG waveforms with semi-supervised deep belief nets: fast classification and anomaly measurement,2011,"Wulsin, Gupta, Mani, Blamco & Litt",Journal of Neural Engineering,,"University of Pennsylvania, USA",14,,Classification of EEG signals,Clinical,Epilepsy,TBD,New Approach,Use DBN to detect EEG anomalies / rare events.,"Ongoing recording in a clinical settings 
(to record rare anormal events)",DBNs can learn from unlabeled data (more available and cheaper than labeled one),,N/M,No,"1) spike & sharp wave, 
2) GPED & Triphasic Waves, 
3)  PLEDs,
4) eye blink artifact,
 5) background activity",Internal Recordings,Private,11,17,256,13 x 2h blocks,Offline,,"None.
Only subsampled 1000 x 2 min window",No,"Diff. Exp.
1) Raw EEG
2) Features (Area, Norm. Decay, Mean Energy, ...)
3) PCA (20)",,z-score,,Matlab,DBN,,N/M,Using DBN / RBMs to learn from unlabeled data,Yes,"1) Raw 256x17 channels
2) Features 16x?
3) PCA 20x1 ",4,Sigmoid,N/M,5,"1) spike & sharp wave, 
2) GPED & Triphasic Waves, 
3)  PLEDs,
4) eye blink artifact,
 5) background activity",not clear,N/M,"3-Step Semi-Supervise Layerwise. 
(1) unsupervised layer-wise RBM training (2) fine-tuned the DBN with backprop on unlabeled data. (3) fine-tune DBN with backprop on labeled data",N/M,LR: 0.1,10,N/M,N/M,RMSE,Inter,10 Fold CV,"Train: 500k + 72,800 (lbl)
Valid: 100k + 14,500 (lbl)
Test: 100k + 14,500 (lbl)
Total: 700k (unlbl) + 
101.8k (lbl)",,"Sensititivity
Precision
F1-Measure","sensitivity, precision, f1-measure",Mac OS X 10.5 array of 36 dual-core Intel Xeon CPUs (2.26–2.8 GHz),,N/M,"Reporting F1 on a graph. For: Raw256, Feat16, PCA20

We show that DBN, has comparable performance with SVM and KNN classifiers and has fast test time, even on high-dimensional raw data. We also show that using unpreprocessed, raw input data instead of features can yield comparable classification performance with greatly increased methodological elegance","Decisition Tree
SVM
KNN",,"Yes
Wilcoxon-Mann-Whitney test
(raw vs features)",N/M,"(1) We show that a relatively new type of neural network, the Deep Belief Net, has comparable performance with SVM and KNN classifiers and has fast test time, even on high-dimensional raw data. We also show that using unpreprocessed, raw input data instead of features can yield comparable classification performance with greatly increased methodological elegance. (2) As previously mentioned, we have found DBNs can be sensitive to heavy class-imbalance, which occurs in our dataset",Didn't consider the training time which takes a few days to more than a week.,No,N/A,No,---,,Yannick,[TBD],,[TBD]
,Single-trial EEG Discrimination between Wrist and Finger Movement Imagery and Execution in a Sensorimotor BCI,2011,"Mohamed, Marwala & John",Arxiv,,"University of Witwatersrand, South Africa
University of Johannesburg, South Africa
University of Cape Town, South Africa",5,,Classification of EEG signals,BCI,Active,TBD,"New Approach / Improve SOTA
(The combination of these five essential hand movements has not yet been explored in EEG-based BCI literature [9])",Explore BCI based on Motor (real & imagined) using finger vs wrist on the same hand,Motor Imagery & Real - Finger vs Wrist on the same hand,None,,EGI,No,"Motor
Imagery & Real",Internal Recordings,Private,5,128,200,400 trials / subject,Offline,,"1) Band-pass filter: 0.5 - 100Hz
2) Notch filter: 50Hz
3) Epoched in 7s windows
4) AAR (Automatic Artifact Removal) in EEGLAB
5) Band-pass filter: 8 - 30Hz (for mu and beta)
6) ICA (infomax) + Source Loc
7) Visual Inspection to select best ICs (8-12 / subject)",Yes,"1) FFT - 7 Freq Bands from Sources (ICA)
28 time windows * 7 bands * 8-12 ICs = ~2k features
2) Bhattacharyya Distance to select best 18 features
From Sources, not Electrodes. ",,N/M,,"EEGLAB
Matlab","NN
(MLP)",,N/M,N/M,No,"18
(18 best features from Bhattacharyya distance)","1
(24 nodes)",N/M,N/M,2,"Finger
Wrist",1,N/M,N/M,N/M,N/M,N/M,Trial and Error,N/M,N/M,Intra,N/M,N/M,,"Accuracy
(they say they also check Specificity and Sensitivity, but nothing is reported)",accuracy,N/M,,N/M,"Grand Average: 71%
Real - RH: [52-81 | AVG: 70], LH: [56-69 | AVG: 67]
Imaginery - RH: [61-82 | AVG: 73], LH: [67-72 | AVG: 69]","Mahalanobis Distance (MD)
Grand Average: 65%",,N/M,N/M,"Classification is slightly more successful for imagined movements than for real movements. This is contrary to the findings of other BCI studies [20], where classification results for real movements are superior due to real movements generating stronger motor neural activity [20].",N/M,No,N/A,No,"They say ""Multilayer perceptron artificial neural networks are used widely in BCI research"" citing Fabien Lotte ML Review on BCI, 2007. (are they?)
Lots of manual steps... not very much automated.",,Yannick,[TBD],,Mohamed2011
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Analysis and classification of EEG signals using spectral analysis and recurrent neural networks,2010,Naderi & Mahdavi-Nasab,Iranian Conference of Biomedical Engineering,,Islamic Azad University,4,,Classification of EEG signals,Clinical,Epilepsy,TBD,Improve SOTA,Using Elman RNN on Welch PSD on Bonn University Dataset,"On going EEG with and without seizures
(Bonn University Dataset)",Highly nonlinear dynamic mappings can be performed by RNNs and therefore have temporally extended application,,"N/M
(see dataset info)",No,Seizures,Bonn University,Public,"10
(5 healthy + 5 epileptic)",128,173.61,2 (sets) x 100 x 23.6s,Offline,,"0) Band-Pass filter: 0.53 - 40Hz  (hardware)
1) Visual Inspection + Removal of Artifacted Data",Yes,"Welch (129 features) +
Dimensionality Reduction Stats (129 --> 8 features)
(PSD)",,N/M,,Matlab,Elman RNN,,"Elman RNN to capture temporal information. Elman network has an explicit memory of one time lag with its 
""context layer""",Doing dimensionality reduction before the network to reduce parameters,Yes,"1 x 8
(assumed, not clear)","2
(assumed, not clear)",N/M,N/M,2,"Epileptic
Normal","N/M
(assuming 2)",N/M,N/M,"Levenberg-Marquard ??
(TBC)
(Gradient Descent)",N/M,N/M,N/M,N/M,LSE,Inter,N/M,"50/50
Train: 1600 (800 C1/C2)
Test: 1600 (800 C1/C2)",,"Accuracy
Specificity
Sensitivity","accuracy, specificity, sensitivity",N/M,,N/M,"Specificity: 100%
Sensitivity: 100%
Accuracy: 100%","MLP - Specif: 99.75%, Sensitiv: 98.12%, Acc: 98.93%
(Ubbeyli, 2008) Acc: 94.83%
(Nigam & Graupe, 2004) Acc: 97.2%",,N/M,N/M,"We demonstrated that Welch method power spectrum density estimation provides very strong features which well represent EEG signals. The high dimension of feature vectors increases computations. To solve this problem, statistical features were obtained from extracted feature vectors and time series EEG segment. ",N/M,No,N/A,No,---,,Yannick,[TBD],,Naderi2010
,EEG discrimination using wavelet packet transform and a reduced-dimensional recurrent neural network,2010,"Bu, Shima & Tsuji",IEEE International Conference on Information Technology and Applications in Biomedicine,,"Kumamoto National College of Technology, Japan",4,,Classification of EEG signals,BCI,TBD,TBD,New Approach: Dimensionality Reduction with RNN using Wavelet features,Using a RNN with dimensionality reduction on Wavelet features.,"Finger Taping. (BCI Motor Task, with real movement)","NN can approximate nonlinear mapping between input and output patterns, and they can be trained to adapt for variations among individuals.",,N/M,No,"Motor 
(real movement)",Internal Recordings,Private,4,9,1000,"4x3x30

4 subjects x 3 tasks x 30 trials",Offline,,"1) Spatial Filtering
2) Artifact Removal
3) Wavelet Transform
(they don't go in details)",Yes,"Wavelet
(7 Decomposition Levels)",,N/M,,N/M,"RNN
(R-LLGMN)",,Consists of a dimension-reducing stage and a time series pattern discrimination stage. This NN calculates posterior probabilities for multivariate time series patterns,N/M,Yes,"9 x t
(electrodes x time)",5,N/M,N/M,3,"Left Finger
Right Finger
Rest","1 ?
(not clear, but 1vs1 comparison)",N/M,"Two-Step Learning
(training the Dimension-reducing layers and Dimension-reducing
Time series pattern discrimination layers separately)",N/M,N/M,N/M,N/M,N/M,N/M,Intra,N/M,N/M,,Accuracy,accuracy,N/M,,N/M,"Subject A: 73.2 ± 5.8, 89.8 ± 8.0, 95.2 ± 3.2
Subject B: 94.5 ± 3.3, 93.9 ± 4.9, 85.9 ± 5.6
Subject C: 72.1 ± 7.1, 65.1 ± 10.4, 74.2 ± 9.5
Subject D: 70.4 ± 7.5, 71.3 ± 7.3, 57.3 ± 9.2",N/M,,N/M,N/M,an EEG discrimination method was developed based on the proposed NN and feature extraction using a spatial Laplacian filter and the wavelet packet transform.,N/M,No,N/A,No,---,,Yannick,[TBD],,Bu2010
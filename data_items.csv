,,,Origin,,,,,,Rationale,,,,,,,,,,Data,,,,,,,,,,,EEG processing,,,,,,Methodology,,,,,,,,,,,,,,,,,,,,,,,,,,,Results and discussion,,,,,,,,,,,,Status,,
,Title,Year,Authors,Journal/origin,Arxiv preprint?,Lab / School / Company,Nb of pages,,Domain,domain1,domain2,domain3,domain4,High-level Goal,Practical Goal,Task/Paradigm,Motivation/Reason for using DL,,Hardware,Invasive,Neural response pattern,Dataset name,Dataset accessibility,Nb Subjects,Nb Channels,Sampling Rate (Hz),Nb EEG Epochs,Offline / Online,,Preprocessing,Artefact handling,Features,Features (clean),Normalization,,Software,Architecture,Architecture (clean),Design peculiarities,EEG-specific design choices,Network Schema/Graph/Table,Input Format,Layers,Activation function,Regularization,Number of classes,Classes,Output Format,Nb Parameters,Training procedure,Optimizer,Optim parameters,Minibatch size,Hyperparameter optim,Data augmentation,Loss,Intra- or inter-subject?,Cross Validation,Data split,Performance metric(s),Training hardware,,Training Time,Results,Comparison to (benchmarks),Baseline model type,Statistical analysis of performance,Analysis of learned parameters,Discussion,Limitations/Obstacles,Code Available?,Limited Data,Others & Comments,,Analyzed by,Reviewed by,Done?
,EEG-signals based cognitive workload detection of vehicle driver using deep learning,2018,"Almogbel, Dang & Kameyama",IEEE Conference on Advanced Communication Technology,No,Waseda University,4,,Transportation,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art,,Driving Game (GTA),,,Muse,No,Raw EEG,Internal Recordings,Private,1,4,256Hz,N/M*,,,None,No,Raw EEG,Raw EEG,z-score,,N/M*,CNN,CNN,,,[TBD],"38400x4
(38400 = 150s @ 256Hz)","7 Conv
+ 3 FC",ReLU,Dropout: 50%,,,2 (Softmax),N/M*,,"RMSProp
",lr=0.002,64,N/M,N/M*,Binary cross-entropy,,"All sessions but last for training.
Last session for evaluation.",,Accuracy,N/M,,N/M,95.31%,No,None,,No,"""This study does not impose in any way a direct comparison with the distinguished previous works because the used data, experimental conditions, classification targets are different in each, but rather explore and introduce the potential of using deep CNN architecture in classifying raw EEG signals without any pre-processing.""",,No,No,24 sessions of 15 to 30 minutes over 1 month on 1 subject. Balanced dataset / classes. (is that important to report?),,Yannick,Isabela,
,Automatic ocular artifacts removal in EEG using deep learning,2018,"Yang, Duan, Fan, Hu & Wang",Biomedical Signal Processing and Control,No,"Key Laboratory of Power Station Automation Technology, Shanghai University",11,,Cleaning EEG Signals,Improvement of processing tools,Signal cleaning,Artifact handling,,Novel,,Motor Imagery,,,Neuracle Wireless 32,No,Clean EEG / Ocular artefacts,"BCI Competition IV - Dataset #1
+ Internal Recordings",Public (open),"4 (of 7 in public dataset)
+ 3 (internal)","59
32",100Hz,200 per subject * 7 = 1400,,,1) Band-Pass Filter: 0.05-200Hz,,Raw EEG,Raw EEG,min-max,,MATLAB,SAE,AE,N/M*,,Yes,100x1,3,,,,,100x1,N/M*,Greedy Layer-wise training,N/M*,,,,N/M*,RMSE,,N/M,,"RMSE of reconstructions
Accuracy on surrogate MI task ",Not mentioned,,N/M*,"RMSE is lower for proposed approach than for benchmarks, as is the accuracy on the surrogate MI task","Shallow SAE, ICA, K-ICA, SOBI",Traditional pipeline,,,"""Compared with the classical OAs removal methods, the proposed method has many highlights. [...] In the future work, we are going to improve the training method of DLN or try replacing the SAE with other neural networks such as convolutional neural networks (CNN) to strengthen its fitting ability for the details of EEG.""",,No,No,Poorly written... :( The way some elements are explained shows the authors do not really understand the methods they are using.,,Yannick,Hubert,
,An end-to-end framework for real-time automatic sleep stage classification,2018,"Patanaik, Ong, Gooley, Ancoli-Israel & Chee",Sleep,No,"Duke-NUS Medical School, Singapore
University of California, San Diego",11,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,"Improve State-of-the-Art: DL for Sleep
(CNN + MLP)",Reduce the time necessary to stage sleep recordings by using DL,Sleep,No need for feature engineering,,N/M,No,Raw EEG,Internal Recordings,Private,459,"2 EEG + 2 EOG
(the two bipolar EEG channels are then averaged)",N/M,"1,403,164 epochs",,,"1) Pass-Band Filter (FIR): 0.3-45Hz
2) Downsampled to 100Hz (polyphase FIR filter)",No,Spectrogram,Frequency-domain,N/M,,TensorFlow,"CNN + MLP
(2 Stages)",CNN,Consecutive probabilities outputted by the CNN are aggregated by the MLP ,N/M,Yes,"32x32x3
(spectrogram 2D x 3 channels) ","CNN: 16
MLP: 1","CNN: ReLU
MLP: tansig",N/M,,,"5
(Softmax)
Probability of each Sleep Stage","dCNN: 177 669 weights
MLP: 445 weights",Standard optimization,Stochastic gradient descent with Nesterov momentum,"Learning rate: 0.001
Momentum: 0.9
Learning rate decay: 10e-6","CNN: 300
MLP: 1000",Trial and error,N/M,"N/M
(Most probably categorical cross-entropy)",,N/M,"Train: 75% of DS1 & DS2
Test: 25% of DS1 & DS2
Validation: DS3, DS4","Accuracy
Cohen's kappa",NVidia GTX 1060,,N/M,"Test set: ~89.8%. kappa=0.862
Validation set 1: 81.4%, kappa=0.740
Validation set 2: 72.1%, kappa=0.597",Expert rescoring of 50 records,None,,No,"""... our framework provides a practicable, validated, and speedy solution for automatic sleep stage classification that can significantly improve throughput and productivity of sleep labs. It has the potential to play an important role in emerging novel applications of real-time automatic sleep scoring as well as being installed in personal sleep monitors.""",N/M,No,No,"Great paper, with most of the information available. Interesting experiment (slow wave entrainment)",,Yannick,Hubert,
,Epileptic Seizure Detection: A Deep Learning Approach,2018,"Hussein, Palangi, Ward & Wang",Arxiv,Yes,UBC,12,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,"Improve State-of-the-Art: DL for Epilepsy
(LSTM)","Improve performance on seizure detection with DL, on real conditions (with noise)","Resting State, Eyes Open, Eyes Closed, Seizures.",Automatically learns features,,N/M,Both,Raw EEG,Bonn University Dataset,Public (open),15,1,173.6Hz,500,,,"1) Artifacts Removed
2) Band-Pass Filter: 0.53-40Hz
(before saving the dataset... ""hardcoded"")",Yes (dataset already cleaned),Raw EEG,Raw EEG,N/M,,"MATLAB, Python
Keras with TensorFlow backend",LSTM,RNN,N/M,N/M,Yes,100x2,3,N/M,N/M,,,"2, 3 or 5",N/M,Standard optimization,Adam,LR: 0.001,64,N/M,"The added artifacts (EMG, EOG and white noise)!",Categorical Cross-Entropy,,"1) None
2) 3-, 5- and 10-fold CV","1) Train: 80%, Test: 20%
2) 3-, 5- and 10-fold","Accuracy
Sensitivity
Specificity",NVidia K40,,2h,"100% everywhere.
For Sensitivity, Specificity & Accuracy of the
2-Classes, 3-Classes & 5-Classes.
Robust to artificial artfiacts","Compared with many other SotA using the same dataset.
BNN, ME, SVM, ELM, LDA, SVM, KNN, ANN, etc.",Traditional pipeline,,No,"Compared to the state-of-the-art methods, this approach can learn the high-level representations, and can effectively discriminate between the normal and seizure EEG activities. Another advantage of this approach lies in its robustness against common EEG artifacts (e.g., muscle activities and eye- blinking) and white noise.",Unbalanced class distributions,No,No,"""To the best of our knowledge, this is the most widely used dataset for epileptic seizure detection""  (Bonn University Dataset)",,Yannick,Hubert,
,Development of a brain computer interface interface using multi-frequency visual stimulation and deep neural networks,2018,"Perez-Benitez, Perez-Benitez & Espina-Hernandez","IEEE Conference on Electronics, Communications and Computers",No,"National Polytechnic Institute, Mexico",7,,BCI,Classification of EEG signals,BCI,Reactive,SSVEP,Improve State-of-the-Art: SSVEP with CNN,Increase number of commands and reduce eyestrain in a visual BCI,SSVEP (with LEDs),Just another classifier!,,Custom-made,No,SSVEP,Internal Recordings,Private,11,3,250,N/M,,,N/M,N/M,Spectrum,Frequency-domain,N/M,,N/M,"SAE
(Sparse AutoEncoder)",AE,N/M,N/M,Yes,N/M,"SAE: 2
Final: 2",Sigmoid,"L2 regularization
Sparsity loss",,,"5
(Softmax)
Diff SSVEP Freqs",N/M,"1) Train SAE
2) Train softmax on top of SAE middle layer",N/M,"epochs: 50
lambda (L2): 0.16
gamma (sparsity): 1.0
rho: 0.1",N/M,N/M,N/M,"Mean Squared Error (SAE)
Cross-entropy (softmax layer)",,N/M,N/M,Accuracy,N/M,,N/M,97.78% (not clear if on training set or something else!),"k-NN
Naive Bayes, Bayes Kernel
Decision Tree, Random Forest, Gradient Boosted Tree
Rule Induction, MC-SVM, 
ML Perceptron",Traditional pipeline,,Yes (visualization of learned parameters),"The analysis of the DNN first layer weights reveals that there are two main patterns containing information about the SSVEPs in the power spectrums of the measured EEG signals: (i) the weights reinforces the features of the spectrum at frequencies {fst}, 3/2 {fst} and 2{fst} where fst are the frequencies of the MFVS and the other (ii) the weights reinforces the features of the spectrum at low frequencies from 0 Hz – 20Hz.",N/M,No,No,"They say that it could go up to 220 commands!!! But tested with 5 and their next step is to try with 30 commands.
Also, since they don't talk about data split, it could be that the results they report were obtained on the training set...",,Yannick,Hubert,
,Deep Semantic Architecture with discriminative feature visualization for neuroimage analysis,2018,"Ghosh, Dal Maso, Roig, Mitsis & Boudrias",Arxiv,Yes,"McGill, UdeM",11,,Other,Classification of EEG signals,Monitoring,Physical,Exercise,Improve SOTA,Study the add-on effects of exercise on motor learning,Hand motor task before and after an acute exercise,Does not require hand-engineered features,,ActiCap (BrainVision),No,"Brain Rhythms
(SMR)",Internal Recordings,Private,25,64,2500,N/M,,,"1) Band-Pass Filter: 0.5-55Hz
2) Re-reference to average.
3) Visual Inspection, noisy signal segment removed
4) ICA to remove eye blinks
5) Morlet Wavelet (wave:7, 1Hz reso)","Visual inspection to reject transient artefacts
ICA for eye blinks",Frequency Bands (55),Frequency-domain,Per-electrode spectral normalization,,"Brainstorm (MATLAB), Torch",CNN,CNN,"1) Base CNN that expects baseline and post-condition data in parallel
2) CNN that predicts class
3) Adverserial Component to penalize subject-dependent training",Base CNN: spectral-only convolutions,Yes,"64 x 55
(channels x freq bands)
[x2 since the Base CNN is used twice in a single pass]","[On TF maps, on topo maps]
BaseCNN: 2 + 1, 3 + 1
Discriminator: 2, 2
Adversary: 2, 2",ReLU,"Dropout, weight decay",,,"2
Prob of EXE
Prob of CON",N/M,Standard optimization,Adam,"[On TF maps, on topo maps]
LR: 0.001, 0.001
LR decay: 0.0001, 0.001
Weight decay: 0.001, 0.03",N/M,N/M,N/M,"Negative Log-Likelihood
 (part 1) & 
KL-Divergence (part 2)",,N/M,"Train: 80%
Validation: 20%",Accuracy,N/M,,N/M,98.70%,N/M,None,,Yes (focus of paper actually! New technique to visualize average feature maps),"""Importantly, the proposed novel method enabled us to visualize the features learnt by deep networks such as CNNs, which may in turn yield better interpretation of their classification basis.""",N/M,No,No,"Yes, yes.",,Yannick,Hubert,
,Cascade and Parallel Convolutional Recurrent Neural Networks on EEG-based Intention Recognition for Brain Computer Interface,2018,"Zhang, Yao, Zhang, Wang, Chen & Boots",AAAI Conference on Artificial Intelligence,Yes,University of New South Wales,8,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Novel Approach: Cascade & Parallel CNN and RNN,Compare Cascade and Parallel CNN + RNN on Motor Imagery Dataset (eegmmidb) to SOTA,"Motor Imagery
(see eegmmidb dataset)",To capture temporal and spatial information.,,BCI2000 Instruments,No,Motor Imagery,eegmmidb,Public (open),108,64,160,"3,145,160 EEG records",,,"1) 2D Mesh (Matrice)
2) Sliding Window (clips)
3) Normalize",No,"2D Mesh Clips
(of Raw EEG)",Raw EEG,z-score,,N/M,"Cascade / Parallel
CNN + RNN (LSTM)",CNN+RNN,CNN + LSTM combined (serial or parallel),To capture spatial and temporal resolution,Yes,"2D Data mesh

(time signal x spatial matrice)","3 CNN + 1 FC (1024)
2 LSTM (64) + 1 FC (1024)",N/M,"Dropout
(0.5)",5,5 Motor Commands,"5

(Softmax)",N/M,N/M,Adam,LR: 0.0001,N/M,N/M,N/M,Cross-Entropy,,Cross Subject Validation?,"Train: 75%
Test: 25%",Accuracy,Nvidia Titan X Pascal,,N/M,"Cascade: 0.9824
Parallel: 0.9828","(Major and Conrad 2017)  : 0.72  -   ICA
(Shenoy, Vinod, and Guan 2015) : 0.82  -  SR-FBCSP
(Pinheiro et al. 2016) : 0.85  -  SVM
(Kim et al. 2016) : 0.80  -  SUTCCSP
(Zhang et al. 2017) : 0.79  -  XGBoost
(Bashivan et al. 2016) : 0.67  -  R-CNN",DL & Trad.,,it is observed that the cascade architecture produces best performance when the hidden state size of LSTM cells is 64. This is probably because it is hard to well trained the network with larger size and smaller hidden state size has limited representation capabilities,"A large-scale dataset of 108 participants on five categories is used to evalu- ate the proposed models. The experimental results show that both the cascade and parallel architectures could achieve very competitive accuracy around 98.3%, considerably superior to the state-of-the-art methods.",N/M,No,No,"Results seem a little too good. Need to be reproduced!
98% in the BCI world for a 5 classes MI... That's too good... Very interesting! CNN + LSTM together (serial or parallel) Even when trying on the Emotiv (5 Classes MI-BCI; 93% Accuracy!!!)",,Yannick,Isabela,
,A hierarchical LSTM model with attention for modeling EEG non-stationarity for human decision prediction,2018,"Hasib, Nayak & Huang",IEEE EMBS International Conference on Biomedical & Health Informatics,No,"University of Texas, San Antonio",4,,BCI,Classification of EEG signals,BCI,Active,Mental tasks,Improve SOTA,Novel Approach: H-LSTM with Attention for Decision Classification ,"Allow or Deny Access based on ID + Image
(Guard)",No need for hand-engineered features,,BioSemi,No,Raw EEG,"BCIT Guard Duty
(US Army)",Private,18,64 (out of 256),512,"Total: 1782
Deny: 892
Allow: 890",,,"1) Downsampled to 128Hz
2) Band-Pass Filter: 0.1-55Hz",N/M,Raw EEG,Raw EEG,z-score,,N/M,LSTM,RNN,"Hierachical (from samples in first layer to epochs in second layer)
Attention mechanism","First layer acts on samples
Second layer acts on epochs",Yes,0.5s epochs,2,N/M,L2 weight decay,,,"1
Allow / Deny",N/M,Standard optimization,Adam,N/M,N/M,N/M,N/M,Cross-Entropy,,3-fold CV,"Train: 60%
Validation: 6%
Test: 33%",AUC,N/M,,N/M,"H-LSTM (w/ Attention & 0.5s epochs): 82.6%
H-LSTM (w/ Attention & 2.5s epochs): 81%
H-LSTM (w/ Attention & 5s epochs): 81.6%
H-LSTM (w/out Attention & 0.5s epochs): 80.3%
H-LSTM (w/out Attention & 5s epochs): 73.7%","SVM: 65%
CNN: 69%",DL & Trad.,,N/M,"""Using the attention mechanism does help enhance the discriminate features obtained from these epochs, although it does not help model the EEG non-stationarity"" 
""Consistent with the observation from LSTM performance, we observed an increase of performance with shorter epoch length.""",N/M,No,No,Interesting task and approach.,,Yannick,Hubert,
,Deep EEG super-resolution: Upsampling EEG spatial resolution with Generative Adversarial Networks,2018,Corley & Huang,IEEE EMBS International Conference on Biomedical & Health Informatics,No,"University of Texas, San Antonio",4,,Generating EEG Signals,Generation of data,Generating EEG,Spatial upsampling,,Novel Approach: GAN for EEG Upsampling.,,BCI Competition III - Dataset V,GANs previous great results on image super-resolution,,"N/M
(see dataset)",No,N/A,BCI Competition III - Dataset V,Public (open),3,32,512,N/M,,,1) Downsampling in the number of channels (from 32 to 16),No,None,Raw EEG,z-score,,N/M,WGAN,GAN,N/M,Convolutional layers with kernel dimensions that find the relationships between channels,Yes,"32 x 512
(channels x samples)","Gen: 6 Conv Layers
Discrim:  4 Conv Layers + 1 FC",ELU,"Dropout
(0.1 - 0.25)",,,"32 x SR
(Channels x Super Resolved)
(upsampled data)",N/M,"Pre-trained Gen fine-tuned w/
WGAN framework losses w/ gradient penalty weight of 10. 
Also, label smoothing technique",Adam,"a=10^-4, b1=0.5, b2=0.9",64,N/M,N/A,"Gen: MSE
Discrim: Distance",,Holdout,"Train: 75%
Valid: 20%
Test: 5%","MSE 
MAE 
(mean absolute error)
Accuracy, precision and recall (for classification task)",N/M,,N/M,"[Scale 2 - Test]   MSE: 2.06E3  |  MAE: 24.66
[Scale 4 - Test]   MSE: 8.68E3  |  MAE: 64.39

~10^4 fold (MSE) and ~10^2 fold (MAE) compared to Bicubic Interpolation",Bicubic Interpolated Channel Data,Traditional pipeline,,N/M,"""Feature scaling techniques besides standard normalization decreased model performance. [...] It was notably difficult and time-consuming to train GANs for EEG data. [...] After testing different variants of GAN: WGAN appeared to be more stable during training.""","""It was notably difficult and time-consuming to train GANs for EEG data""",No,No,N/A,,Yannick,Isabela,
,Spatial and Time Domain Feature of ERP Speller System Extracted via Convolutional Neural Network,2018,"Yoon, Lee & Whang",Computational Intelligence and Neuroscience,No,"Duke University
Sangmyung University",12,,BCI,Classification of EEG signals,BCI,Reactive,ERP,Alleviate BCI illiteracy,Reduce BCI illiteracy in P300 spellers by using CNNs,Rapid Serial Visual Presentation (P300 speller),"Uncover new unknown spatial/temporal patterns.
When an optimal filter is applied, the convolution will magnify the feature of interest and reduce the others [25].",,B-Alert X10,No,P300 and oddball paradigm-related EEG activity,Internal Recordings,Private,33,11,256,"6x12x20x33
6 icons
20 times each icon / trial
12 trials
33 subjects",Both,,N/M,N/M,Raw EEG,Raw EEG,N/A,,"TensorFlow
Python",CNN,CNN,-,"Layer 1: spatial correlation
Layer 2: temporal filter",Yes,"14 x 300
(channels x samples)","CNN: 2
FC: 2",ReLU,"Dropout
(0.1 - 0.25)",6,"6 different icons 
(Power On/Off, Volume Up/Down, Channel Up/Down)",2,N/M,Standard optimization,Adam,N/M,N/M,N/M,N/M,N/M,"Intra*
(*assumed... not clear)",N/M,N/M,"Accuracy, sensitivity, precision, F1 score, ROC (+ ANOVA on metrics)",N/M,,N/M,"Accuracy: 88.9 for high performing group, 68,7% for low performing group",No benchmark,None,ANOVA,Analysis of feature maps,"A P300 is not visible in all subjects, but there seems to be a P700 that is pretty consistent across subjects.
Spatial features seem to play a more important role than temporal features in the classification of an oddball task. ",-,No,No,"I don't understand how they trained their nets, per-subject or across everyone? Their whole analysis is based on grouping Low and a High performing participants, but they came up with these groups based on the performance of each group, while providing learning curves per group... So what came first?",,Hubert,Yannick,
??,Spectrographic Seizure Detection Using Deep Learning With Convolutional Neural Networks,2018,"Yan, Wang & Grinspan",Neurology,No,Well Cornell Medical College New York,,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve State-of-the-Art: Using CNN on Spectrogram for Seizure Detection,,"Existing dataset, no mention of any task.
(Supposed: Resting Sate)",,,N/M*,N/M*,"Raw EEG
(Seizure)",PhysioNet ,Public (open),"N/M*
(130 EEG with 
+ 130 EEG without)",N/M*,N/M*,"16,992 seizure containing images and 16,992 images without seizures",,,N/M*,,Medium Power Spectrogram (MPS),Frequency-domain,,,N/M*,"CNN
(4 variants of VGG16)",CNN,N/M*,,No,"Images 
(1s sliding window of MPS)",N/M*,,,,,N/M*,N/M*,,Dropout: 0.5,,,,N/M*,N/M*,,"Train: 80%
Test: 80%",,"Sensitivity
Specificity",,,N/M*,All four CNN variants achieved >98% sensitivity and specificity,N/M*,None,,,"""Convolutional neural nets can achieve high sensitivity and specificity in detecting seizures within spectrograms. However, generalizability and overfitting remains a concern. Further evaluation with more diverse data sets, images grouped by individual seizures, and additional regularization techniques is warranted.""",,[TBD],,"Can't find the actual paper, if any, seems to be just a brief description of a conf paper.",,Yannick,[TBD],
,Generating target/non-target images of an RSVP experiment from brain signals in by conditional generative adversarial network,2018,Lee & Huang,IEEE EMBS International Conference on Biomedical & Health Informatics,No,"University of Texas, San Antonio",4,,Other,Generation of data,Generating images conditioned on EEG,,,Novel Approach: generating images confitioned on EEG,Using EEG from RSVP to generate images (target or non-target),RSVP - 5 Images/s,GAN models.,,Biosemi,No,RSVP,Internal Recordings,Private,10,"32 
(out of 256 recorded)",N/M,"10 subjects 
x 5 sessions (~1h)",Offline,,"- PREP Pipeline (EEGLAB): bandpass (0.1-55 Hz), robust referencing, interpolating bad channels
- Downsampled to 32Hz
- Subset of 32 channels (visual cortex)",Yes,Raw EEG,Raw EEG,z-score,,EEGLAB,cGAN,GAN,"It's to generate the image, not the EEG data. Based on DCGAN",N/A,Yes,"32 x 32
(channels x samples)","Generator: 4
Discriminator: 4","G: Leaky ReLU
D: ReLU",N/M,N/A,N/A,64 x 64 (image),N/M,GAN Style.,N/M,N/M,16,N/M,N/M,N/M,"Inter*
(*assumed... not clear)",N/M,N/M,Visual inspection (making sure generated image is of the right class),N/M,,2-3h,Accuracy: 0.625,Generator conditioned on uniform noise from non-overlapping distribution for target and non-target classes,DL,N/M,"Occlusion of input image
(Occluding P300 part did not change anything, but before and after made the image blurry)",We demonstrated the performance of the proposed cGAN model and showed that generation with raw or normalized EEG produced better performance than that with added noise. We also showed how this model could be used for investigating the EEG and image associations.,N/M,No,No,"It uses DL on EEG as an input to generate an image. Their method doesn't seem to work well (only 0.625 accuracy on a 2-class generation problem), and their occlusion experiment shows that the network doesn't even care about the relevant features in the input data...",,Yannick,Hubert,
,Cross-Participant EEG-Based Assessment of Cognitive Workload Using Multi-Path Convolutional Recurrent Neural Networks,2018,"Hefron, Borghetti, Schubert Kabban, Christensen & Estepp",Sensors,No,Air Force Institute of Technology (Ohio),27,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Novel Approach: Using a Multi-Path Convolutional Recurrent Neural Network (MPCRNN) to improve SOTA on cross-participant classification of cognitive workload ,Tackle cross-subs variability in cognitive workload assessment,Multi-Attribute Task Battery (MATB) environment,,,BioSemi ActiveTwo,No,None,Internal Recordings,Private,8,128,4096,N/M*,,,"1) Trimmed to 303s trials
2) Downsampled to 512Hz
3) Down-selected 64 electrodes
4) PREP Pipeline to identify and interpolate bad channels, calculate a robust average reference, and remove line noise
5) High-Passe Filter: 1Hz
6) PSD 3-55Hz (2s Hanning-Windowed STFT, 1s overlap)",No,PSD - Frequency Bands (53),Frequency-domain,"[-1, 1]",,"Keras, TensorFlow","(multi-path, residual)
CNN
+
(bi-directional, residual)
LSTM",CNN+RNN,"It combines a wide multi-path, residual, convolutional networkwith a bi-directional, residual LSTM.",1x1 convolutions to act as cross-channel parametric pooling,"Yes
(Great ones!)","20x53x64
(time x frequency bands x channels)
","[very deep, see schema / paper]",ReLU and sigmoid,Dropout + batch normalization + early stopping + L1 + L2,,,"1
(Mental Workload)",N/M,Standard.,Adam,LR: from 0.0001 to 0.000001,128,N/M,N/M,Binary cross-entropy,,"Test: Hold-out 1 Participant
Training: 7-Fold Cross-Validation",,Mean Accuracy,N/M,,N/M,between 80-86% (depending on sequence length used as input),Simpler DL architectures,DL,,No,"We show that increasing sequence length—a common method to improve accuracy in non-stimulus-locked settings—increases both mean accuracy and variance at statistically significant levels for cross-participant models. Since variance grows with sequence length, increasing temporal sequence length does not adequately address the cross-participant modeling challenge: Producing high-accuracy models with low variance across participants.",N/M,No,Yes,"Great Literature Review, explaining who did what!
""Ensemble methods, CNNs, and RNNs have generally improved results. However, no comparison using different training techniques has been characterized for deep neural network models""",,Yannick,Isabela,
,Classification of auditory stimuli from EEG signals with a regulated recurrent neural network reservoir ,2018,"Moinnereau, Brienne, Brodeur, Rouat, Whittingstall & Plourde",Arxiv,Yes,Université de Sherbrooke,5,,BCI,Classification of EEG signals,BCI,Reactive,Heard speech decoding,Improve SOTA,Classify heard speech (vowels) from EEG,Auditory Stimuli + Imagined Speech,Can extract features automatically,,ActiCap + BrainAmp,No,Raw EEG,Internal Recordings,Private,8,64,N/M,4800,Offline,,"1) Pass-Band Filter: 0.1-45Hz
2) Re-sampled at 500Hz
3) Windows of 2s (stimulus at 0.5s)
4) Trials with Amplitude > +-75uV rejected
5) Re-reference to local average",Yes (amplitude thresholding),"Spike Train from
Ben’s Spike Algorithm (BSA) ",Other,N/M,,Python,RNN Reservoir,RNN,The reservoir comprises 512 neurons placed in a three-dimensional grid where 80% are excitatory and 20% are inhibitory neurons,N/M,"Yes
(not explicit enough)",Spike Trains per channel,N/A,Leaky Integrate-and-Fire,N/M,3,"""a"", ""i"", ""u""",1,N/M,"Reservoir: unsupervised tuning
Classifier: linear regression",N/M,N/M,N/M,N/M,N/M,N/M,Intra,5-Fold CV,"Train: 4/5
Test: 1/5",Accuracy,N/M,,N/M,"83.2% (64 electrodes)
1 Electrode: 57.3% 
3 Electrodes: 71.4% 
10 Electrodes: 81.7%
[Chance: 33%]","CNN
(3 conv layers of 64 filters)",DL,N/M,N/M,"""It’s hard to compare these results with the previ- ous work where many different experimental conditions (e.g. different type and number of stimuli) and preprocessing has been used. However, we show here that excellent classifica- tion results can be obtained with minimal preprocessing of the EEGs.""",N/M,No,No,"I don't know about the BSA algo to get the features.
The Reservoir Idea seems interesting.",,Yannick,Hubert,
,Deep learning for detection of epileptiform discharges from scalp EEG recordings,2018,"van Putten, de Carvalho, Tjepkema-Cloostermans",Clinical Neurophysiology,No,University of Twente,,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve State-of-the-Art: Using CNN and/or LSTM to classify yes/no discharges.,,"Pre-Recorded EEG, no mention of any task.
(Supposed: Resting Sate)",,,,No,"Raw EEG
(Epileptiform Discharges)",[TBD],Private,"N/M*
(100 EEG recordings)",19,N/M*,"Training: 41381
Test: 8775
Valid: 47122 (discharge)
Valid: 11782 (normal)",,,1) Band-Pass Filter: 0.5-35Hz,,Raw EEG,Raw EEG,,,"Keras, Theano","CNN
RNN",CNN+RNN,Multiple designs,,No,19 channels x 2s epoch,"CNN: 4-9 Layers
LSTM: 50-100 Units
Both w/ 1-3 FC Layers",,Dropout,,,"1
(prob [0,1] of discharge)",N/M*,,,,,,N/M*,N/M*,,N/M*,,"AUC
Sensitivity
Specificity",NVidia GPU,,60 min,"AUC: 0.86-0.92
Sensitivities from 20% to 80% with Specificities between 95% and 100%",N/M,None,,,"We foresee that deep nets may outperform humans both in classifi- cation accuracy and speed, leading to a fundamental shift in clinical EEG analysis in the next decade.",,No,,N/M*,,Yannick,[TBD],
,"Cognitive Analysis of Working Memory Load from EEG, by a Deep Recurrent Neural Network",2018,"Kuanar, Athitsos, Pradhan, Mishra & Rao",ICASSP,No,"University of Texas, Arlington",5,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art: Using RNN to measure levels of cognitive load.,"Extract features less sensitive to
variations along each spatial dimension","Working memory / workload experiment.
(showing a set of letters and then showing a letter asking if the letter was part of the set) Sets of 4,6,8,10 letters corresponding to mental workload 1,2,3,4.",ConvNets have demonstrated the ability to extract features that are invariant to changes in input patterns,,"Neurofax EEG-1200 
(Nihon Kohden)
",No,PSD,NIMHANS,Private,22,64,256,N/M,,,1) From 4.5s Windows to 9 Windows of 0.5s,No,"192 Features: 64 chan x 3 bands
Theta (4-7Hz), Alpha (8-13Hz), Beta (13-30Hz) (FFT)
Converted into images. (32x32)
3D electrodes spatial to 2D.",Frequency-domain,N/M,,"Theano, Python",CNN + BiLSTM,CNN+RNN,"Transforming channels and frequency bands into images of 0.5s windows, fed to an Hybrid CNN+BiLSTM",N/M,Yes,"EEG Images 32x32
(0.5s windows)
(mixing 3 freq bands + 64 channels)","9 Conv Layers + 1 FC
+ 2 LSTM Layers of 64 units + 1 FC",Sigmoid,Dropout (0.5) + L2 (0.0001),,,"4 Classes
(Softmax)",1.66 Mil,Standard,Adam,"LR: 10^-4
Beta1: 0.9
Beta2: 0.99",30,N/M,The data was augmented by adding Gaussian noise to the image. We experimented with various noise levels.,Cross-Entropy,,"Leave-Subject-Out Cross-Validation
(22 Folds)",,Accurary,NVidia K40,,18h,92.50%,"SVM, Logistic Regression, Random Forest
CNN+LSTM, CNN+LSTM+1Conv",DL & Trad.,,N/M,"""Our implementation was different from the previous attempts and learned the robust representations from EEG image sequences using a ConvNet and BiLSTM hybrid network. Our proposed hybrid network demonstrated the significant improvements in finding better classification accuracy i.e. up to 92.5% over various existing LSTM models.""",N/M,Yes,No,N/M*,,Yannick,Isabela,
,A Deep Learning Approach with an Attention Mechanism for Automatic Sleep Stage Classification,2018,Längkvist & Loutfi,Arxiv,Yes,"Center for Applied Autonomous Sensor Systems, Orebro University",18,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,"New approach: ""Explore the advantages of using a model qith selective attention applied to automatic sleep staging""",Learn representations of sleep EEG with attention,Sleep (PSG),Learn better features,,N/M,No,Sleep,St. Vincent's University Hospital / University College Dublin Sleep Apnea Database,Public (open),25,"1 EEG (out of 2)
+ 1 EMG
+ 2 EOG",128,N/M,Offline,,"1) Notch Filter: 50Hz
2) Down-Sampled to 64Hz
3) Band-Pass Filter: 0.3-32Hz",N/M,"28 Features: Relative Power: Delta (0.5 − 4Hz), Theta (4−8Hz), Alpha (8−13Hz), Beta (13−20Hz), & Gamma (20−32Hz), Entropy, Kurtosis, and Spectral Mean of all signals and fractal component of EEG.  [+ EOG & EMG features]",Frequency-domain,z-score,,N/M,SAE,AE,"Attention Mechanism
(static & adaptive approaches)",N/M,No,28,1,Sigmoid,"L2 normalization
KL term in cost function for sparsity",5,"SWS, S2, S1, REM, Awake","5 Classes
(Softmax)",N/M,"1) Training AE
2) Training softmax layer on learned features",SGD with momentum,"Momentum: 0.9
LR decay: 0.01",30,Random grid search,N/M,MSE,Inter,5-fold random CV,"Train: 60%
Valid: 20%
Test: 20%",Accurary,N/M,,2-3h,60-90% on each of the 5 classes.,"DBN
SAE (standard a)
SAE (fixed a)
SAE (adaptive a)",DL,N/M,Visualization of attention mechanism weights,"""[...] Many of the used features try to capture the most relevant information for the current sleep stage and therefore mimic the standard Rechtschaffen and Kales (R&K) system [38, 18, 17] that is manually used by sleep technicians.""",Unsupervised learning treats all features equally; that's why attention mechanism is useful,No,No,"Not clear how the attention and the recurent network is used with the SAE.
[Hubert]: They mention the RNN once and then forget about it! I think that's probably a mistake that will be corrected in the next version of their paper.",,Yannick,Hubert,
,On the Classification of SSVEP-Based Dry-EEG Signals via Convolutional Neural Networks,2018,"Aznan, Bonner, Connolly, Moubayed & Breckon",Arxiv,Yes,Durham University,6,,BCI,Classification of EEG signals,BCI,Reactive,SSVEP,Improve State-of-the-Art,Apply CNN to SSVEP with dry EEG headset,SSVEP,Want an end-to-end system (no need to extract features),,Quick-20 (Cognionics),No,SSVEP,Internal Recordings,Private,4,20,500,"Collected: 640
For first subject: 400
For cross-subject: 80",,,None,No,None,Raw EEG,N/A,,Pytorch,CNN,CNN,-,Layer 1: temporal filter,Yes,N/M,"2
(Tried 7 in the end)",ReLU,"L2 normalization
Dropout (50%)",,,4,N/M,Standard optimization,Adam,N/M,32,Grid search over validation set,-,Categorical cross-entropy,,"Experiments 1, 2, 3: 10-fold CV
Experiment 4: Leave-one-subject-out
",N/M,Accuracy,Nvidia GTX 1060,,4 min,"Subject 1 - all data: 96%
Subject 1-3 (individually, only 20 trials each): mean of 89%
Across-subjects: 78%
Leave-one-subject:out:59% ","Traditional feature-based pipeline (Riemannian Geometry + classifier)
RNN, LSTM, GRU",DL & Trad.,,No,Repeating the convolutional layer block increased accuracy on the held-out subject.,N/M,No,Yes,"Their benchmark results look a bit weak, knowing that they used RG...
The paper only mentions at the very end that they tried a deeper net too.",,Hubert,Isabela,
,A Long Short-Term Memory deep learning network for the prediction of epileptic seizures using EEG signals,2018,"Tsiouris, Pezoulas, Zervakis, Konitsiotis, Koutsouris & Fotiadis",Computers in Biology and Medicine,No,National Technical University of Athens,14,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Prediction,"New Approach: Using LSTM for seizure detection. (claiming they are the first ones but they are not, so its a Improve SOTA)",Apply LSTM for seizure detection on CHB-MIT,"Resting State, Eyes Open, Eyes Closed, Seizures.","Expand from CNN to LSTM. (they claimed to be first, but they are not...)",,"N/M*
(see dataset paper)",No,Seizures,"CHB-MIT 
(PhysioNet)",Public (open),23,23,256,"~980 hours of EEG
185 seizures",,,"1) Selecting only channels that are stable across recordings (for cross-validation)
2) Kept 18 channels.",No,"Time Domain: the 4 Statistical Moments, Standard Dev, Zero Crossings, Peak-to-peak Voltage, Total signal area, decorrelation time.
Frequency Domain: FFT (PSD), DWT.
Cross-Correlation: Max absolute coefficient.
Graph Theory: Local & Global measures.
(all on 5s windows)",Combination,N/M,,"Keras
Tensorflow
Python 3.6",LSTM,RNN,-,LSTM Length: predicting seizures from 15 min before onset to 120 min before onset,Yes,"Features x EEG Segments

643x[5-50]","LSTM_1: 1 (32 HU)
LSTM_2: 1 (128 HU)
LSTM_3: 2 (128/128 HU)

+ 1 FC (30)",ReLU,"Dropout
(finally discarded, because the shuffling of data seems to be enough)",,,"2
(Softmax, 1 hot encoded: preictal or interictal)",N/M,"By shuffling the EEG segments that are used as input, the LSTM network is forced to learn more generic preictal patterns as each sequence consists of random, non-adjacent preictal segments that not only come from various locations with different time distances from the actual seizure onset, but also from the preictal activity of different seizures.",Adam,"LR: 0.001
B1: 0.9
B2: 0.999
Decay: 0",10,Manually trying 3 different configurations,"To overcome class imbalance issues but still use the entire volume of the available EEG data for a more complete evaluation, the interictal EEG signals are split into smaller subgroups that match the duration of the preictal class.",Cross-Entropy,,10-Fold CV,"Eval: 3/24 
Train: N/M* 
(assuming 21/24)","Sensitivity (SEN)
Specificity (SPEC)
False Prediction Rate (FPR)
Preictal Window","N/M
(he seems to say CPU)",,N/M,"[Segments] SEN, SPEC |  [Events] SEN, FPR

15-min Preictal Window: 99.28, 99.28 |  100, 0.107
30-min Preictal Window: 99.37, 99.60 |  100, 0.063
60-min Preictal Window: 99.63, 99.78 |  100, 0.032
120-min Preictal Window: 99.84, 99.86 |  100, 0.02","SVM
Decision Trees
Repeated Incremental Pruning to Produce Error Reduction (RIPPER)

(LSTM outperforms all of them on all subjects)",Traditional pipeline,,"Yes, going in depth on the 3 different LSTM networks they tried.","In theory, better EEG signal representation could be learned if the size of LSTM network was substantially increased, by adding more layers and memory units, to compensate for the increased input size of directly providing the EEG signals. However, the computational cost of training larger LSTM networks increases rapidly requiring more training time or using arrays of GPUs. Even if computational cost was not a problem, this approach would require even more EEG data to effectively train the millions of network parameters.","1) Overal amount of Data
2) Number of Seizures",No,Yes,"All Papers need to describe their network that way!
They compared 3 different LSTM
They compared feature-based vs learned features and Raw EEG underperforms feature-based.",,Yannick,Isabela,
,Joint Classification and Prediction CNN Framework for Automatic Sleep Stage Classification,2018,"Phan, Andreotti, Cooray, Chén & De Vos",Arxiv,Yes,University of Oxford,11,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,"Improve State-of-the-Art
(~New task: predict neighboring classes too)",Use one-to-many approach with a multi-task softmax to leverage neighboring data to predict sleep stage,Sleep,"Re-using their previous network.
(H. Phan et al., 2018)",,N/M*,No,Sleep events,MASS dataset,Public (account),200,"1 EEG
1 EMG
1 EOG",100,"228,870",Offline,,"1) Convert 20s epochs in 30s epochs
    (+5s before + 5s after)",N/M,"Spectrogram (STFT)
Hamming window 2s + 50% overlap
Log Spectrum",Frequency-domain,N/M*,,Tensorflow,CNN,CNN,Conv-Pool-Softmax,Layer 0: filter bank on spectrogram,Yes,"129 x 29 x {1, 2, 3}
Bins x time, x channels
30-s epochs","1

(1xCNN +Pooling +Softmax)",ReLU,"L2
Dropout (20%)",5,"Wake
N1, N2, N3
REM",5 x (1 + 2 * nb of neighbouring windows),N/M*,Standard optimization,Adam,LR: 0.0001,200,N/M,N/M*,Categorical cross-entropy,Inter,"Leave-p-subjects-out
20 folds
","Train: 180 subjects
Valid: 10 subjects
Test: 10 subjects","Accuracy, Kappa, Specificity, Sensitivity, F1-score",N/M*,,1.36 hours,Multimodal acc.: 83.6 %,"One-to-one and Many-to-one with same architecture and with a different ConvNet architecture without l-max pooling
DeepCNN
DeepSleepNet",DL,No,No,"Increasing the number of filters in the Conv layer doesn't impact the performance much
Adding other modalities (EOG, EMG) lead to significant improvements
A context size larger than 3 leads to performance degradation
Using recurrent layers might help",No,No,No,"1. Not sure how their first ""filter-bank"" layer works. Seems to be omitted from their network graph figure.
2. Is this really a deep net? Looks like a 1-layer ConvNet to me.",,Hubert,Yannick,
,Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals,2018,Wen & Zhang,IEEE Access,No,Xiamen University,12,,Epilepsy,Improvement of processing tools,Feature learning,,,Improve SOTA,Learn features for epilepsy detection using unsupervised learning,"Resting State, Eyes Open, Eyes Closed, Seizures.",Learn features automatically,,"N/M
(see dataset papers)",Both,Raw EEG,"Dataset 1: Bonn University Dataset
Dataset 2: CHB-MIT",Public (open),"D1: 10? (Some healthly, some epileptic, some with intracranial EEG)
D2: 23","Chose a single channel
[D1: 128
D2: 23]","D1: 173.61
D2: 256",500,Offline,,"1) Common average reference
2) Bandpass 0.53-40 Hz",N/M,1) Chose single channel with the most variance,Raw EEG,min-max,,"Scikit-learn
Python",Convolutional AE,AE,Various (tried multiple classifiers on top of the encoder),-,Yes,4096 x 1,"9
[YR: not sure how HJB got that 9]",ReLU,N/M,2,"Seizure
No Seizure

(not explicit)",4096 x 1,N/M,"1) Training AE
2) Training standard classifier on learned features",Adam,N/M,N/M,N/M,N/M,Mean absolute error divided by input mean amplitude,Both,5-fold CV,N/M,Accuracy,N/M,,N/M,"No aggregate is reported...

(see paper, they report results per subject and per classifier)","PCA
Random projection",Traditional pipeline,No,No,"Less than 4 hidden units on the bottleneck layer led to a drop in accuracy as compared to standard dimensionality reduction techniques.
Their approach is flexible to new datasets...","""It is very difficult to train multiple hidden layers [...]"" ",No,No,"Interesting approach, but only used one channel!",,Hubert,Yannick,
,Deep learning with convolutional neural networks for decoding and visualization of EEG pathology,2018,"Schirrmeister, Gemein, Eggensperger, Hutter & Ball",Arxiv,Yes,University of Freiburg,7,,Other Pathology*,Classification of EEG signals,Clinical,Pathological EEG,,Improve SOTA ,End-to-end detection of abnormal EEG,N/M,Automated EEG diagnosis,,N/M,No,Raw EEG,TUH Abnormal EEG Corpus,Public (account),2385,21,250,"Abnormal: 1361 (train), 127 (test)
Normal: 1379 (train), 150 (test)",,,"1) Select 21 electrodes common to all subjects 
2) Remove 1st minute
3) Crop to recording to up to 20 minutes
4) Clip amplitude to +-800uV
5) Resample to 100Hz",N/M,Raw EEG,Raw EEG,N/M,,Pytorch,CNN,CNN,Tried two architectures: shallow and deep CNNs,Shallow CNN tailored to decode band powers,Yes,600 x 21,"Deep: 5 conv layers
Shallow: 1 conv layer",ELU,N/M,,,2,N/M,Standard optimization,Adam,Used SMAC ,N/M,SMAC ,N/M,Binary cross-entropy,,10-fold CV,"Train: ~90%
Test: ~10%","Accuracy, Sensitivity, and Specificity",N/M,,< 3.5 h,"Accuracy: 85.4% (deep), 84.5% (shallow)
Sensitivity: 75.1% (deep), 77.3% (shallow)
Specificity: 94.1% (deep), 90..5% (shallow)",CNN and linear model with band-power features as input,DL & Trad.,,Effect of spectral perturbations of the input on the resulting prediction,"Perturbation visualizations showed that the CNNs used information related to changes in delta and theta bands. Suprisingly, shorter length EEG recordings yielded better accuracies.","""Still, to yield more clinically useful insights and diagnosis explanations, further improvements in ConvNet visualizations are needed.""",Yes,No,Performed an architecture search that provide non-intuitive models. Best architecture did not reach significantly better performance. ,,Isabela,Hubert,
,Predicting sex from brain rhythms with deep learning,2018,"van Putten, Olbrich & Arns",Scientific Reports (Nature),No,University of Twente,7,,Other,Classification of EEG signals,Personal trait/attribute,Sex,,New Approach: Detecting Sex from RS EEG with DL (CNN),Predicting an individual's sex from their EEG,Resting State EEG.,"No need for engineered features, and ""have potential to detect subtle differences in otherwise similar patterns"".",,N/M,No,Raw EEG,Brain Resource International Database,Public (account),1308,24,128,"52320
(Train: 40000)
(Test: 12320)",,,"1) Downsampled to 128Hz (from 500Hz)
2) Band-Pass Filter: 0.5-25Hz",EOG regression,Raw EEG,Raw EEG,N/M,,"Windows 10
Keras, Tensorflow
Python 3.6",CNN,CNN,None,N/M,Yes,"256 x 24
(Samples x Channels)
2s epoch",6,ReLU,Dropout,,,"1
0: Female  |   1: Male
(2 from schema)","9,051,902",Standard optimization,Adamax,"LR=0.002, B1=0.9, B2=0.999, e=10^8, decay=0.00",70,N/M,N/M,Categorical Cross-Entropy,,No CV,"Train: 1000 subjects
Test: 308 subjects",Accuracy,NVidia GTX-1060,,N/M,"81% 
(of correct classification over all subjects)",CNN with precomputed features (from other paper),DL,,Visualization of learned filters through Deep Dream-like backprop on inputs,"While not all details of the features used for classification by the deep net have been revealed, our data show that differences in brain rhythms between sexes are mainly in the beta frequency range.",N/M,No,No,They also say that DL for Epilepsy might become the standard.,,Yannick,Hubert,
,Deep learning with EEG spectrograms in rapid eye movement behavior disorder,2018,"Ruffini, Ibanez, Castellano, Dubreuil, Gagnon, Montplaisir & Soria-Frisch",BioarXiv,Yes,"NeuroElectrics
University of Montreal",10,,Other Pathology*,Classification of EEG signals,Clinical,Sleep,Abnormality detection,New Approach,Using DCNN for Rapid Eye Movement Behavior Disorder,Resting State EEG.,Exploiting compositional structure in data,,N/M,No,"
Raw EEG",Internal Recordings,Private,"118 RDB
74 Healthy",14,256,N/M,Offline,,"1) Band-Pass Filter: 0.3 and 100 Hz  [Hardware]
2) Notch Filter: 60Hz [Hardware]
((FFT) after detrending blocks of 1 second with a Hann window (FFT resolution is 2 Hz))",N/M,Spectrogram Frames,Frequency-domain,z-score,,Tensorflow,DCNN,CNN,Conv-Pooling-Dropout,N/M,Yes,"14 x 21 x 20
Channels x FFTBins x Epochs",5,ReLU,Dropout,2,"Parkinson's disease
Healthy",2,N/M*,Standard optimization,N/M,N/M,N/M,N/M,N/M,Cross-Entropy,Inter,"For training, datasets were balanced for subjects by random replication of subjects in the class with fewer subjects. For testing, we used a leave-pair-out strategy (LPO [2]), with one subject from each class.",N/M,"Accuracy
AUC",N/M,,N/M*,"Net: Problem [ N ] ACC (AUC)
DCNN: HC vs PD [2x73 / 2x1]   79% (87%)
RNN: HC vs PD [2x73 / 2x1]     81% (87%)
DCNN: HC+RBD vs PD+DLB [2x159 / 2x1]   73% (78%)
RNN: HC+RBD vs PD+DLB [2x159 / 2x1]     72% (77%)","Stacked RNN
Shallow CNN",DL,No,Yes (by maximizing network outputs for a given class). ,"Although here, as in [28], we worked with time-frequency pre-processed data, the field will undoubt- edly steer towards working with raw data in the future when larger datasets become available—as suggested in [21]","""We note that one of the potential issues with our dataset is the presence of healthy controls without
follow up, which may be a confound. \We hope to remedy this by enlarging our database and by
improving our diagnosis and follow up methodologies""",No,Yes,N/M*,,Yannick,Isabela,
,Deep transfer learning for error decoding from non-invasive EEG,2018,"Völker, Schirrmeister, Fiered, Burgard & Ball",IEEE International Conference on Brain-Computer Interface,Yes,University of Freiburg,6,,BCI,Classification of EEG signals,BCI,Reactive,ERP,New approach: Exploring Transfer Learning for BCI.,"Using CNN on 2 different BCI tasks, can it generalize? Transfer Learning across subjects and across tasks","1) Eriksen Flanker Task
2) Online GUI to control intelligent robots",Enables transfer learning,,N/M,No,"1) Error
2) Mental tasks (MI)",Internal Recordings,Private,"1) 31
2) 4","1) 128
2) 64",N/M,"1) N/M
2) (3032 +/- 818) * 4",,,"1) Re-referenced to Common Average (CAR)
2) Resampled to 250Hz",N/M,Raw EEG,Raw EEG,Electrode-wise exponential  running standardization,,"Python
BrainDecode
Scikit-learn",CNN,CNN,N/M,"N/M
(see BrainDecode paper)","No
(See BrainDecode paper)","N/M
(Raw EEG windows)","N/M
(see BrainDecode paper)",N/M,"N/M
(see BrainDecode paper)",,,N/M,N/M,"N/M
(See braindecode paper)","N/M
(see BrainDecode paper)",N/M,N/M,N/M,N/M,"N/M
(see BrainDecode paper)",,"1) Within-subject decoding: N/M
2) Between-subject transfer learning: Leave-one-subject out",N/M,Normalized Accuracy,N/M,,N/M,"Between-Subject Transfer Learning
Flanker Task:  81.7%  Normalized Accuracy
GUI Robots Task:  Poor results, because only 4 subjects.
Between-Paradigms Transfer Learning
Both failed. ~50%","rLDA
(CNN outperforms rLDA)

Also, best result ever reported on the Error Detection on Flanker Task*",Traditional pipeline,,Input-perturbation network-prediction correlation maps,"(1) As a next step, techniques including data augmentation and automated hyper-parameter and architecture search might help to improve the generalization of deep ConvNets. (2) For a generalization to new subjects, our data suggest that a training subject group of at least 15 subjects might be necessary for reliable error decoding on unknown subjects. (3) In the flanker task, our deep ConvNets achieved the highest to date reported average accuracy.",N/M,No,Yes,"Interesting to see that after 15 subjects the gain isn't that much.
Lots of information is not included in the paper and can be found in the original braindecode paper.",,Yannick,Hubert,
,DeepIED: An epileptic discharge detector for EEG-fMRI based on deep learning,2018,"Hao, Khoo, von Ellenrieder, Zazubovits & Gotman",NeuroImage: Clinical,No,"McGill University, Osaka University",14,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,Detect interictal epileptic discharges in noisy EEG data collected during an fMRI recording,Resting state EEG - Seizures.,Reduce the amount of time it takes to manually label interictal epileptic discharges,,Brain-Amp,No,Raw EEG,"Internal Recordings
(2004-2016 recordings)",Private,67,25,200,N/M,Offline,,"1) Bandpass 0.5-50 Hz
2) fMRI-induced artefact removal
3) Electrode-wise exponential running standardization [6] was applied with a decay factor of 0.999
4) BCG artifact removal (ballistocardiographic)",N/M,Raw EEG,Raw EEG,N/M,,N/M,CNN (ResNet),CNN,-,-,Yes,25 x [16 to 256],31,ReLU,Dropout on penultimate layer (50%),"N/M
(different EID types)",EIDs,"128 (FC)
going to softmax and triplet (real output N/M)","999,920",Standard optimization,N/M,N/M,N/M,N/M,N/M,"Softmax for multi-class classification
Triplet loss function",Inter,No CV,"Train on 30 subject
Test on 37 subjects","ROC curves
Sensitivity
False positive rate
t-tests on sensitivity",N/M,,N/M,"Median sensitivity: 84.2%
False positive rate: 5 events/min",Cross-correlation (template-based) method for finding similar EEG epochs,Traditional pipeline,,-,"In their tests, they asked experts to edit the outputs of the net and reject false positives; they argue that it's a necessary step and that it is not too time-consuming.",-,No,No,Good example of using DL as a clinical assistant tool.,,Hubert,Yannick,
,Deep learning for hybrid EEG-fNIRS brain–computer interface: application to motor imagery classification,2018,"Chiarelli, Croce, Merla & Zappasodi",Journal of Neural Engineering,No,G. d'Annunzio' University,12,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Improving MI classification with DL in multimodal system,Motor Imagery,High performance on other tasks,,Electrical Geodesic,No,ERD/ERS,Internal Recordings,Private,15,123 (out of 128),250,3000,Offline,,1) Bandpass 8-30 Hz,N/M,"Power in the mu-beta range, averaged across 1-s",Frequency-domain,N/M,,TensorFlow,Fully-connected NN,FC,N/M,N/M,Yes,"123 x 1, 16 x1, or 139 x 1",5,ReLU,Dropout (0.75),2,"Right-hand MI, Left-hand MI",2,N/M,Standard optimization,Adam,"LR=1e-4, B1=0.9, B2=0.999, constant=1e-8",90,N/M,N/M,Cross-Entropy,Intra,1000x 10-fold,"Train: 180
Test: 20",Accuracy,N/M,,N/M,"EEG only: ~70%, NIRS only: ~77%, EEG+NIRS: ~83%","LDA, linear SVM",Traditional pipeline,"2-way repeated measurement ANOVA
+ post-hoc analysis ",N/M,"DNN worked better than CNN, RNN not tested.",RNN was not tested,No,No,NIRS alone is better than EEG alone!,,Hubert,[TBD],
,Preference Classification Using Electroencephalography (EEG) and Deep Learning,2018,"Teo, Hou & Mountstephens","Journal of Telecommunication, Electronic and Computer Engineering (JTEC)",No,University Malaysia Sabah,5,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,New Approach: Using DBN to classify preference [...],,"Rating of 3D Stimulus (1: like very much, 2: like, 3: undecided, 4: do not like, 5: do not like at all)  
~ 20s epochs (3s rest - 5-15s viewing - 6s rating) ",,,ABM B-Alert X10,No,Raw EEG,Internal Recordings,Private,10 + 16,9,N/M*,"960 Total, used 208 (using only strongest preference in task, i.e. 1 specific class)",,,"1) Notch Filter: 50Hz
2) 5 Physiological Artifacts Removal
3) Artifacts replaced by 0s.
4) Spline interpolation to replace 0s with values.

* Usin B-Alert (ABM) SDK in Matlab to clean the signal.",," 45 features
(PSD for each channel)
D (1-3Hz), T (4-6Hz), A (7-12Hz), B (13-30Hz), G (31-64Hz)",Frequency-domain,,,"Java, Matlab, R",DNN,FC,"200 hidden neurons
AF: ReLU",,No,"47 x 208
47: ID, Rating + 45 features
208: Observations (epochs)",2,,,,,"[Not Mentioned]
(probably 5 classes)",N/M*,,"Uniform adaptive method for init weights.

Adadelta 
(Adaptive learning rate)",,,,N/M*,Cross-Entropy,,10-Fold Cross-Validation,,Accuracy,,,N/M*,63.99%,"SVM Linear: 60.19%, SVM Radial:  59.67%, OneR: 59.00%, Adaboost: 58.65%, Random Forest: 57.74%, NNet: 57.71%, JRip: 57.21%, Naive Bayes: 56.79%, C5.0: 56.74%, kNN (k = 5): 56.29%       ",Traditional pipeline,,,"An initial study using kNN provided sufficiently good results in a 10-subject study. However, when expanded to a larger cohort size of 16 subjects, the results were not encouraging. However, the use of deep learning was able to observably overcome some of the difficulties presented by inter-subject variability posed by larger cohort sizes in EEG-based preference classification.",,No,No,N/M*,,Yannick,[TBD],
,An Automated System for Epilepsy Detection using EEG Brain Signals based on Deep Learning Approach,2018,"Ullah, Hussain, Qazi &Aboalsamh",Arxiv,Yes,"National University of Ireland
King Saud University",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach: Using P-1D-CNN to classify Epilepsy,,"Resting State, Eyes Open, Eyes Closed, Seizures.",,,N/M*,No,Raw EEG,Bonn University Dataset,Public (open),15,1,N/M*,N/M*,,,None. (Splitting in overlapping windows),,"Raw EEG
(~8 Windows)",Raw EEG,,,TensorFlow,Pyramidal 1D-CNN (P-1D-CNN),CNN,"Input Normalization. Convolutional, batch normalization, ReLU, fully connected and dropout layers.

n 1D-CNNs (1 for each time window), with a voting system",,Yes,"8 EEG windows
Raw EEG (1 channel)",3 Conv + 2 FC,,,,,"2 or 3 Classes
(Softmax)",N/M*,,"Adam, learning rate (0.001), beta1 (0.9), beta2 (0.999), epsilon (0.00000001), locking (false). Dropout 0.5",,,,They proposed 2 (new) methods for data augmentation,Cross-Entropy,,10-Fold Cross-Validation,,"Accuracy, Specificity, Sensitivity, Precision, f-measure, and g-mean.",,,N/M*,"99.1 ± 0.9% (for 3 classes problem)

The mean accuracy of the proposed system is 99.6% for all the sixteen cases/

Many results (see papers) comparing Binary / Tenary classifications.","Random forests, Naive Bayes, kNN",Traditional pipeline,,,"According to our knowledge until this date, DL approach has never been used for this problem. The mean accuracy of the proposed system is 99.6% for all the sixteen cases (shown in Table 8 last column), which figures out the generalization power of the proposed system.",,No,Yes,N/M*,,Yannick,[TBD],
,A Novel Channel-aware Attention Framework for Multi-channel EEG Seizure Detection via Multi-view Deep Learning,2018,"Yuan, Xun, Ma, Suo, Xue, Jia & Zhang",IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),,"Beijing Laboratory of Advanced Information Network
State University of New York at Buffalo",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach: Attention Mechanism to select channel.,,"Existing dataset, no mention of any task.
(Supposed: Resting Sate)",,,N/M*,[TBD],Raw EEG,CHB-MIT ,Public (open),23,23,256Hz,N/M*,,,short-time Fourier Transform (STFT),,Spectrogram,Frequency-domain,,,N/M*,Multi-view DL,AE,"Channel Encoders (SAE)
Global Encoder (SAE)
+ Attention",,Yes,Channel x EEG Time-Freq,[TBD],,,,,1,N/M*,,"Adam, Regularization, Normalization, drop-out, mini-batch ",,,,N/M*,Cross-Entropy,,hold-out validation,,"F1-Score
Accuracy",,,N/M*,"[F1-score] - Channel Attloc:  0.9781, Channel Attglo: 0.9785
[Accuracy] - Channel Attloc:  0.9651, Channel Attglo: 0.9661","PCA+SVM (PSVM)
SAEs",DL & Trad.,,,"""To the best of our knowledge, this is the first work using attention mechanism for biosignal channel selection in healthcare.""",,No,No,Attention Mechanisms! I was wondering when we'd see some attempts.,,Yannick,[TBD],
,Compact Convolutional Neural Networks for Classification of Asynchronous Steady-state Visual Evoked Potentials,2018,"Waytowich, Lawhern, Garcia, Cummings, Faller, Sajda, Vettel",Arxiv,Yes,"U.S. Army Research Laboratory
Lab for Intelligent Imaging and Neural Comp.
University of Pennsylvania
University of California, Santa Barbara",,,BCI,Classification of EEG signals,BCI,Reactive,SSVEP,New Approach: Compact CNN for SSVEP,,SSVEP (12 classes!),,,BioSemi ActiveTwo,No,SSVEP,Internal Recordings,Private,10,8,2048Hz,N/M*,,,"1) Pass-Band Filter (Butterworth): 9-30Hz
2) Downsampled to 256Hz",,Raw EEG,Raw EEG,,,"TensorFlow, Keras
Original Stimuli (from 2015) on MATLAB with Psychophysics Toolbox",EEGNet,CNN,"Batch-Norm, Pooling, Dropout",,"Yes of the ""big picture"", but not of the Neural Network itself",8 channels x 1s window,4,,,,,"12
(softmax)
",N/M*,,"Adam
Mini-batch 64
Dropout 0.25",,,,"N/M*
(they splitted 4s epoch in 1s seg)",Categorical Cross-Entropy,,Leave-one-subject-out,,Accuracy,,,N/M*,"~90% for 7/10 Subjects.
60%, 75%, 30% for the others.
(chance = 8%)","CCA 
(Canonical Correl. Analysis)
C-CCA (Combined CCA)",Traditional pipeline,,,"""Although unexpected, these within-class clusters highlight the strength of the deep learning approaches to learn diagnostic features directly from the data.""",,No,No,Their previous paper on C-CCA showed 90%+ on each subject on 1s windows and here C-CCA showed very poor performance... I'm missing something.,,Yannick,[TBD],
,Deep Classification of Epileptic Signals,2018,"Ahmedt-Aristizabal, Fookes, Nguyen & Sridharan",Arxiv,Yes,Queensland University of Technology,,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve State-of-the-Art: Using LSTM for Epilepsy classification,,"Resting State, Eyes Open, Eyes Closed, Seizures.",,,"N/M*
(Using Bonn University dataset)",Both,Raw EEG,Bonn University Dataset,Public (open),15,1,173.6Hz,N/M*,,,"None, but the Bonn University Dataset already has some preprocessing.",,Raw EEG,Raw EEG,,,Keras,LSTM,RNN,N/M*,,Yes,"100 x 4096
(100 samples of 4096 segments)","Model 1: 1 LSTM + 1 Dropout
Model 2: 2 LSTM + 2 Dropout
+ 1 FC",,,,,1,"less than 17,000 trainable parameters in the case of Model 1",,"Adam, LR: 10^-3, b1:0.9, b2:0.999, batch size of 4, dropout:0.35",,,,N/M*,Binary Cross-Entropy,,"10-Fold Cross-Validation
Train: 70%
Valid: 20%
Test: 10%",,"Accuracy, Sensitivity, Specificity, Precision and the Area Under the Curve (AUC).",,,N/M*,"Accuracy: [Valid] 95.54% [Test] 91.25%
Sensitivity: [Test] 91.83%
Specificity: [Test] 90.50%
Precision: [Test] 91.50%
AUC: [Test] 0.9582",N/M,None,,,"""We experimented with various numbers of memory cells in each layer and obtained the best performance with a network configured with one single layer with 64 hidden units (Model 1) and with 2 hidden layers of 128 and 64 hidden units respectively (Model 2)""",,No,Yes,,,Yannick,[TBD],
,Emotion Recognition from EEG Using RASM and LSTM,2018,"Li, Tian, Shy, Xu & Hu",International Conference on Internet Multimedia Computing and Service,,"South China University of Technology
Lanzhou University",9,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,Improve State-of-the-Art: Using LSTM for Emotion Classification,Using rational assymetry (RASM) as features and LSTM as classifier on DEAP dataset for emotion classification. 2 Classes (Positive / Negative Valence),DEAP Dataset: watching emotional movies (clips).,LSTM to capture temporal dependencies in emotions,,N/M,No,Emotions,DEAP,Public (open),32,32,"N/M
(see dataset)",895 Trials,,,None,No,"RASM14
(STFT + Hanning Window --> 4 Freq Bands)
",Frequency-domain,N/M,,N/M,LSTM,RNN,N/M,"In our assumption, emotions change continuously, and this continuity is reflected in the temporal correlations of EEG signals. To explore the correlations, the classification method of Long Short-TermMemory networks (LSTM) is adopted.",Yes,"125 * 14 * 4
(segments * pairs * bands)",1,N/M,"Dropout
(0.5)",,,"1
Positive Valence
Negative Valence",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,,10-Fold Cross-Validation,N/M,Accuracy,N/M,,N/M,"RASM + LSTM:     76.67    (Accuracy)
RASM + SVM:       65.62    (Accuracy)
Zhang, 2016:         69.67    (Accuracy)
Chen, 2015:           73.00    (Accuracy)
Li X, 2016:             72.06    (Accuracy)","SVM
Zhang [10] (DE + GELM)
Chen [2] (Fusion feature + HMM)
Li [6] (Wavelet energy + CRNN)",DL & Trad.,,No,"Although the accuracy of our experiment is more than 75%, it is not good enough for applications. The task of the future work is to improve the recognition accuracy. More features will be tried especially those reflect the characteristics of EEG signals in frequency-space domain.",N/M,No,No,Only 2 classes for Emotion Classification. Not sure if it's that good. Shouldn't be too hard to reproduce!,,Yannick,[TBD],
,EEG detection and de-noising based on convolution neural network and Hilbert-Huang transform,2018,"Wang, Guo, Zhang, Bai & Wang","International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",,"Changchun University of Science and Technology
Jilin Engineering Research Center of RFID and Intelligent Information Processing",6,,Other,Improvement of processing tools,Signal cleaning,Artifact handling,,New Approach,Denoising EEG with Hilbert-Huang Transform after a detection of (yes/no) EOG artifact from a CNN classifier,N/M*,Nonlinearity of EEG,,N/M,No,Raw EEG,Internal Recordings,Private,N/M*,N/M*,1000,2100,,,N/M*,N/M*,IMF / HHT,Other,N/M,,N/M,CNN,CNN,2*2 convolution kernels,N/M,Yes,"""characteristic matrix of the extracted instantaneous power""",1,Softmax,N/M,,,"1
EOG artifact yes/no
(softmax)",N/M,N/M,N/M*,N/M,N/M,N/M,N/M*,N/M*,,N/M*,"Train: 2000
Test: 100",Accuracy,N/M,,N/M,80%,"(they don't compare the DL aspect... Just the HHT - after the DL)
Wavelet db8
HHT
HHT+FastICA",Traditional pipeline,,No,The results show that the method in this paper takes a little longer CPU time compared with the traditional wavelet de- noising [4] and HHT de-noising alone. But the signal-to-noise ratio after de-noising is obviously higher than the other two methods.,N/M,No,No,"They seem to use the CNN just to detect if there is an artifact or not, then use the Hilbert-Huang transform. The paper is more about that transform than the CNN.
Missing LOTs of info on the DL-EEG side. They don't even talk about the data they recorded...",,Yannick,[TBD],
,Data Augmentation for EEG-Based Emotion Recognition with Deep Convolutional Neural Networks,2018,"Wang, Zhong, Peng, Jiang & Liu",International Conference on Multimedia Modeling,,"Shenzhen University
The Hong Kong Polytechnic University",12,,General Affective,Generation of data,Data augmentation,,,New Approach: Data augmentation on Emotion datasets for Deep learning models,Data augmentation on SEED & MAHNOB-HCI dataset and evaluation using ResNet & LeNet.,Emotional Films/Clips,Data augmentation for deep models with many parameters,,"N/M
(see datasets papers)",No,"Emotions
(Frequency Features)","1) SEED
2) MAHNOB-HCI",Public (open),"1) 14
2) N/M","1) 62
2) 32",N/M,"1) 1890
2) 188/208/131",,,"1) Downsampled to 200Hz
2) Band-pass filters: 5 freq bands
3) SFTF with n-overlap Hamming window 1s
4) Differential Entropy (log energy spectrum)",No,Differential Entropy (DE),Other,N/M,,"LIBSVM
MATCONVNET","ResNet
LeNet",CNN,"Data Augmentation Paper, it's not about these networks.",Data augmentation with Gaussian Noise,No,"n x l x 5
n: electrodes
l: length (time)
5: Freq Bands DE",N/M,N/M,N/M,,,"1) 3
2) 3 Classes",N/M,N/M,N/M,LR: 0.1,100,N/M,"Yes. The whole paper is about Data Augmentation.
With Gaussian Noise
up to 30 times.",N/M,,N/M,N/M,Accuracy,N/M,,N/M,"DS #1) LeNet: [Pre] 49.6% | [Post] 74.3%
DS #1) ResNet: [Pre] 34.2% | [Post] 75.0%
DS #2) ResNet: [Pre] 40.8% | [Post] 45.4%
DS #2) LeNet: N/M","DS #1) SVM: [Pre] 74.2% | [Post] 73.4%
DS #1) PCA-SVM: [Pre] 49.8% | [Post] N/M%
DS #2) SVM: [Pre] 42.5% | [Post] 44.3%
",Traditional pipeline,,N/M,"By analyzing the experimental result, we find that the data augmentation method can effectively improve the performance of deep models. In future, we will seek to use other data augmentation methods, such as generative adversarial networks, to generate more effective samples of EEG data and improve the performance of EEG-based emotion recognition.",N/M,No,Yes,"Interesting results on the first dataset.
Their next step is trying a GAN to generate data. I'm quite interested in that.",,Yannick,[TBD],
,A convolutional neural network for sleep stage scoring from raw single-channel EEG,2018,"Sors, Bonnet, Mirek, Vercueil & Payen",Biomedical Signal Processing and Control,No,"Université Grenoble Alpes
CEA Leti, MINATEC Campus (Grenoble)
Dijon University Hospital (Dijon)
Grenoble University Hospital",8,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,New Approach: Sleep Stage Scoring (5 stages) with CNN on Single EEG Channel,Use CNNs on raw EEG data for 5-class sleep prediction,Sleep,CNNs have presented good performance in other domains and other EEG tasks.,,N/M,No,Raw EEG,Sleep Heart Health Study (SHHS),Public (account),5728,1,125Hz," Wake:1,514,280
N1: 201,431
N2: 2,169,452
N3: 719,690
REM: 779,548

Total: 5,384,401",Offline,,None.,No,Raw EEG,Raw EEG,No,,TensorFlow,CNN,CNN,(no mention of pooling or dropout),1D convolutional layers,Yes,"(3750 * 4) x 1

30s epoch + 2 preceding + 1 following
30s @ 125Hz = 3750 samples",12 Conv Layers + 1 FC (256) + 1 FC (5 classes),Leaky ReLU,N/M,5," Wake
N1
N2
N3
REM","5
[prob for each class]
(Softmax)",N/M*,Standard optimization,Adam ,"lr = 3 ×10^−5, b1 = 0.9, b2 = 0.999",128,N/M,Tried cost- sensitive learning or oversampling.,Multiclass Cross-Entropy,Inter-subject,Train-valid-test split,0.5 / 0.2 / 0.3,Accuracy,NVidia GTX980Ti,,N/M*,87%,"Tsinalis [15] CNN: 0.75
Supratak [16] CNN-LSTM: 0.86
Liang [9] [...] : 0.88
Zhu [10]  DVG, SVM: 0.85
Fraiwan [6] T-F, RF: 0.83
Hassan [38] EMD, Ensemble: 0.87
Hassan [11] EMD, [...]: 0.89
Hassan [12] PSD, RF: 0.88
Hassan [39] EMD, [...] : 0.83
Sharma [13] Iterative filtering: 0.88
Hsu [14] Energy, RNN: 0.90",DL & Trad.,No,Yes,"""This study shows that it is possible to classify sleep stages using a single EEG channel and a convolutional neural network work- ing on raw signal samples without any feature extraction phase and with performance on par with other state-of-the-art methods.""
""Further research is necessary to address class imbalance. Ensemble learning [35] or CNN-specific methods [36] may prove suitable""",N/M,Yes,No,If all the abstract could be like that one! You have ALL the info.,,Yannick,Isabela,
,ChronoNet: A Deep Recurrent Neural Network for Abnormal EEG Identification,2018,"Roy, Kiral-Kornek & Harrer",Arxiv,Yes,IBM Research - Australia,,,Other Pathology*,Classification of EEG signals,Clinical,Pathological EEG,,Improve SOTA,Detect abnormal EEG with a new end-to-end architecture,?,Automatic interpretation of EEG from raw data,,N/M,No,Raw EEG,TUH Abnormal EEG Corpus,Public (account),3017 sessions (patients might appear more than once!),22,250,"Abnormal: 1488
Normal: 1529",,,None.,,None,Raw EEG,N/A,,N/M,"1) Conv+GRU
2) Inception Conv+GRU
3) Dense Conv+GRU
4) Inception Dense Conv+GRU",CNN+RNN,"Conv filter sizes grow exponentially inside a given layer (e.g., 2, 4, 8)",-,Yes,15000 x ?,"1) 7
2) 7
3) 7
4) 7",N/M,N/M,,,2,N/M,Standard optimization,Adam,500 epochs,64,N/M,N/M,N/M,,"No for most of the paper, but tested 5-fold CV",90.8 - 9.2,Accuracy,N/M,,N/M,"1) 82.31
2) 84.11
3) 83.89
4) 86.57","CNN-MLP: 78.80
DeepCNN: 85.40",DL,,-,The ChronoNet architecture is a general-purpose architecture for time series - has been applied to speech data classication.,-,No,No,Preliminary version of the paper.,,Hubert,[TBD],
,EEG-GAN: Generative adversarial networks for electroencephalograhic (EEG) brain signals,2018,"Hartmann, Schirrmeister & Ball",Arxiv,Yes,University of Freiburg,7,,Generating EEG Signals,Generation of data,Generating EEG,,,Generate EEG signals,Generate EEG signals using GANs,Motor imagery,GANs are good at generating data,,N/M,No,Raw EEG,Internal Recordings,Private,?,1,250,438,,,None.,No,None,Raw EEG,Subtract mean then divide by maximum absolute value,,N/M,Wassertein GAN (modified),GAN,-,"Conv layers instead of autoregressive model, as it worked well in the authors's other papers",Yes,"Gen: 200
Discr: 768","Gen: 14
Discr: 14",Leaky ReLU,"Minibatch standard deviation [normalization?]
Pixel normalization",N/A,N/A,"Gen: 768
Discr: 1",N/M,GAN optimization with increasing resolutions,Adam,"""Equalized learning rate""
lr = 0.001
beta1 = 9
beta2 = 0.99",?,N/M,-,Improved Wassertein distance,N/A,-,286-72-80,"Inception score
Frechet inception distance
Euclidean distance
Sliced Wassertein distance",N/M,,N/M,[Too many obscure values],WGAN with gradient penalty,DL,No,"Visual inspection of generated segments (time series distribution, spectrum distribution, examples)","The metrics did not correlate with visual performance, and so the authors recommend using many metrics to obtain a balanced view",Mode collapse in GANs,No,No,Very descriptive on the DL side.,,Hubert,Isabela,
,Know Your Mind: Adaptive Brain Signal Classification with Reinforced Attentive Convolutional Neural Networks,2018,"Zhang, Yao, Wang, Zhang, Zhang & Liu",Arxiv,Yes,"University of New South Wales, Tsinghua University, Michigan State University",,,General EEG classification,Classification of EEG signals,Multi-purpose architecture,,,Make general framework for EEG classification,Apply a single architecture (reinforced attentive CNN) to EEG classification,"1 & 2: Motor imagery
3: Person identification
4: Pathology (seizure detection)",Skip time-consuming feature engineering and no task-specific classifier.,,"1) ?
2) Emotiv
3) ?
4) ?",No,"1 & 2) Motor Imagery
3) None
 4) Seizures","1) eegmmidb
2) Internal recording
3) EEG-S (subset of 1)
4) TUH","1) Public
2) Private
3) Public
4) Public","1) 20
2) 7
3) 8
4) 5","1) 64
2) 14
3) 64
4) 22","1) 160
2) 128
3) 160
4) 250","1) 560,000
2) 241,920
3) 56,000
4) 60,000",,,None.,,None,Raw EEG,N/A,,TensorFlow,CNN with attention + DQN,CNN,"1) Replicating and shuffling incoming samples
2) Attention mechanism trained with RL
3) CNN
4) Nearest-neighbour classifier",A) Replicate and shuffle operation intended to randomly unveil interesting spatial patterns,Yes,1 x nb_channel,"CNN: 3
DQN: 2",ReLU & Sigmoid,L2,,,"1) 5
2) 6
3) 8
4) 2",N/M,Standard optimization (including reinforcement learning),Adam,Learning rate: 0.001,N/M,N/M,-,Cross-entropy,,N/M,N/M,"Accuracy, Precision, Recall, F1-score
Latency
Resilience",N/M,,N/M,"Accuracy
1) 0.9932
2) 0.9708
3) 0.9984
4) 0.9975","Not clear what they were trained on (samples? features?):
Linear SVM, Random Forest, kNN, LSTM, GRU, Adaptive boosting, LDA
+ 5 state-of-the-art papers for each (20 total)",DL & Trad.,,-,"Latency is comparable to other methods
The number of channels used affects the performance.",-,Yes,No,"How come their accuracy is so high??
Sample-by-sample classification instead of per epoch is interesting! However, how did they go from labels (usually applied to windows) to samples when reporting performance?",,Hubert,Yannick,
,Gated Recurrent Networks for Seizure Detection,2018,"Golmohammadi, Ziyabari, Shah, Von Weltin, Campbell, Obeid & Picone",Arxiv,Yes,"Neural Engineering Data Consortium, Temple University",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA (their previous work),"Explore Gated RNN (LSTM & GRU), explore initialiazation and regularization of these networks",(see TUH dataset paper),Improve their last results,,(see TUH dataset paper),No,Seizures,"TUH EEG Seizure Corpus 
(TUSZ)",Public (account),(see TUH dataset paper),22,250,(see TUH dataset paper),,,None.,,LFCCs + First & Second Derivative of LFCCs,Other,N/A,,N/M,"1) CNN + LSTM
2) CNN + GRU",CNN+RNN,"2D CNN to 1D CNN to bi-LSTM
First LSTM output: 128 (1s data / epoch)
Second LSTM output: 2-way sigmoid
(classification of a 1s epoch)","1) Gated units to avoid vanishing gradient.
2) RNNs to capture long-term dependencies.",Yes,"210 x 22 x 26
(Windows * Channels * Features)","3x 2D CNN
+ 1x 1D CNN
+ LSTM",ELU,"1) L1
2) L2
3) L1/L2
4) Dropout
5) Guassian Noise",,,"1
(classification - sigmoid)",N/M,"Initialization: 
The best performance is achieved using orthogonal initialization",Adam,N/M,N/M,N/M,-,MSE,,N/M,N/M,"Sensitivity, Specificity",N/M,,N/M,"CNN + GRU -   Sensitivity:  30.83%   |    Specificity:  91.49%
CNN + LSTM -   Sensitivity:  30.83%   |    Specificity:  97.10%

Best Regulation: L1/L2
Best Initialization: Orthogonal","Compared CNN+GRU vs CNN+LSTM
Compared 10 different initialization methods (see comments)
Compared 5 different regularization methods
(L1/L2, L1, L2, Gaussian noise, Dropout)
",DL,,-,"LSTMs outperformed GRUs. We also studied initialization and regularizations of these networks. In future research, we are designing a more powerful architecture based on reinforcement learning concepts. We are also optimizing regularization and initialization algorithms for these approaches. Our goal is to approach human performance which is in the range of 75% sensitivity with a false alarm rate of 1 per 24 hours [11].","No enough labeled data. Having certified specialist to label the data is very expensive, and hard to have people to do it.",No,Yes,They compare many Initializations methods. Interesting! Orthogonal [26] Lecun Uniform [27] Glorot Uniform [28] Glorot Normal [28] Variance Scaling [26] Lecun Normal [27] He Normal [29] Random Uniform [26] Truncated Normal [26] He Uniform [29]   (see Table 4),,Yannick,[TBD],
,Optimizing Channel Selection for Seizure Detection,2018,"Shah, Golmohammadi, Ziyabari, Weltin, Obeid & Picone",Arxiv,Yes,"Neural Engineering Data Consortium, Temple University",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Study the Impact of Number of Channels,Explore the impact of using/having from 2 to 22 channels with same network,(see TUH dataset paper),"Lower the number of EEG channels required 
(also save disk space)",,(see TUH dataset paper),No,Seizures,"TUH EEG Seizure Corpus 
(TUSZ)",Public (account),(see TUH dataset paper),"[2, 22]",250,(see TUH dataset paper),,,None.,,LFCCs + First & Second Derivative of LFCCs,Other,N/A,,N/M,CNN + LSTM,CNN+RNN,(same as there previous paper: Gated Recurrent Networks for Seizure Detection),(same as there previous paper: Gated Recurrent Networks for Seizure Detection),Yes,"210 x 22 x 26
(Windows * Channels * Features)","3x 2D CNN 
+ 1x 1D FC CNN
+ 2x Bi-LSTM",ELU & Sigmoid,Dropout,,,"1*
(classification - sigmoid)",N/M,N/M,Adam,N/M,N/M,N/M,-,MSE,,N/M,N/M,"Sensitivity, Specificity",N/M,,N/M,"22 Channels -    Sensitivity:  39.15%    |    Specificity:  90.37%
20 Channels -    Sensitivity:  34.54%    |    Specificity:  82.07%
16 Channels -    Sensitivity:  36.54%    |    Specificity:  80.48%
8 Channels -    Sensitivity:  33.44%    |    Specificity:  85.51%
4 Channels -    Sensitivity:  33.11%    |    Specificity:  39.32%",22 Channels is their baseline.,None,,-,The results presented in this paper use the Any Overlap scoring method [11] in which true positives are counted when the hypothesis overlaps with one or more reference annotations. False positives correspond to events in which the hypothesis annotations do not overlap with any of the reference annotations. This method of scoring is popular in the EEG research community.,-,No,No,-,,Yannick,[TBD],
,Improving brain computer interface performance by data augmentation with conditional Deep Convolutional Generative Adversarial Networks,2018,Zhang & Liu,Arxiv,Yes,Beijing Institute of Technology,,,BCI,Generation of data,Data augmentation,,,Generate EEG signals,Generate EEG signals using GANs for data augmentation,,Increase amount of data available for training,,(see BCI competition dataset),No,Motor imagery,BCI competition II dataset III,Public (open),1,3,128,280,,,None,,"Continuous Wavelet transform (Morlet)
Only keep 7-15 Hz",Frequency-domain,N/A,,N/M,"DCGAN for data augmentation
CNN",CNN,Convolutional GAN + label information as input to both generator and discriminator,2D kernel to accomodate input TFR,No,N/M,N/M,ReLU,N/M,,,Same as input (not mentioned),N/M,"GAN optimization
Training CNN with real and artificial data",N/M,N/M,N/M,N/M,The GAN produces artificial data for training a CNN,N/M,,N/M,50-50,Accuracy (for CNN using data augmentation),N/M,,N/M,"No augmentation: ~83 %
50% of augmentation: ~84%
150% of augmetation: ~84%
200% of augmentation: ~85.5%",None,None,,-,Data augmentation with GAN is does help increasing accuracy when limited data is available.,Limited amount of data available per subject when training a BCI,No,No,Definitely a first draft - a lot of missing information and English has not been reviewed.,,Hubert,[TBD],
,Convolutional neural networks for seizure prediction using intracranial and scalp electroencephalogram,2018,"Truong, Nguyen, Kuhlmann, Bonyadi, Yang, Ippolito & Kavehei",Neural Networks,,"University of Sydney
Royal Melbourne Institute of Technology
Swinburne University
University of Melbourne
University of Queensland
University of Adelaide",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Prediction,Improve SOTA,Use CNN to improve SOTA in seizure detection,Ongoing recording with and without seizures,Test CNN on different epilepsy datasets,,N/M,Both,"None
(Seizures)","1) Freiburg Hospital
2) CHB-MIT
3) Kaggle
(American Epilepsy Society Seizure Prediction Challenge)","1) $$$
2) Public
3) Public","1) 13
2) 13
3) 2 humans + 5 dogs","1) 6
2) 22
3) 16",(see datasets papers),"1) 59 Seizures + 311h
2) 64 Seizures + 209h
3) 48 Seizures + 627h",,,"1) Removed Powerline: 47-53Hz + 97-103Hz
2) Removed DC Component (0Hz)",,"SFTF
(2D Freq x Time)
30s EEG windows",Frequency-domain,N/A,,"Python
Keras
Tensorflow",CNN,CNN,"Batch Norm + Pooling
2 Dense","First, we keep the CNN architecture simple and shallow as described above (Ba & Caruana, 2014)",Yes,"n x 59 x 114
(electrodes x time x freq)","CNN: 3
FC: 2","ReLU
Sigmoid
Softmax
","Dropout 
(50%)",,,2,N/M,We applied cost-sensitive learning by changing 300 the cost function in a way that the misclassification cost of preictal samples is multiplied by the ratio of interictal samples to preictal samples for each patient.,N/M,N/M,N/M,N/M," To overcome this [imbalance], we generate more preictal segments by using an overlapped sampling technique during the training phase.",N/M,,"Leave-one-out
(each out executed twice)","Train: 75%
Test: 25% ","Sensitivity
FPR (/h)", NVidia K80,,N/M,"Measures (Epilepsy Specific): 
SOP of 30 min  |   SPH of 5 min

DS #1) Sensitivity : 81.4% | FPR: 0.06/h
DS #2) Sensitivity : 81.2% | FPR: 0.16/h
DS #3) Sensitivity : 75.0% | FPR: 0.21/h","Compares on 3 Datasets

Compares to 14 other SOTA (papers)",DL & Trad.,,N/M,,"(1) Unbalanced Classes.
(2) Comparing results with SOTA is complicated because each approach was tested with one dataset that is limited in the amount of data.",No,Yes,-,,Yannick,[TBD],
,Semi-supervised Seizure Prediction with Generative Adversarial Networks,2018,"Truong, Kuhlmann, Bonyadi & Kavehei",Arxiv,Yes,"University of Sydney
University of Melbourne
University of Queensland",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Prediction,Improve SOTA,Use unlabelled data and data fusion to improve SOTA in seizure prediction,"Resting State, Eyes Open, Eyes Closed, Seizures.",Leverage unlabelled data,,N/M,No,Raw EEG,"1) CHB-MIT dataset
2) Freiburg Hospital dataset",Public (open),"1) 13
2) 13","1) 16 (22 available)
2) 6",256,N/M,,,"STFT on 1-s windows with 50% overlap
Removal of power line noise frequencies",,STFT,Frequency-domain,N/M,,Tensorflow,"1) GAN
2) CNN",Other,-,-,Yes,"1) GAN generator: 100 x1
2) GAN discriminator: n x 56 x 112
3) CNN: Same as discriminator","1) GAN generator: 4
2) GAN discriminator: 3
3) Classifier: 2","Softmax, Sigmoid",Dropout (50%),,,"1) GAN generator:
2) GAN discriminator:
3) CNN",N/M,"1) Train GAN
2) Train 2 new FC layers on top of discriminator using labelled data",N/M,N/M,N/M,N/M,"In their 3rd experiment, they used a non-described method to generate new samples from existing ones.",N/M,,Leave-one-sample-out (one example from each subject is left out),75-25,AUC,Nvidia P100,,N/M,"AUC: 77.68% (CHBMIT), 75.47 (Freiburg)
[6 and 12% less than benchmark]",CNN,DL,,-,"Although the performance decreased as compared to a standard CNN, the authors argue this can reduce the effort put into labelling the data.",-,No,No,"This paper is obviously not in a state to be published. Missing references, and pretty short. The conclusion is completely unrelated to the rest of the paper... :P
Also, many things are not clear: what is their CV methodology? How was the benchmark trained? How much labelled data did they use after the GAN training?",,Hubert,[TBD],
,Time Series Segmentation through Automatic Feature Learning,2018,"Lee, Ortiz, Ko & Lee",Arxiv,Yes,Princeton University,,,Other,Classification of EEG signals,Multi-purpose architecture,,,Improve SOTA,Detect changepoints/breakpoints in data (changes in signal) and apply to different types of time series data,Eye movements,"Deep learning models for changepoint detection don't make assumptions about the underlying processes, as opposed to standard models",,Emotiv,No,Eyes open vs. eyes closed,EEG Eye State,Public (open),1,14,256,N/M,,,N/M,,N/M,NS,N/M,,N/M,Stacked Autoencoder,AE,-,-,No,N/M,2 (encoder),N/M,"Tied weights in encoder and decoder
L2 weight decay",,,2,N/M,Standard optimization,Stochastic gradient descent,N/M,N/M,N/M,-,Cross-entropy (or square loss?),,N/M,N/M,"ROC
Prediction loss (specific to task)",N/M,,N/M,ROC curves...,"Bayesian changepoint detection (based on Gamma or Gaussian priors)
Pruned Exact Linear Time method
Density-ratio estimation method",Traditional pipeline,,-,Deep learning avoids typical problems in modelling changepoints.,-,No,No,"Interesting task. Cool to see that people from other field try their algorithms on EEG data. However, the data (eyes open vs. eyes closed) is in my opinion not challenging at all. Also, basic information is missing.",,Hubert,[TBD],
,Investigating the Impact of CNN Depth on Neonatal Seizure Detection Performance,2018,"O’Shea, Lightbody, Boylan & Temko",Arxiv,Yes,University College Cork,,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,Use CNN to improve SOTA in seizure detection in neonatal,Ongoing recording with and without seizures,Improve SOTA with CNN-11 based on their CNN-6 (2017),,N/M,No,Raw EEG,Internal Recordings,Private,18,8,256,N/M,,,"Down-sample to 32Hz
Filtered between 0.5 and 12.8Hz",,8 sec windows (1 sec shift),Raw EEG,N/A,,N/M,CNN,CNN,"Conv - Batch Norm - Pooling
Output not Dense layer but 
Grand Average Pooling","""The 11-layer network can learn more simple features in the first layer (3 samples wide) and more complex features in the final layers (212 samples wide).""",Yes,"256x1 
(1sec - 256 samples)",11,Softmax,N/M,,,"2
Seizure / Non-Seizure","28,642","The network was trained for 100 epochs, after each epoch the validation AUC was calculated.",Stochastic Gradient Descent,"LR: 0.01
Momentum: 0.9",2048,N/M,N/M,N/M,,Leave-one-subject-out,The training data contains less than 2% of the validation dataset,AUC,N/M,,N/M,AUC90: 86.85%,"CNN - 6 layers (O'Shea et al., 2017)
SVM",DL,,N/M,This represents a substantial improvement over a shallower 6-layer CNN network which has a smaller range of receptive fields. These results represent the current best results for this task obtained using a single classifier.,N/M,No,No,They are the new SOTA acording to them. To be validated!,,Yannick,[TBD],
,Fair Deep Learning Prediction for Healthcare Applications with Confounder Filtering,2018,"Wu, Wang, Cao, Chen, Xing",Arxiv,Yes,"Beijing University of Posts and Telecommunications, Carnegie Mellon University",12,,Other,Improvement of processing tools,Reduce effect of confounders,,,New approach: Reduce effect of confounders in medical data,"Reduce the effect of confounders in medical data (e.g., gender bias in training data)",Students watching MOOC videos,Learn representations from scratch,,NeuroSky Mindset,No,Raw EEG,Internal Recordings,Private,10,1,N/M,N/M,N/M,,N/M,No,Raw EEG,Raw EEG,z-score,,TensorFlow,Bi-LSTM,RNN,Use of Confounder Filtering,N/M,No,N/M,N/M,Tanh,N/M,2,"Confused
Not-confused",1 (sigmoid),N/M,N/M,N/M,N/M,20,N/M,N/M,Binary Cross-Entropy*,N/M,5-fold CV,N/M,Accuracy,N/M,,N/M,CF-Bidirectional LSTM acc: 75.0%  ,"SVM: 67.2%
K-Nearest Neighbors: 51.9%
Convolutional Neural Network: 64.0%
Deep Belief Network: 52.7%
RNN-LSTM: 69.0%
Bidirectional LSTM: 73.3%",DL & Trad.,No,No,The use of confounding filtering improves the predictive performance. ,N/M,Yes,No,"Nice paper. The proposed method (confounding filtering) is tested in many scenarios. Work is not super deep in the EEG side, but it is a nice example of people using EEG data to validate new approaches.",,Isabela,[TBD],
,HAMLET: Interpretable Human And Machine co-LEarning Technique,2018,"Deiss, Biswal, Jin, Sun, Westover & Sun",Arxiv,Yes,"Georgia Institute of Technology
Massachusetts General Hospital",9,,Other,Classification of EEG signals,Multi-purpose architecture,,,New approach,Help experts generate high quality labels,"Tested on Epilepsy data, could be used for different tasks",Features can be automatically extracted to help experts label the data,,N/M,No,Raw EEG,Internal Recordings,Private,155,19,200,4176h of recordings,,,"1) Low-Pass filter: 60Hz
2) Computation of montages*
(not sure what that means)
3) 16s windows",No,"Raw EEG
(None)",Raw EEG,N/M,,"Python
Tensorflow","CNN
CAE
(Conv AutoEncoder)",Other,"1D CNN
FC Layer only for training
","One advantage of CNNs is the automated feature selection that happens during training. Without additional work, the model learns the features that it finds most relevant for its given task, from the raw signals.",Yes,16x,Classifier: 6 Conv + 1FC,ELU,"Dropout
(20%)",,,"5
(softmax)",N/M,"Co-Learning
Supervised & Unsupervised",Adam,N/M,128,N/M,"Flipped Electrodes Left <-> Right side of the brains while keeping the references the same (Fz, Cz, Pz), almost double the dataset.",N/M,,N/M,"Train: 80%
Test: 20%",Accuracy,"Intel(R) Xeon(R) 
E5-2630 2.40 GHz 
32 cores
256 Gb ofRAM 
4 GPUs Tesla K80",,13h,"Before re-labeling    |    After re-lbl full    |     After re-lbl re-eval only
HAMLET-CNN      39.36%  |  40.75%  |  68.75%
HAMLET-CAE      38.46%  |  39.06%  |  67.97%
CNN                      38.89%  |  41.58%  |  68.75% 
MLP                      21.04%  |  23.14%  |  14.06%","(only internal comparisons)
HAMLET-CNN
HAMLET-CAE
CNN
MLP",DL,,They talk about the importance of interpretability of the results.,"To summarize, first, we have introduced a novel tech- nique, HAMLET, for human and machine co-learning that is suited for creating high-quality labeled datasets on challenging tasks with a limited budget. This technique has benefits that can appreciated in many deep learning applications.",N/M,No,"Yes
(lack of labels!)","Not an easy one to read / understand, but very interesting. Trying to address a real problem in EEG / DL
(prepare a bit of time :p)",,Yannick,[TBD],
,Addressing Class Imbalance in Classification Problems of Noisy Signals by using Fourier Transform Surrogates,2018,"Schwabedal, Snyder, Cakmak, Nemati & Clifford",Arxiv,Yes,Emory University,7,,Sleep,Generation of data,Data augmentation,,,Improve SOTA,Use FT Surrogates for Data Augmentation. (Tested with a CNN on Sleep Data),Sleep Dataset (CAP),"Some EEG problemes are unbalanced. (e.g. Sleep stages, Epilepsy, etc.) For DL to perform well, we need data augmentation techniques.
",,N/M,No,Sleep,CAP Sleep Dataset,Public (open),101,"EEG: 2
EOG: 1
EMG: 1","N/M
(see dataset paper)",101 x 8h,,,"Low-pass filter: 13Hz (4th order Butterworth)
Downsampling to 32Hz",No,"Raw EEG
(None)",Raw EEG,N/M,,N/M,CNN,CNN,"1D CNN for each channel: 
2xEEG + 1xEOG + 1xEMG",,Yes,30s Raw EEG,"Conv 1D: 4
Conv 2D: 1
FC: 3",,Dropout,,,"6
(softmax)",N/M,N/M,RMS-Prop,"LR: 0.0016
Momentum: None
Decay: 0.9",128,Baysian Hyperparams Optim.,"FT Surrogates
(the goal of the paper!)",N/M,,5-Fold CV,"Train: 4/5
Validation: 1/5
(Test N/M)","F1-Score
Accuracy",Google Cloud,,N/M,"Accuracy (no augmentation):    67% | 73% | 51% | 64% | 75% | 70% 
Accuracy (FT surrogate):          83% | 86% | 38% | 75% | 97% | 46% 
Accuracy (IAAFT surrogates):   91% | 83% | 48% | 79% | 96% | 81% ","(all internal, no external)
No data augmentation
FT surrogates
IAAFT surrogates",None,,N/M,"Increases in the S2-accuracy seemed to be at the expense of stages S1 and S3 for larger values of α. Based on these results, we hypothesize that the effect of surrogate augmentation on an individual class accuracy does not directly depend on their conditional prediction accuracies, which are on the diagonal of the conditional confusion matrix (cf. Fig. 4(a)); instead, augmentation may introduce mixing between class labels indicated by a large off-diagonal element upon which the accuracy of one of the mixed labels will dominate.","Unfortunately, we were not yet able to evaluate and compare IAAFT surrogates with these results due to temporal and budget constraints.",Yes,Yes*,Using FT Surrogates to generate Raw EEG is assuming that the frequency features are explaining pretty much all the data. (I feel like it reduces the power of DL on raw data),,Yannick,[TBD],
,A Hybrid SAE and CNN Classifier for Motor Imagery EEG Classification,2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,EEG Classification Based on Sparse Representation and Deep Learning,2018,"Gao, Shang, Xiong, Fang, Zhang, & Gu ",NeuroQuantology,No,"Zhejiang University City College,",7,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use CNN + Sparse coding on top of CSP features,Motor Imagery,,,N/M,No,CSP,BCI competition III (dataset IVa),Public (account),5,118,100,140,,,Band-pass filter 8-15Hz,No,CSP (32 CSP filters),Frequency-domain,N/M,,N/M,CNN,CNN,CNN's input is a sparse representation of CSP features,N/M,Yes,28 x 28,"CNN: 4
FC: 1",ReLU,N/M,,,2 (softmax),N/M,N/M,N/M,N/M,N/M,N/M,N/M,Binary cross-entropy,,N/M,N/M,Accuracy,N/M,,N/M,Accuracy: 100%,Sparse representations (not clear what is the classifier),Traditional pipeline,,No,Performance of CNN+sparse representations is less afect when the number of training samples decreases.,N/M,No,No,"The idea of using sparse coding seems really nice. However, the paper is shallow. Important aspects of the training and results are missing. ",,Isabela,[TBD],
,Use of features from RR-time series and EEG signals for automated classification of sleep stages in deep neural network framework,2018,"Tripathy, & Rajendra Acharya",Biocybernetics and Biomedical Engineering,,"Siksha 'O' Anusandhan, India
Ngee Ann Polytechnic, Singapore
SUSS University, Singapore",13,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use DNNs on EEG + ECG for sleep stage scoring,Sleep Dataset (MIT-BIH),They don't mention why DL.,,"N/M
(see MIT-BIH paper)",No,"Raw EEG
(Sleep)",MIT-BIH Polysomnographic,Public (open),18,"1 EEG
1 ECG",250,N/M*,,,1) 5 Band-pass filters to 5 freq bands,No,"14 EEG-HRV Features  (out of 19)
(The dispersion entropy and the variance features are evaluated from the different bands of EEG signal)
(the RQA and dispersion entropy features are evaluated from the IMFs of RR-time series)",Other,N/M,,Matlab 2015a,SAE,AE,"3 DNNs

EEG features + HRV features combined 
as inputs. Outputs = 2 classes (x3 DNNs)",N/M,Yes,"14 EEG Features
 ECG Features
(30s window)",2 AE,Sigmoid,"L2

(N/M... Assumed from the formula)",,,"2 (softmax)

3 DNN Networks
Classifying 2 classes each",N/M,Greedy Layer Wise,SGD,N/M,N/M,N/M,N/M,(See Formula),,10-Fold CV,N/M,"Accuracy (Acc)
Sensitivity (Sen)
Specificity (Spe)","CPU 2 GHz
2 GB RAM",,"1 Instance:
EEG: 4.89s 
RR: 0.03s","Acc Sleep vs Wake: 85.51%
Acc Light vs Deep Sleep: 94.03%
 Acc REM vs NREM: 95.71%","Hayet and Slim [55] (ELM, Werteni et al. [56] (SVM), Adnane et al. [16] (SVM), Rossow et al. [57] (HMM), Redmond and Heneghan [58] (QDA), Song et al. [59] (Multivariate Discrim. Analysis), Prucnal et al. [12] (NN), Hasan et al. [11] (RUSBoost), Da Silveira et al. [13] (RF)",Traditional pipeline,,N/M,"The dispersion entropy values for delta (d), theta (u) and alpha (a) bands are found to be more discriminatory for the classification of the wake and sleep classes.","The limitation of this work is that we have used only 18 subjects. The performance of this work can be improved using more subjects from the diverse race. The number of REM sleep stage instances in MIT-BIH polysomnography database is less as compared to deep sleep, light sleep and wake classes.",No,Yes,Interesting... Not really a multiclass however. But seems quite high compared SOTA.,,Yannick,[TBD],
,Emotion stress detection using EEG signal and deep learning technologies,2018,"Liao, Chen & Tai",IEEE International Conference on Applied System Invention (ICASI),,Department of Information Management Chaoyang University of Technology,,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,New approach,Use CNN to classify Attention & Meditation from raw EEG,Listening to music,Exploring the use of DL for stress detection via EEG,,Neurosky Mindwave Mobile,No,None,Internal Recordings,Private,7,1,512*,N/M,,,N/M,,Frequency Bands,Frequency-domain,N/A,,N/M,CNN,CNN,N/M,N/M,No,"1s
(N/M, assuming 512 samples)",7,RELU,N/M,,,"1
0: Meditation
1: Attention",N/M,N/M,N/M,N/M,N/M,Grid Search,N/M,N/M,,N/M,"Train: 80%
Test: 20%","Accuracy
F1-Score",N/M,,N/M,Accuracy: 80.13%,N/M,None,,N/M,The F1-score shows that our system is better in predicting class 1 than predicting class 0.,N/M,No,No,"Terrible Paper.
They talk about measuring stress, but they use DL on raw EEG from Neurosky to classify based on attention/meditation coming from the Neurosky values...",,Yannick,[TBD],
,Hierarchical internal representation of spectral features in deep convolutional networks trained for EEG decoding,2018,"Hartmann, Schirrmeister & Ball",BCI Conference,Yes,University of Freiburg,6,,Other,Improvement of processing tools,Model interpretability,Model visualization,,Improve interpretability of CNNs ,Study most activating inputs. Study effect on internal representation of variations in the input signal,Motor imagery,End-to-end learning,,N/M,No,Raw EEG,Internal Recordings,Private,14,128,5000,1000 trials/subject,,,"1) Downsample to 250 Hz
2) Common average re-reference ",No,"Raw EEG
(None)",Raw EEG,N/M,,Pytorch,CNN,CNN,See Schirrmeister et al. (2017),See Schirrmeister et al. (2017),Yes,522 x 128 (samples x channels),"CNN: 5
FC: 1",ELU,N/M,,,4,N/M,Standard optimization,Adam,N/M,N/M,N/M,N/M,Cross-entropy,,N/M,"Train: 80%
Test: 20%","Accuracy
F1-Score",N/M,,N/M,"Mean accuracy over 14 subjects: 88.6% 
(but this is not the focus of paper)",No,None,,"Yes
1) Signal perturbation (amplitude & phase)
2) Most-activating input windows",Analyzed effect of perturbations in phase and amplitude of input signals. Earlier layers focus on frequency-related information while latest layers focus on amplitude.,N/M,No,No,Cool paper. The focus is in the interpretability of what is learned by the convolutional layers.,,Isabela,Hubert,
,Spatial-Temporal Recurrent Neural Network for Emotion Recognition,2018,"Zhang, Zheng, Cui, Zong & Li",IEEE Transactions on Cybernetics,Yes,"Southeast University, Nanjing, China
Nanjing University of Science and Technology, China",9,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,"New Approach: Stacking 2 RNN layers for spatial and temporal resolution, for EEG & Facial Expression for emotion classification","Stacking 2 RNN layers for spatial and temporal resolution, for EEG & Facial Expression for emotion classification","Emotion Classification for short emotional films/clips
(SEED dataset)",Leverage RNN for both spatial and temporal features,,ESI neuroscan,No,Emotions,SEED,Public (open),15,62,1000,N/M,,,None,No,"DE descriptors (?)  -  Freq Bands
(256-point FFT + Hanning Window (1s) for 5 F-Bands)",Frequency-domain,N/M,,N/M,"STRNN
(Spatial-Temporal RNN)",RNN,Spatial & Temporal features representation with stacked RNNs,"1) To learn spatial dependencies, a quad-directional spatial RNN (SRNN) layer is first employed
2) Then, a bi-directional temporal RNN (TRNN) layer is further stacked on SRNN to capture long-term temporal dependencies",Yes,"Not clear...
(to be reviewed)","SRNN: 1
TRNN: 1","ReLU
Sigmoid",N/M,,,"3
(Softmax)",N/M,N/M,"Back Propagation 
Through Time
(BPTT)",N/M,N/M,N/M,N/M,Cross-entropy,,N/M,"Train: 9 Sessions
Test: 6 Sessions",Accuracy,N/M,,N/M,Accuracy: 89.5%,None,None,,N/M,"A multidirection SRNN layer and a bi-direction TRNN layer are hierarchi- cally employed to learn spatial and temporal dependencies layer by layer. To adapt the multichannel EEG signals to the proposed STRNN framework, the spatial scanning order of electrodes are specified by spatial coordinates and tempo- ral variation information is involved by slicing a window on the extracted DE feature sequences.",N/M,No,No,Interesting...,,Yannick,[TBD],
,Individual Recognition in Schizophrenia using Deep Learning Methods with Random Forest and Voting Classifiers: Insights from Resting State EEG Streams,2018,"Chu, Qiu, Liu, Ling, Zhang & Wang",IEEE Transactions on Neural Systems and Rehabilitation Engineering,Yes,Big Data and AI Research Center of Shanghai Jiaotong University,,,Other Pathology*,Classification of EEG signals,Clinical,Schizophrenia,,New Approach: Using Random Forest and Voting Classifiers with a CNN for Individual Recognition in Schizophrenia,,"Resting State, Eyes Open. (300s each)",,,BrainCap,No,Raw EEG,Internal Recordings,Private,"120
(40 CHR, 40 FES, 40 Healthy)",64,1000,N/M*,,,"1) Occular Correction (with Brain Vision Analyzer's algos)
2) Re-Referenced to Common Average
3) Pass-Band Filter (IIR): 0.01 - 50Hz",,"1) Raw EEG
2) Freq Bands",Raw EEG,,,"Brain Vision Analyzer
EEGLab","1) Raw EEG
2) Freq Bands
(not very clear about the shape)",CNN,"3 Conv Layers, ELU, 3 Dropout 0.5, 3 Max Pooling + Dropout 0.25, 3 FCs, 1 voting (RF, softmax or SVM)",,Yes,"1) Raw EEG
2) Freq Bands
(not very clear about the shape)","15
(including in,out, dropout)",,,,,"3 Classes
(replaced Softmax with Random Forrest)",N/M*,,"exponential linear unit (ELU) to accelerate the learning speed, max pooling to prevent substantial overfitting problem.",,,,N/M*,N/M*,,"Cross-Validation 
(""Our results are the averages of 1000 independent runs"")",,Accuracy,,,N/M*,"FES: 96.7% 
CHR: 81.6%
HC: 99.2%
(3 classes)","ANNV, RNNV, CNNV,
ANNV+mSVM, RNN+mSVM, CNN+mSVM, 
ANN+RF, RNN+RF, CNN+RF",DL,,,"In conclusion, we have shown that CNNV-RF performs better than softmax and CNNV-mSVM on a well-known dataset (mnist) and resting state EEG streams used in this paper. Switching from softmax or mSVM to RF is incredibly simple and appears ro be helpful for classification problems.",,No,No,"N/M*
(not a huge fan of the EEG signal presented...)",,Yannick,[TBD],
,An EEG-based Image Annotation System,2018,"Parekh, Subramanian, Roy & Jawahar","National Conference on Computer Vision, Pattern Recognition, Image Processing, and Graphics",Yes,"IIIT Hyderabad, India
University of Glasgow, Singapore
National Brain Research Centre, Manesar, India",11,,BCI,Classification of EEG signals,BCI,Reactive,RSVP,Novel Approach: Image classification based on subject's P300,Using CNN (EEGNet) to classify images based on P300. RSVP with Oddball.,"RSVP. Images from Caltech101 and VOC 2012.
Oddball Paradigm for P300",Not mentioned why DL...,,Emotiv,No,"RSVP
P300",Internal Recordings,Private,5,14,128,N/M,,,"1) Baseline power removal using the 0.5 second pre-stimulus samples
2) Band-Pass filter: 0.1 - 45 Hz
3) ICA to remove artifacts 
(eye-blinks, and eye and muscle movements)",Yes,P300,Other,N/A,,"Python
Braindecode","CNN
(EEGNet)",CNN,"They add a Outlier Removal ""Feature"".
They used a pre-trained VGG-16 on predicted target image.
(to reduce false-positive due to class imbalance)",see EEGNet & Braindecode,No,"1s Windows
(Raw EEG)",3,ELU,"N/M

(see Braindecode / EEGNet)",,,"2

Target / Non-Target",N/M,N/M,Adam,N/M,N/M,N/M,N/M,Categorical Cross-Entropy,,5-Fold CV,"Train: 2500 images
Test: 2500 images","F1-Score

(Due to a heavy class imbalance between T/non-T, we use F1-score)","NVIDIA GEFORCE
 GTX 1080 Ti",,N/M," [DS: CT101] Before outliers removal: F1: 0.71 Precision: 0.66 Recall: 0.81
 [DS: CT101] After outliers removal: F1: 0.68 Precision: 0.63 Recall: 0.72
 [DS: VOC2012] Before outliers removal: F1: 0.88 Precision: 0.99 Recall: 0.81
 [DS: VOC2012] After outliers removal: F1: 0.83 Precision: 0.97 Recall: 0.72",None,None,,N/M,"Our annotation system exclusively relies on the P300 ERP signature, which is elicited upon the viewer detecting a pre-specified object class in the displayed image. A further outlier removal procedure based on binary feature-based clustering significantly improves annotation performance.",N/M,No,No,"They talk about image classification, but all they do is P300 Target/Non-Target... I don't see how they will bring this to the next level or a multi-class...",,Yannick,[TBD],
,EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer Interfaces,2018,"Lawhern, Solon, Waytowich, Gordon, Hung & Lance",Journal of Neural Engineering,Yes,"U.S. Army Lab, University of Texas at San Antonio, Columbia University, Georgetown University Medical Center",30,,BCI,Classification of EEG signals,BCI,Active & Reactive,MI & ERP,Novel Approach: DN that can be used for different BCI paradigms,Compare EEGNet with SOTA ML for different BCI Paradigms,"Visual P300 
ERN
Movement-related cortical potentials
Sensory Motor Rhythms",CNNs have been used successfully in vision and speech for automatic feature extraction.,,Biosemi,No,"1) P300 
2) ERN
3) Movement-related cortical potentials
4) SMR","Internal Recordings
+ BCI Comp. IV Dataset 2A
","1,2,3) Private
4) Public","P300: 15
ERN: 26
MRCP: 13
SMR: 9","P300: 64
ERN: 56
MRCP: 64 / 256
SMR: 22","1) 512
2) 600
3) 1024
4) ","1) ~2000/subject
2) 340/subject
3) ~1100/subject
4) 288/subject",,,"1) Rereferencing (linked mastoids)
2) Bandpass filter: 1 - 40 Hz 
3) Downsampled to 128 Hz
(** Different approaches! e.g. Used PREP Pipeline for #3)",No,"None
(Raw EEG)",Raw EEG,N/M,,"Python
Matlab
Keras, Tensorflow",CNN,CNN,"Layer 1: 1D spatial filters
Layer 2: Depthwise 2D Conv
Layer 3: Separable 2D Conv","Depthwise: Inspired in part by the Filter-Bank Common Spatial Pattern (FBCSP) algorithm. 
Separable: explicitly decoupling the relationship within and across feature maps by first learning a kernel summarizing each feature map individually, then optimally merging the outputs afterwards",Yes,Channels x Time,3,ELU,Dropout,,,"(depends on the task)
(softmax)","1) 1,066 
2) 1,082 
3) 1,098 
4) 796   ","Within-Subject and Cross-Subject
If classes are umbalanced, we apply class-weight to the loss function whenever the data is imbalanced",Adam,Default Params,N/M,N/M,N/M,Categorical cross-entropy,,"Leave some subjects out 
(per task)

X-Fold CV 
(depending on the task and if cross-suject or within-subject)","varies, depending on the task and if cross-subject or within-subject","Accuracy
AUC",NVidia Quadro M6000,,N/M,"See paper for full breakdown. TLDR;
Doesn't outperform or underperform anything by a lot.","DeepConvNet (Schirrmeister, 2017)
ShallowConvNet (Schirrmeister, 2017)",DL,,"They suggest 3 approaches (1) Summarizing averaged outputs of hidden unit activations. (2) Visualizing the convolutional kernel weights. (3) Calculating single-trial feature relevance on the classification decision
Also used DeepLIFT (Shrikumar 2017)","In this work we proposed EEGNet, a compact convolutional neural network for EEG-based BCIs that can generalize across different BCI paradigms in the presence of limited data and can produce interpretable features.
To the best of our knowledge, this represents the first work that has validated the use of a single network architecture across multiple BCI datasets, each with their own feature characteristics and data set sizes. Finally, through the use of feature visualization and ablation analysis, we show that neurophysiologically interpretable features can be extracted from the EEGNet model",N/M,Yes,No,"Great paper, but quite long and hard to ""review"" because of the 4 paradigms and all the tests/comparisons they do...
Nice appendix on the effect of different tricks (batch norm, dropout, dense layer)",,Yannick,[TBD],
,A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series,2018,"Chambon, Galtier, Arnal, Wainrib & Gramfort",IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING,Yes,"Telecom ParisTech, Inria, Université Paris-Saclay",12,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve State-of-the-Art,,Sleep,,,N/M*,No,Sleep events,MASS dataset - session 3,Public (account),61,"20 EEG
2 EOG
3 EMG",128,N/M*,,,1) Low-pass @30Hz,,Raw EEG + EOG and raw EMG,Raw EEG,z-score,,Keras + Tensorflow,ConvNet,CNN,3 conv layers + dense (per modality),"Layer 1: spatial filter
Layers 2, 3: temporal filters",Yes (table),Nb channels * 30 s,4,"Linear, ReLU, Softmax",25% (last layer),,,5,<10^5,"1) Training on a single 30-s epoch
2) Freezing net, and train last layer on multi-epochs",Adam,,,,N/M*,Categorical cross-entropy,,"Leave-p-subject-out
5 random permutations
67-16.4-16.4",,"Balanced accuracy
F1-score, Precision, Sensitivity, Specificity, Confusion matrix",N/M*,,~250 s,"Acc: ~80%
Bal. acc.: ~80%
Kappa: ~0.7
F1 score: ~0.71","Gradient boosting on time domain and freq. domain features
Univariatie ConvNets from Tsinalis et al. (2016) and Supratak et al. (2017)
",DL & Trad.,,Occlusion sensitivity,"1D convolution provided a speed-up vs. 2D convolutions
Smaller number of parameters than other studies
Temporal context helps for some classes, but not for others; recurrent architectures could help
Size of dataset matters",,No,Yes,Extensive justification of design choices; discussion is pretty detailed,,Hubert,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,A convolutional neural network for SSVEP classifcation under ambulatory environment,2017,"Kwak, Muller & Lee",PLOS One,,"Korea University, TU Berlin",,,BCI,Classification of EEG signals,BCI,Reactive,SSVEP,Improve SOTA,Improve robustness of SSVEP BCIs for exoskeleton control in ambulatory conditions,SSVEP,-,,MOVE system (Brain Products GmbH),No,SSVEP,Internal Recordings,Private,7,8,1000,"Static condition: 350
Ambulatory condition: 1750",,,"1) Notch filter @60Hz
2) Band pass from 4-40 Hz",,FFT bins from 5-35 Hz,Frequency-domain,min-max,,N/M,CNN or MLP,CNN,"1) CNN (3 layers) 
2) CNN (4 layers)
3) MLP (3 layers)","First conv layer: spatial filter
Second conv layer: spectral filter",Yes,120 x 8,"1) 3
2) 4
3) 3",Sigmoid,N/M,,,5,N/M,Standard optimization,Stochastic gradient descent,Learning rate: 0.1,N/M,N/M,N/M,N/M,,"10 fold
Chronological split","Train: 90%
Test: 10%",Accuracy,N/M,,N/M,"Static condition: up to 99.28%
Ambulatory condition: up to 94.03%","CCA, MSI, CCA + kNN",Traditional pipeline,,Visual presentation of learned features,"CNN-1 (3 layers) was the most robust.
Since architecture is pretty simple, no regularization is used.",Artefacts in ambulatory settings,No,No,-,,Hubert,[TBD],
,"Mental Tasks Classification using EEG signal, Discrete Wavelet Transform and Neural Network",2017,"Padmanabh, Shastri & Biradar",Discovery,,Savitribai Phule Pune University,,,BCI,Classification of EEG signals,BCI,Active,Mental tasks,"[Classification of 5 different mental tasks, via Wavelet & ANNs (PNN & MLP)]",,"5 Mental Tasks (Baseline, Multiplication, Rotation, Counting, Letter composition)",,,Grass 7P511 Amplifier,,,Keirn and Aunon,Public (open),5,6,250Hz,,,,1) Band-Pass filter: 0.1-100Hz,,,Frequency-domain,,,MATLAB & NNtool,"MLP
PNN",FC,,,,200x1,"2
(20; 15)",,,,,,,,Learning Rate: 0.9,,,,N/M*,MSE,,N/M*,,,,,,"MLP: 92%
NPP: 100%",None,None,,,,,No,No,,,Yannick,[TBD],
,Cross-session classification of mental workload levels using EEG and an adaptive deep learning model,2017,Yin & Zhang,Biomedical Signal Processing and Control,,"University of Shanghai for Science and Technology
East China University of Science and Technology",,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Mental workload,New approach,,ACAMS (Automation-enhanced Cabin Air Management System),,,Nihon Kohden Biomed. Amplifier,,PSD,Internal Recordings,Private,7,11,500,N/M*,,,"1) Low-Pass filter: 40Hz
2) ICA for EOG artifacts",,"PSD
Avg. Power:  T (5–7.5 Hz), A (8–13.5 Hz), B1 (14–20 Hz), 
B2 (20.5–30 Hz), G (30.5–40 Hz)",Frequency-domain,,,MATLAB,SDAE,AE,Adaptive Stacked Denoising AutoEncoder,,,"55x1
EEG PSD Features",6,,,,,2,N/M*,,,,,,Yes. Superposing the Gaussian distributed noise on the original feature values,N/M*,,"66% training, 33% validation.",,,,,N/M*,"[Complicated ... read me again ...]
SDAE > State of the art.","ANN, NB, kNN, SVMlin, SVMrbf, BSV, SDAE",DL & Trad.,,,It is evident that the proposed method is superior to those shallow and static classifiers when the comprehensive cortical information is adopted as the network inputs.,,No,No,They want to explore recording on multiple (different) days to capture the non-stationary neural physiological data distributions.,,Yannick,[TBD],
,Generative Adversarial Networks Conditioned by Brain Signals,2017,"Palazzo, Spampinato, Kavasidis, Giordano & Shah",ICCV,No,"University of Catalania, University of Central Florida",9,,Other,Generation of data,Generating images conditioned on EEG,,,New approach: generating images conditioned on EEG,Generating images using GANs conditioned by EEG representation,Visual presentation of images,Allows image generation,,actiCAP,No,Raw EEG,Internal Recordings,Private,6,128,1000,"11,466",,,"1) Hardware notch filter: 49-51 Hz
2) Band-pass filter: 14-70 Hz
3) Non-uniform quantization of the voltage values",N/M,Raw EEG,Raw EEG,N/M,,N/M*,"1) LSTM for EEG encoder 
2) DCGAN for image generation",Other,Conditional DCGAN (conditioning G and D),N/M,Yes (good one),Nb channels * 0.5 s,"1) 2
2) 5 (generator), 6 (discriminator)","1) ReLU
2) ReLU",N/M,,,"1) 40
2) 64 x 64",N/M,"1) Train encoder to predict image category from raw EEG
2a) Train GAN on images without EEG features
2b) Train GAN condtioned on average (across subs) EEG representation learned by the encoder",Adam (lr=0.001),"1) N/M
2) Batch normalization","1) 16
2) N/M",N/M,"1) N/M
2) Resizing images + horizontal flipping","1) categorical cross-entropy. 
2) non-saturating ",,"1) N/M
2) ",1) 80%-10%-10%,"1) Accuracy
2) Inception score, Inception accuracy",2 Titan X Pascal,,N/M,"Encoder: 83.9%
GAN: IS: 4-6.5, acc: 43%",No,None,,N/M,"Conditioning vector (i.e. EEG representations) are noisy, which makes harder to learn how an appropriate conditioning vector. 
 ","Suffers from classes with high internal variability
Dataset is small",No,No,Nice results for classes with low internal variability.,,Isabela,Hubert,
,The effects of pre-filtering and individualizing components for electroencephalography neural network classification,2017,Major & Conrad,IEEE SoutheastCon,No,University of North Carolina (Charlotte),6,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Analyze effectiveness of using ICA to enhance EEG that will be processed by a neural network,,Motor imagery,,,N/M,No,Raw EEG,eegmmidb,Public (open),109,64,160,N/M,,,1) Band pass filter: 8-30Hz,,Raw EEG,Raw EEG,N/M,,Matlab,MLP,FC,N/M,,No,N/M,N/M,N/M,,,,,N/M,N/M,N/M,,,,N/M,N/M,,,,Accuracy,N/M,,N/M,"With ICA: 68%
Without ICA: 56%",No,None,,No,Applying ICA to raw data improves the neural network performance.,,No,No,"Very limited paper. They used a neural network but didn't specify number of layers, or any other aspect. The focus of the paper is on whether using ICA helps or not.",,Isabela,[TBD],
,Convolutional neural network-based transfer learning and knowledge distillation using multi-subject data in motor imagery BCI,2017,Sakhavi & Guan,IEEE Conference on Neural Engineering,,NUS & NTU,4,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Transfer learning (from one subject to another),Reduce calibration time in a BCI using transfer learning,Motor imagery,Reduce BCI's calibration time,,N/M,No,Raw EEG,BCI Competition IV-2a,Public (open),9,22 + 3 EOG,250,5184,,,"1) Bandpass between 0.5-100 Hz
2) Notch filter @50 Hz",,"FBCSP in 9 frequency bands, then extracting envelope",Frequency-domain,weird z-scoring,,Torch7,CNN + MLP,CNN,"CNN: 5 layers 
MLP: 1 layer",-,Yes,"CNN: 32x40
MLP: 32","CNN: 4 conv, 1 FC
MLP: 1 FC",ReLU,N/M,,,"CNN: 128
MLP: 128",N/M,"1) Pre-train CNN+MLP on N-1 subjects
2) Fine-tune pre-trained network on 1 subject",Adam,N/M,N/M,N/M,N/M,KL divergence,,Leave-N-samples-out," N=5, 10, 20",Test set accuracy,N/M,,N/M,Average acc: 69.71%,SVM,Traditional pipeline,,-,"Best results (average across subjects) show significant improvement with respect to SVM. However, there is high variability  ",Choosing hyperparameter lambda,No,No,"Proposed approach applied knowledge distillation, but discussion is very poor",,Hubert,Isabela,
,Single-trial EEG classification of motor imagery using deep convolutional neural networks,2017,"Tang, Li & Sun",Optik - International Journal for Light and Electron Optics,,Zhejiang University of Technology,,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,New Approach: CNN for MI on Single Trial,,Motor Imagery,,,BioSemi,,SMR - ERD/ERS,Internal Recordings,Private,2,28,1000,"Left-Hand: 230
Right-Hand: 230",,,"1) [Hardware] Notch Filter: 50Hz
2) [Hardware] Band-Pass Filter: 0.5-100Hz
3) [Software] Band-Pass Filter: 8-30Hz",,,Frequency-domain,,,N/M*,CNN,CNN,Activation Function: Hyperbolic Tangent,,Yes,"28x60
Channels x Time Points ","2 Conv
1 FC",,,,,2,N/M*,,N/M*,,,,N/M*,N/M*,,"80% Training
20% Testing
10-Fold Cross-Validation",,,,,N/M*,86.41%,"Power+SVM
CSP+SVM
AR+SVM",Traditional pipeline,,,The results demonstrate that CNN can further improve classification performance compared with other three conventional methods.,,No,No,,,Yannick,[TBD],
,Pattern Recognition of Momentary Mental Workload Based on Multi-Channel Electrophysiological Data and Ensemble Convolutional Neural Networks,2017,"Zhang, Li & Wang",Frontiers in Neuroscience,,East China University of Science and Technology,,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art: MWL with CNN & ECNN,,ACAMS (Automation-enhanced Cabin Air Management System),,,Nihon Kohden Biomed. Amplifier,No,,Internal Recordings,Private,6,11,500,,,,1) Low-Pass filter: 40Hz,,"PSD
Avg. Power:  D (1-4Hz), T (5–8 Hz), A (9–13 Hz), B1 (14–16 Hz), 
B2 (17–30 Hz), G (31–40 Hz)",Frequency-domain,,,"Python
Matlab","CNN
ECNN",CNN,,,Yes,,,,,,,,,,"NM
Adagrad
Adadelta
Adam",,,,,Cross-Entropy,,50% - 50%,,,"Single Intel core i5 CPU, 4-GB memory, Windows",,,93%,"LDA
NB
SDA",Traditional pipeline,,,"""It was found that the deeper CNN model with the small convolutional kernels leads to improved classification performance.""
[YR] --> Like in other fields...",,No,No,"They compared 5 CNNs and 4 Optimizers...
Then build an Ensemble from these 20.",,Yannick,[TBD],
,Deep RNN learning for EEG based functional brain state inference,2017,"Patnaik, Moharkar & Chaudhari","International Conference on Advances in Computing, Communication and Control (ICAC3)",,"Xavier Institute of Engineering, Mahim, Mumbai
M G M Inst. of Health Sciences, Navi Mumbai
",,,BCI,Classification of EEG signals,BCI,Active,Mental tasks,New Approach: Brain State Inference with RNN using Alpha Phase Coherence,,"5 Tasks: Baseline, Multiplications, Rotations, Letter Composition, Visual Counting (not using baseline)",,,N/M*,No,"ERD/ERS
(looking at Alpha Cross Coherence - Occipital/Center)",Keirn and Aunon - BCI Dataset 1989,Public (open),7,6,250,N/M*,,,"1) Band-Pass Filter: 0.1-100Hz (Hardware)
2) ICA for EOG Artifacts
3) DWT to get Alpha Sub-Bands
4) Hilbert Transform (no-overlap) for Phase Coherence",,"Alpha Sub-Bands 
Phase Coherence",Frequency-domain,,,N/M*,"Elman's RNN
with Bottlenect",RNN,A 5-layer network with 53-400 - 50-200-20-T,,"Yes
(bad one)",[Shape Not Mentioned],5,,,,,4 Classes,N/M*,,N/M*,,,,N/M*,N/M*,,N/M*,,Accuracy,,,N/M*,"90% for two tasks
82% for three tasks
77% for all the four tasks",No,None,,,"""In this research, a RNN model is trained to identify the phase coherence patterns of EEG alpha-bands. Difference between EEG signals from central and occipital (C1-O1 & C2- O2) locations is considered to compute phase coherence patterns for various activities.""",,No,No,N/M*,,Yannick,[TBD],
,Deep Convolutional Neural Networks for Interpretable Analysis of EEG Sleep Stage Scoring,2017,"Vilamala, Madsen & Hansen",IEEE International Workshop on Machine Learning for Signal Processing,Yes,"Technical University of Denmark
Danish Research Centre for Magnetic Resonance",,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,New Approach: CNN for Sleep Stages,,Sleep,,,N/M*,,PSD,"Sleep EDF
 (PhysioNet Repo)",Public (open),20,1,100,N/M*,,,Multitaper Spectral Estimation,,"Spectrogram log values
(from Multitaper Spectral Estim.)",Frequency-domain,,,N/M*,CNN,CNN,"VGGNET
Activation Function: ReLU & Softmax
Xavier’s initialisation.",,No,"224x224
(RGB Image)",16,,,,,"5
(Sleep Stage)",N/M*,,"Dropout
Adam
Learning Rate: 10^-5
Mini-batch: 250
Decay Rate 1st & 2nd moments 0.9 & 0.999",,,,N/M*,Categorical cross-entropy,,"Leave-one-subject-out
4 Subjects for Validation
15 Subjects for Training",,"Precision 
Sensitivity 
F1-score 
Accuracy",,,N/M*,"[VGG-FE] Precision: 91, Sensitivity: 73, F1-S: 81, Accuracy: 83
[VGG-FT] Precision: 93, Sensitivity: 78, F1-S: 84, Accuracy: 86","SSAE, CNN",DL,,,Further improvement of the method includes better hyperparameter optimisation when generating the spectral images,,No,Yes,"Pretty much on par with the 2 papers from Tsinalis et al., 2016",,Yannick,[TBD],
,Deep long short-term memory structures model temporal dependencies improving cognitive workload estimation,2017,"Hefron, Borghetti, Christensen & Kabban",Pattern Recognition Letters,,"Air Force Institute
Air Force Research Laboratory",,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve State-of-the-Art: MWL classification with RNNs (LSTM).,,Multi-Attribute Task Battery (MATB) environment,,,N/M*,No,"PSD
(Raw EEG)",Internal Recordings,Private,"6
(out of 8)
(over 5 days)",19,256Hz,approximately 9000 observations per individual for the five day period,,,The power spectral density was determined for 30 points spread out over a logspace from 3 Hz to 55 Hz by extracting power from complex Morlet wavelets [9] . Each wavelet was 2 s in length,,"Mean, Variance, Skewness, Kurtosis of PSD (delta (1–4), theta (4–8), alpha (8–14), beta (15–30), and gamma (30–55)) + all possible combinations of M, V, S, K.",Frequency-domain,,,"Keras, Theano",LSTM,RNN,N/M*,,Yes,"600 x 30 x F
(batch size, temporal depth in seconds, and number of features)
(F varies between 90 and 380 features)","2 LSTM Layers
(50 and 10 units",,,,,"1
(low or high WL)",N/M*,,"Mini-batch gradient descent (600 obs. per batch)
Adam, Dropout 20%",,,,N/M*,Binary Cross-Entropy,,4-Fold Cross-Validation,,Accuracy,,,N/M*,"93% (using all measures: M/V/S/K)
 ","linear SVM (SVM-L), Radial Basis Function (RBF) SVM (SVM-R), feedforward ANN (ANN), deeply stacked simple RNN (RNN-D), single LSTM (LSTM-S), and deeply stacked LSTM (LSTM-D)",DL & Trad.,,,"There is an abundance of future work to be pursued in this area. Due to time constraints and computational complexity, only a select number of deep architectures were examined during this re- search. A thorough evaluation of different deep RNN architectures to include variations in the depth of hidden layer recurrent con- nections, stacking of different sized LSTM layers, and interleaving fully-connected feedforward layers between sequence-to-sequence recurrent layers may yield additional improvement.",,No,No,N/M*,,Yannick,[TBD],
,The signature of robot action success in EEG signals of a human observer: Decoding and visualization using deep convolutional neural networks,2017,"Behncke, Schirrmeister, Burgard & Ball",Arxiv,Yes,"Albert-Ludwigs-University Freiburg
University Medical Center Freiburg",6,,Other,Classification of EEG signals,BCI,Reactive,ERP,Novel Approach: DL for Robot Error Detection,Comparing CNN to rLDA and FB-CSP (both state of the art) for error detection in human-robot interaction,Participant watching short videos of robots making error (or not),Deep Learning hasn't been tried for that task. (and they want to use/promote Braindecode :p),,N/M,No,Error Potential,Internal Recordings,Private,17,128,N/M,"KPO: 720+ trials
RGO: 800+ trials
per participants",,,"1) Re-reference to common average (CAR)
2) Downsampled to 250Hz
3) Electrode-wise exponential moving standardization with a decay factor of 0.999 was applied [3]",No,Raw EEG,Raw EEG,N/M,,"Python
Braindecode",CNN,CNN,"N/M
(Braindecode)","N/M
(Braindecode)",No,"(different time windows)
(few seconds)","N/M
(Braindecode)","N/M
(Braindecode)","N/M
(Braindecode)",,,"N/M
Assuming 2: 
error/no error",N/M,"N/M
(Braindecode)","N/M
(Braindecode)",N/M,N/M,N/M,N/M,N/M,,N/M,N/M,Accuracy,N/M,,N/M,"KPO Error (2.5-5s): (78.2 ± 8.4) %
KPO Error (3.3-7.5s): (71.9 ± 7.6) %
RGO Error (4.8-6.3s): (59.6 ± 6.4) %
RGO Error (4-7s): (64.6 ± 6.1) %","rLDA
FB-CSP

(CNN is better)",Traditional pipeline,,Yes. We used the correlation of changes in ConvNet predictions with perturbation changes in input spectral amplitudes to obtain information about what the deep ConvNets learned from the data [3].,"Among other recent advances in the field of deep learning research, automatic hyperparameter optimization and architecture search, including recurrent and residual network architectures, data augmentation, using 3-D convolutions, or increasing the amount of training data all have the potential to further increase ConvNet performance.",N/M,No,No,"Using braindecode. Not explaining much about the network, just referring to the paper... Hence all the N/M",,Yannick,[TBD],
,Deep learning with convolutional neural networks for EEG decoding and visualization,2017,"Schirrmeister, Springenberg, Fiederer, Glasstetter, Eggensperger, Tangermann, Hutter, Burgard, Ball",Human Brain Mapping,Yes,University of Freiburg,30,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Find out best CNN architecture for EEG decoding,Motor imagery/execution,Can learn from raw data,,"1)
2)
3)
4)",No,None,"1) BCI competition IV dataset 2a
2) High Gamma Dataset (Internal recordings)
3) BCI Competition IV 2b
4) Mixed Imagery Dataset",Public (open) and private,"1) 9
2) 14
3) 9
4) 4","1) 22
2) 44 (out of 128)
3) 3
4) 64 (out of 128)","1) 250
2) 250
3) 250
4) 250","1) 9 * 2 * 288 = 5184
2) 14000
3) 9 * 5 (400 + 320) = 32400
4) 675 + 2172 + 698 + 464 = 4009",,,"BCI Competition Datasets:
1) Lowpass @38 Hz","Yes
(removed trials with at least one channel > 800 uV)",Raw EEG,Raw EEG,Electrode-wise exponential moving standardization,,Lasagne,CNN,CNN,"1) Deep ConvNet
2) Shallow ConvNet
3) Hybrid of 1) and 2) with 2 dense layers
4) ResNet","1) Layer 1: temporal filtering, Layer 2: spatial filtering, with no non-linearity in-between
2) Embedding FBCSP in a ConvNet
3) Combining 1 and 2
4) 2 layers like in 1)",Yes,,"1) 2
2) 5
3) max(2, 5) + 2 = 7
4) 31","1) ELU
2) Square, log
3) ELU, square & log
4) ELU","Dropout (0.5)
Early stopping",,,2 or 4,N/M,Standard optimization,Adam,Batch norm,N/M,N/M,Using crops (sliding windows with step of 1 sample),"Categorical cross-entropy
For cropped training: ""Tied loss function""",,None,"1) 288 - 288
2) 880 - 160
3) 400 - 320
4) Variable per subject","Accuracy
Confusion matrices","Geforce GTX Titan Black
Intel Xeon @2.60 GHz with 32 cores
128 GB RAM",,N/M,,Filter bank common spatial patterns,Traditional pipeline,,"Input-feature unit-output correlation maps (visualization of correlation between spectral bands and receptive fields)
Input-perturbation network-prediction correlation map (perturbing the input and visualizing change in output of net)","ConvNets reached FBCSP accuracies
ConvNet design choices substantially affects decoding accuracies
Recent DL advances substantially increases accuracies
ResNet performed worse than deep ConvNet
Cropped training strategy improves performance on higher frequencies
And much more!","ConvNets can be too flexible, especially if there is a specific type of brain activity that a user should use",Yes,Yes,Best DL + EEG ever.,,Hubert,[TBD],
,Optimal Feature Selection and Deep Learning Ensembles Method for Emotion Recognition From Human Brain EEG Sensors,2017,"Mehmood, Du & Lee",IEEE Access,,"Chonbuk National University, Nanjing University of Posts and Telecommunications",10,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Ensemble Method with DL and others to improve SOTA in EEG emotion classification,"Watching ""Emotional"" Images from IAPS database.",Using ensemble approach.,,Emotiv,No,Emotions,Internal Recordings,Private,21,14,128,368s x2 sessions / subject,,,"1) Artifact Removal (cites: Gómez-Herrero et al., 2006)
2) Filtering (cites: Widmann et al., 2012)
3) Epoching",Yes,"Hjorth parameters for different frequency ranges
+ ANOVA feature selection",Frequency-domain,N/M,,"EEGLAB
Matlab
WEKA","""Deep Learning""

(they don't even specify)",NS,"Ensemble: LDA, KNN, SVM, Naive/Bayes-Net, DT, RF, Deep Learning

They don't describe the DL model at all",N/M,Yes,"3 Hjorth params for each of the 5 frequencies
(?)",N/M,N/M,N/M,,,N/M,N/M,Pre-Training and Fine Tuning,N/M,N/M,N/M,N/M,,N/M,,10-Fold CV,"Train: 9/10
Valid: 1/10",Accuracy,"SOTA Server
4 TITAN-X (Pascal)",,N/M,Accuracy: 76.62%,"Jirayucharoensak et al., 2014 (SAE): 46/50%
Chanel et al., 2006 (FDA, Naive Bayes): 72% 
Khalili et al., 2008 (LDA, KNN): 61%
Horlings et al., 2008 (SVM): 37/32% 
Jenke et al., 2014 (...): 45%
Yin et al., 2017 (SAE, Ensemble): 84/83%
Atkinson et al., 2016 (...): 73/73%",DL & Trad.,,N/M,"Comparatively, the proposed method performs better than existing emotion recognition methods. The proposed feature selection method OF obtained the best emotion recognition rates of 76.6% for Voting ensembles method. Based on our results, we conclude that optimal feature selection is a good choice for enhancing the performance of EEG-based emotion recognition.","To further improve emotion recognition performance, we need to explore additional feature combinations with more emotional classes in the arousal–valence domain.",No,No,"Not really a DL paper... They don't even describe their ""Deep Learning"" model. They just put it there as one of the methods of the ensemble...",,Yannick,[TBD],
,Converting Your Thoughts to Texts: Enabling Brain Typing via Deep Feature Learning of EEG Signals,2017,"Zhang, Yao, Sheng, Kanhere, Gu, Zhang",Arxiv,,"University of New South Wales
Macquarie University
RMIT University",10,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Novel Approach,Joint CNN & LSTM + AE for Motor Imagery (5 classes),"Motor Imagery (5 classes)
(see eegmmidb dataset)",Current models achieve 70-80% which is not enough.,,"1) BCI2000 Instruments
2) Emotiv",No,Motor Imagery,"1) eegmmidb
(Physionet)
2) Internal Recordings",Public (open),"1) 10
2) 7","1) 64
2) 14","1) 160
2) 128","1) 28,000 samples / subject
2) 34,560 samples / subject",,,None,No,"Raw EEG
(None)",Raw EEG,N/M,,N/M,"CNN + LSTM + AE
+ XGB (classif)",Other,"CNN & LSTM are parallel, then combined for the AE then Xtrem Gradient Boosting classifier",CNN for Spatial and RNN for Sequential info,Yes,"1x64
(sample x channels)","LSTM: 5 layers
CNN: 2 Conv + 2 FC",Softmax,L2,,,5 Classes,N/M,N/M,"LSTM & CNN: Adam
AE: RMSProp","Full table on params, great way to describe it!!! others should do the same.",7000,"N/M

(they have tried many config, manually I suppose)",N/M,"LSTM + CNN: Cross-Entropy
AE: MSE",,N/M,"Train: 75%
Test: 25%","accuracy, precision, recall, F1 score, ROC curve, and AUC",N/M,,2000s,"DS #1 - Accuracy: 0.955
DS #2 - Accuracy: 0.9427","Baselines: KNN, SVM, RF, LDA, AdaBoost, RNN, CNN
Externals: Almoari, Sun, Mohammad, Major, Shenoy, Tonic, Rashid, Ward, Sita, Pinheiro.
(all different papers, see Table IV)",DL & Trad.,,N/M,"The proposed deep learning framework achieves the highest accuracy compared to the state-of-the-art EEG classification methods. The classification accuracy of the public dataset (eegmmidb) is consistently higher than the local real-world dataset (emotiv). Our future work will focus on improving the accuracy in the person-independent scenario, wherein some subjects participate in the training and the rest of subjects involve in the testing.",N/M,Yes,No,"Data Available here: https://drive.google.com/drive/folders/0B9MuJb6Xx2PIM0otakxuVHpkWkk
Code also available - Should try to reproduce!",,Yannick,[TBD],
,Emotion Recognition based on EEG using LSTM Recurrent Neural Network,2017,"Alhagry, Fahmy & El-Khoribi",International Journal of Advanced Computer Science and Applications (IJACSA),,Cairo University,,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,"Improve SOTA: Using LSTM on raw EEG to classify emotions (arousal, valence, liking)",,"Emotion Classification on DEAP 
(Like or Dislike video)",,,[see DEAP Dataset],No,Raw EEG,DEAP,Public (open),32,32,512,N/M*,,,"1) Downsampled to 128Hz  (in the dataset)
2) Re-reference to Common Average  (in the dataset)
3) Eye Artifacts Removed  (in the dataset)
4) High-Pass Filter [freq not mentioned]",,"Raw EEG
(None)",Raw EEG,,,"Keras, TensorFlow",LSTM,RNN,AF: ReLU and Sigmoid,,Yes,"5s segments x 32 channels
(672 x 32)","2 LSTM Layers (64,32) + 1 Dropout (0.2) + 1 FC",,,,,3 Classes,5534113,,"RMSProp, LR:0.001",,,,N/M*,N/M*,,"4-Fold Cross-Validation
Train: 75%
Test: 25%",,Average Accuracy,,,N/M*," Arousal: 85.65%
Valence: 85.45%
Liking: 87.99%","Traditional pipelines
Koelstra et al., [2]: 62 | 56 | 55 %
Atkinson ... [3]: 73 | 73 | - %
Yoon and Chung [6]: 70 | 70 | - %  
Naser and Saha [7]: 66 | 64 | 70 %  
proposed method: 86 | 85 | 88 %",Traditional pipeline,,,"Results show that the proposed method is a very promising choice for emotion recognition, because of its powerful ability to learn features from raw data directly. 
It achieves high average accuracy over participants compared to the traditional feature extraction techniques.",,No,No,N/M*,,Yannick,[TBD],
,Intent Recognition in Smart Living Through Deep Recurrent Neural Networks,2017,"Zhang, Yao, Huang, Sheng & Wang",International Conference on Neural Information Processing (ICONIP),Yes,"University of New South Wales, AU
Macquarie University, AU
Singapore Management University, Singapore",11,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA: Using LSTM on multiclass BCI,"Using LSTM on multiclass BCI open dataset
Use hyperparameter fine-tuning method","Motor Imagery
(see eegmmidb dataset)",Explore multiclass as opposed to binary classification like many others. BCI at home will be multiclasses.,,"N/M
(check eegmmidb dataset)",No,Intent / Motor Imagery,"eegmmidb
(Physionet)",Public (open),10,64,160,"28,000 samples / subject",,,None,,"Raw EEG
(None)",Raw EEG,N/A,,N/M,LSTM,RNN,N/A,N/M,Yes,"64 channels x ?
(not clear...)",5,Sigmoid,L2,,,"5 Classes
(the format isn't clear)",N/M,N/M,Adam,"LR: 0.004
Lambda: 0.005",N/M,Orthogonal Array (OA) experiment method,N/M,Cross-Entropy,,N/M,"Train: 75%
Test: 25%","Accuracy
Recall
F1 Score
AUC",N/M,,N/M,"Accuracy: 0.9545 
Recall:      0.9228 
F1:            0.9382 
AUC:        0.9985","Almoari [2] 0.7497, Sun [13] 0.65, Major [4] 0.68, Shenoy [12] 0.8206, Tolic [16] 0.6821, Ward [19] 0.8, Pinheiro [10] 0.8505 
KNN (k=3) 0.8369, SVM 0.5082, RF 0.7739, LDA 0.5127, AdaBoost 0.3431, CNN 0.8409",DL & Trad.,,N/M,"To achieve optimal recognition accuracy, we employ OA to op- timize the hyper-parameters. In this paper, we select five most common hyper-parameters including λ (the coefficient of L2 norm), lr (learning rate), Ki(the hid- den layer nodes size), I (the number of layers), and nb (the number of batches).",N/A,Yes,No,"Great results (too good to be true?)
Need to reproduce. The code is suposed to be available!",,Yannick,[TBD],
,Deep Recurrent Neural Networks for seizure detection and early seizure detection systems,2017,Talathi,Arxiv,Yes,Lawrence Livermore National Lab,,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA: Using RNN for early seizure dectection,Using GRU-RNN for early seizure detection,"Resting State, Eyes Open, Eyes Closed, Seizures.",Using available data to test RNNs for seizure detection.,,N/M,No,Seizures,Bonn University,Public (open),15,1,173.6,N/M*,,,None (see dataset preprocessing steps),,"Raw EEG
(None)",Raw EEG,N/A,,Keras,"GRU
(RNN)",RNN,GRU -> FC -> GRU,"GRU for RNN long-term dependencies, but control the vanishing gradient",Yes,"51 x 80 x 1
(51 EEG sub-segment x 80 values x 1 channel)","GRU: 2
FC: 1",N/M,N/M,,,"3
(Logistic Regression with Softmax)","In the order of 100,000","(1) We train the RNN in stateful-mode*.
(2) Rescaling the learning rate by factor 0.1 at each 100th epoch",Adam,LR: 0.01,N/M,N/M,N/M,N/M,,N/M,"Train: 50%
Test: 50%",Accuracy,N/M,,N/M,"98% Accuracy within the first 5 sec
(3 classes: Healthy vs Ictal vs InterIctal)","They mentioned (A. T. Tzallas et al., 2007) getting 98% accuracy (ANN).",Traditional pipeline,,-,This findings offers a strong support to the utility of GRU-RNN model for use in early-seizure detection system that can be extremely useful for developing closed loop seizure control systems where timely intervention can be leveraged to abate seizure progression,-,No,No,-,,Yannick,[TBD],
,DeepSleepNet: a Model for Automatic Sleep Stage Scoring based on Raw Single-Channel EEG,2017,"Supratak, Dong, Wu & Guo",Arxiv,Yes,Imperial College London,11,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA: Using CNN+LSTM for Sleep Stage Scoring from Raw EEG,Combining CNN + LSTM for Raw EEG and testing it on 2 different existing datasets,Sleep,Using RNN (LSTM) to capture time depencies in sleep stages.,,"N/M
(see dataset paper)",No,Sleep Stages,"1) MASS
2) Sleep EDF
",Public (open),"1) 62
2) 20","1) 20
2) 2","1) 256
2) 100","1) 58600
2) 41950",,,"1) Notch filter: 60Hz
2) Band-pass filter: 0.30 - 100Hz",No,"Raw EEG
(None)",Raw EEG,N/M,,"TensorLayer
eTRIKS",CNN + bi-LSTM,CNN+RNN,"1D Conv, Batch Norm, Max Pooling","First part is representation learning, which can be trained to learn filters to extract time-invariant features from each of raw single-channel EEG epochs. The second part is sequence residual learning, which can be trained to encode the temporal information.",Yes,"30s EEG Epoch
(2 diff sampling freq)","2 CNN
2 bi-LSTM",ReLU,"L2
Dropout (50%)",,,"5 Sleep Stages
(Softmax)",N/M,"The two-step training algorithm (their technique) to prevent from suffering from class imbalance.
The algorithm first pre-trains the representation learning part of the model and then fine-tunes the whole model using two different learning rates.",Adam,"LR: 0.0001
b1: 0.9
b2: 0.999",100,N/M,"The class-balance training set is obtained from duplicating the minority sleep stages in the original training set such that all sleep stage have the same number of samples (i.e., oversampling).",Cross-Entropy,,"k-Fold CV
1) 31-Fold 
2) 20-Fold",N/M,"Precision (PR)
Recall (RE)
F1-score (F1)
macro-averaging F1-score (MF1)
Accuracy (ACC)
Cohen’s Kappa coefficient (κ)","NVIDIA
GeForce GTX980",,The training time for each validation fold was approximately 3 hours on each node,"Sleep EDF - Acc: 82.0 
Sleep EDF - MF1: 76.9
Sleep EDF - k: 0.76 

MASS - Acc: 86.2
MASS - MF1: 81.7
MASS - k: 0.80","Traditional pipelines & DL
Sleep EDF: Y.-L. Hsu et al., 2013
Sleep EDF: R. Sharma et al., 2017
Sleep EDF: A. R. Hassan et al., 2017
Sleep EDF: O. Tsinalis et al., 2016a
Sleep EDF: O. Tsinalis et al., 2016b

MASS: H. Dong et al., 2016",DL & Trad.,,"Yes (read paper for more info)
We found several memory cells of the forward LSTMs that were interpretable. For instance, several cells were keeping track of the wakefulness or the sleep onset, which reset their values to positive numbers (i.e., active) when a subject was in the stage W or N1 respectively.","It achieved similar overall accuracy and macro F1-score compared to the state-of-the-art hand-engineering methods on both the MASS and Sleep-EDF datasets, which have different properties such as sampling rate and scoring standards (AASM and R&K).",N/M,Yes,No,"Interesting architecture with code on github! <3
Results are average. On par with others.",,Yannick,[TBD],
,Mixed Neural Network Approach for Temporal Sleep Stage Classification,2017,"Dong, Supratak, Pan, Wu, Matthews & Guo",IEEE Transaction on Neural Systems and Rehabilitation Engineering,Yes,Imperial College London,11,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA: Using Mixed NN on 1 channel EEG for Sleep Stage Scoring,Combining MLP + LSTM on 1-Channel Raw EEG from an existing (open) dataset,Sleep,"Using RNN (LSTM) to capture time depencies in sleep stages and using a single, frontal (skin) electrode.",,"N/M
(see dataset paper)",No,Sleep Stages,MASS,Public (open),62,"1
(out of 20)",256,494 hours,,,"N/M
Seems to directly do SFTF for freq features",No,PSD Features,Frequency-domain,N/M,,Theano,"Mixed NN (MNN)
MLP + LSTM",RNN,N/M,"Our MNN is composed of a rectifier neural network which suitable for detecting naturally sparse patterns [18], and a long short-term memory (LSTM) for detection of temporally sequential patterns [19]",Yes,30s EEG Epoch PSD,"MLP: [2,5]
LSTM: 1 (200-1000)",ReLU,Dropout,,,"5 Sleep Stages
(Softmax)",N/M,N/M,SGD,"LR: 0.01
Momentum: 0.9
no weight decay",500,Manual fine tune,Oversampling to balance classes,Cross-Entropy,,31-Fold CV,N/M,"Macro F1-score (MF1)
Accuracy (ACC)
Recall (RE)
Precision (PR)",NVIDIA 630,,2 days,"MF1: 80.50
ACC: 85.92","SVM: 75.01 | 79.70 (best with sequence 2) 
RF: 72.44 | 81.67 (best with sequence 3) 
MLP: 77.23 | 81.43 (best with sequence 4) 
",Traditional pipeline,,N/M,"(1) In terms of convenience, wearing the F4 channel near the hair line is imperfect. Other frontal EEG channels such as Fp2 and Fpz are easier to wear, but these channels have lesser information about stage W, N1, N2 and N3. (2) In our experiment, we tried to add fully connected layers between LSTM and softmax, and vary their hidden sizes, but no improvement was found.","Less inofrmation in low frontal (skin) channels
(They've identified 3 challenges)
Challenge 1. Heterogeneity
Challenge 2. Temporal Pattern Recognition
Challenge 3. Comfort",No,No,Should be reproducible. Data open and architecture rather simple / vanilla,,Yannick,[TBD],
,SLEEPNET: Automated Sleep Staging System via Deep Learning,2017,"Biswal, Kulas, Sun, Goparaju, Westover, Bianchi & Sun",Arxiv,Yes,"Georgia Institute of Technology
Nanyang Technological University
Massachusetts General Hospital",17,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,"Improve SOTA: Using CNN, RNN, CRNN for Sleep Stage Scoring","Trying CNN, LSTM, RCNN on 10,000 subjects on Raw EEG, Expert Feature Set and Freq Bands for Sleep Stage Scoring",Sleep,"Leveraging huge dataset (3.2TB) of 10,000 subjects to apply deep learning",,N/M,No,Sleep Stages,Internal Recordings,Private,10000,6,200,"80000 hours
(3.2TB of data!)",,,None,No,"3 Sets of Features:

1) Raw EEG
2) Experts Defined Features
3) Spectrogram",Combination,N/M,,"Tensorflow
CUDA 8.0","1) CNN
2) RNN
3) RCNN",CNN+RNN,"1) CNN: 1D Conv for Raw EEG / 2D Conv for Freq Features
2) RNN: Look back steps in RNN : [3,5,10,20,30]","By combining a RNN with CNN, we can have a hybrid model, namely, Recurrent-Convolutional Neural Networks (RCNN), which is able to extract features present in a spectrogram and preserve the long-term temporal relationship present in the EEG data",No,"30s EEG Epoch
(depending on feature set)

",RNN: 5 LSTM (1000),ReLU,Dropout,,,5 Classes,N/M,N/M,N/M,LR: [0.01 - 0.00001],N/M,"We performed 50 iterations of random search over a set of parameter choices for hyper-parameter
tuning",N/M,Categorical Cross-Entropy,,N/M,"Train: 8700 patients
Valid: 300 patients
Test: 1000 patients","Accuracy
Cohen's Kappa","Intel Xeon E5-2640, 256GB RAM, 
four Nvidia Titan X",,between 40 -100 min,"[RNN] - Expert Defined Features: [Acc] 85.76 |  79.46 [k]
 [RNN] - Spectrogram Features: [Acc] 79.21 | 73.83 [k]
[RNN] - Waveform Features: [Acc] 79.46 | 72.46 [k]  
---
[RCNN] - Expert Defined Features: [Acc] 81.67 |  76.38 [k]
 [RCNN] - Spectrogram Features: [Acc] 81.47 |  74.37 [k]
[RCNN] - Waveform Features: [Acc] 79.81 | 73.52 [k]  ","Logistic Regression
Tree Boosting
MLP
CNN
RNN
RCNN",DL & Trad.,,We evaluate model performance with different look-back steps in RNN. Figure 8a shows that performance of the model increases as the number of lookback steps. This indicates that long-term temporal dependency does help improving sleep stage classification.,"On 1000 held-out testing patients, the best performing algorithm achieved an expert-algorithm level of inter-rater agreement of 85.76% with Kappa value 79.46%, exceeding previously reported levels of expert-expert inter-rater agreement for sleep EEG staging.",N/M,No,No,3.2 TB of data!!! ,,Yannick,[TBD],
,MindID: Person Identification from Brain Waves through Attention-based Recurrent Neural Network,2017,"Zhang, Yao, Kanhere, Liu, Gu & Chen",Arxiv,Yes,"University of New South Wales, Australia
Tsinghua University
RMIT University, Australia",20,,Other,Classification of EEG signals,Personal trait/attribute,Person identification,,Improve SOTA: EEG for Person Identification,Use RNN on EEG for Person Indentification,"3 Different Datasets.
(they claim that Delta has the most personal info)",The DL motivation is not clear. They want to improve SOTA.,,"1) Emotiv
2) N/M
3) N/M",No,Delta Band*,"1) EID-M (internal)
2) EID-S (internal)
3) eegmmidb","1) Private
2) Private
3) Public","1) 8
2) 8
3) 8","1) 14
2) 14
3) 64","1) 128Hz
2) 128Hz
3) 160Hz","1) 168,000 Samples
2) 56,000 Samples
3) 56,000 Samples",,,"1) Remove DC Offset (substract)
2) Band-Pass Filter: 0.5 - 4Hz  (using only Delta)",No,Delta Band,Frequency-domain,z-score,,Matlab,"Attention-based Encoder-Decoder RNN
+ XGB Classifier",RNN,"Encoder, Decoder, Attention Module
+ XGB Classifier",N/M,Yes,"1x14 
Delta Bands / Channel

(not clear about the dimensionality)","Encoder: 
3 FC (164) + 1 LSTM (164)

Decoder:
1 FC (164)",N/M,L2,,,"8

One-Hot Label
(ID - 8 Subjects)",N/M,N/M,Adam,LR: ,"21,000 samples

(?)",N/M,N/M,Cross-Entropy,,N/M,"Test/All Samples

DS #1: 21,000 / 168000 
DS #2: 7000 / 56000
DS #3: 7000 / 56000","Precision
Recall
F1-Score","Nvidia Titan X Pascal
768G memory 
145 TB PCIe SSD",,N/M,"Precision | Recall | F1-Score
DS #1: 0.982 | 0.982 | 0.982
DS #2: 0.988 | 0.988 | 0.988
DS #3: 0.999 | 0.999 | 0.999","SVM, RF, KNN, AdaBoost, LDA, XGB, RNN",DL & Trad.,,N/M,"Moreover, the pre-trained model should be updated for a period of time since the user’s EEG data is gradually changed with the environmental factors such as age, mental state, and living style. One of our future work is to develop an online learning system which is enabled to automatically update the training dataset based on the testing data which is collected during the operating period.","Limited by the local experimental conditions, our study only gathered EEG data from 8 subjects with few trials. The dataset is only divided into two categories (Multi and Single), which is not enough to explore the change trend of the identification accuracy with the increase of data trials.",Yes,Yes*,"Code + Data available... Should be reproducible!
Very high results on an 8 class problem. 
Based only on Delta band...
Same group as DeepKey",,Yannick,[TBD],
,DeepKey: An EEG and Gait Based Dual-Authentication System,2017,"Zhang, Yao, Chen, Wang, Sheng & Gu",Arxiv,Yes,"University of New SouthWales
Macquarie University
RMIT University",20,,Other,Classification of EEG signals,Personal trait/attribute,Person identification,,Improve SOTA: EEG for Person Identification,Use AR+RNN+SVM on EEG+Gait for Person Identification,"Motor Imagery
(see eegmmidb dataset)

+ Gait (PAMAP2 dataset)",The DL motivation is not clear. They want to improve SOTA.,,BCI2000 Instruments,No,Raw EEG,eegmmidb,Public (open),8,64,160,"1,200",,,None (AR),No,Raw EEG,Raw EEG,N/M,,N/M,AR + RNN + SVM,RNN,N/M,"AR for pre-processing, RNN for feature extracting, and SVM for classification. Auto-regressive Coefficients (AR) is one of the most widely used pre-processing methods on EEG data",Yes*,"150x13x64
(150 segments, 13 coefficients (AR), 64 features/nodes)",5 RNN (64),N/M,L2,,,"8

One-Hot Label
(ID - 8 Subjects)",N/M,N/M,Adam,lambda is set as 0.004 while learning rate is set as 0.005,"8 mini-batch with the shape of [150, 13, 64]",Orthogonal Array Experiment Method,N/M,Log Loss Function,,N/M,"7:1

Train:Test",Accuracy,N/M,,N/M,"Highest Accuracy: 0.9841

Gait: 0.999
Combined: 0.983 ","[45]: PSD + cross-correlation values, [8]: Customized Threshold, [17]: Low-pass filter+wavelets+ ANN, [3]: Bandpass FIR filter +ECOC + SVM, [44]: IAF + delta band EEG + Cross-correlation & mahalobonis, [22]: CSP +LDA, [23]: AR + SVM",Traditional pipeline,,N/M,"The Gait Identification Model adopts a 7-layer deep learning model to process gait data and classify subjects’ IDs, achieving an accuracy of 0.999. The EEG Identification Model combines three components (auto-regressive coefficients, the RNN structure, and an SVM classifier) and achieves the accuracy of 0.9841 on a public dataset. Overall, the DeepKey authentication system obtains a FAR of 0 and a FRR of 0.019.",N/M,Yes,No,"Code + Data available... Should be reproducible!
Very high results on an 8 class problem. 
Same group as MindID.
** Only the EEG part is reported. Not gait",,Yannick,[TBD],
,Multi-Person Brain Activity Recognition via Comprehensive EEG Signal Analysis,2017,"Zhang, Yao, Zhang, Wang, Sheng, Gu",Arxiv,Yes,"University of New South Wales, Australia
Singapore Management University
Macquarie University, Australia
RMIT University, Australia",10,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use AE + XGB for BCI-MI 5 classes (eegmmidb + internal recordings),"Motor Imagery
(see eegmmidb dataset)","Deep learning should be able to generalize better across subjects and across classes, instead of binary classif.",,BCI2000 Instruments,No,Motor Imagery,eegmmidb,Public (open),20,64,160,"560,000 samples",,,N/M,No,"Raw EEG
(None)",Raw EEG,z-score,,N/M,"AE 
+ XGB Classifier",AE,"Encoder, Decoder + XGB Classifier",N/M,Yes,"64x??

Channels x Raw EEG time window","1 (64)

Input - Encoder - Decoder - Classifier (XGB)",N/M,L2,,,5,N/M,N/M,RMSProp,LR: 0.01,"There are 9 mini-batches and the batch size is 17,280.",N/M,N/M,MSE,,N/M,"Train: 532,000
Test: 28,000","Accuracy
Precision
Recall
F1-Score
ROC
AUC","Nvidia Titan X Pascal
768G memory 
145 TB PCIe SSD",,See charts,"Accuracy: 0.794
Precision: 0.7991
Recall: 0.781
F1 score: 0.7883
AUC: 0.9456","SVM, RNN, LDA, RNN+SVM, CNN, DT, AdaBoost, RF

XGBoost, PCA+XGBoost, PCA+AE+XGBoost, EIG+AE+XGBoost, EIG+PCA+XGBoost, DWT+XGBoost, SAE+XGBoost, AE+XGBoost",DL & Trad.,,N/M,"As part of our future work, we will build multi-view model of multi-class EEG signals to improve the classification performance. In particular, we plan to establish multiple models with each single model dealing with a single class. Following this philosophy, the correlation between test sample and each model can be calculated in the test stage and the sample can be classified to the class with minimum correlation coefficient.",N/M,No,No,"They also did it on an Emotiv internal experiment that they've been using a couple of papers now.
It would be interesting to get that dataset and reproduce results!",,Yannick,[TBD],
,Neurology-as-a-Service for the Developing World,2017,"Dharamsi, Das, Pedapati, Bramble, Muthusamy, Samulowitz, Varshney, Rajamanickam, Thomas & Dauwels",Arxiv,Yes,"IBM Research AI
Nanyang Technological University",5,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA: Use DL on the Cloud,Use DL on the Cloud for developing countries. Starting with a BCI Tasks (MI),"MI: Feet and Hands, real / imagined.",To develop neurology-as-a-service to learn features automatically from the data. This would help developing countries,,"N/M
(see EEG-MMIDB paper)",No,Motor Imagery,eegmmidb,Public (open),103,64,160,1500 trials / subject,,,"1) Bandpass: 3 - 30Hz
2) Generate Spectrogram: Hanning window & NFFT (128)","No
(mention it, but only filters)",Spectrograms,Frequency-domain,N/A,,"N/M
(Cloud)",CNN,CNN,N/M,N/M,No,"3D
(channels x freq x time)","[1-3 3D CNN]
[0-2 FC]",N/M,Dropout,,,N/M,N/M,N/M,(hyperparameters are automatically fine-tuned using an optimizer),LR: 0.001,N/M,Random Optimizer,N/M,N/M,,N/M,"7:3
Train:Test",Accuracy,"N/M
(Cloud)",,N/M,Best accuracy: 63.4%,PCA-SVM,Traditional pipeline,,N/M,"As part of our next steps, we plan to use this framework on a dataset aimed at classification of epileptic seizures and/or pathological/normal EEG. We would also like to see how the framework performs using other hyperparameter optimization techniques including Bayesian optimization.",N/M,No,No,Nothing really new... DL with CNN on the cloud from eegmmidb,,Yannick,[TBD],
,Deep Architectures for Automated Seizure Detection in Scalp EEGs,2017,"Golmohammadi, Ziyabari, Shah, de Diego, Obeid, Picone",Arxiv,Yes,"Neural Engineering Data Consortium, Temple University",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA: Comparing different deep architectures,"Compare HMM+sAE, HMM+LSTM, IPCA+LSTM, CNN+MLP, CNN+LSTM","Ongoing EEG recording, with and without seizures.",With big EEG corpus now available we can explore deep learning.,,"1) Natus EEG Equipment 
2) Nihon Kohden",No,Seizures,"1) TUH
2) Duke Seizure Corpus","1) Public
2) Private","1) Train: 64 
1) Eval: 50
2) Eval: 45","1) 22
2) ? (see ds paper)","1) 250
2) ? (see ds paper)",(see ds papers),,,None.,,LFCCs + First & Second Derivative of LFCCs,Other,N/A,,N/M,"1) HMM + sAE
2) HMM + LSTM
3) IPCA + LSTM
4) CNN + MLP
5) CNN + LSTM",CNN+RNN,2D Conv Layers -> Flatten -> 1D Conv Layer -> LSTM (output 1s data) -> LSTM -> 2-way sigmoid,"They tried different architectures trying to capture Spatio-Temporal information.
They also use Time-Freq Features, 
not raw EEG as is.",Yes,"210 @ 22 x 26 x 1
(Frames @ Channels * Features * 1)

(to be reviewed)","3x 2D CNN 
+ 1x 1D FC CNN
+ 2x Bi-LSTM
(CNN + LSTM)
(see paper for others)",ELU,Dropout,,,2-way Sigmoid,N/M,"Trained + Eval on TUSZ and 
only Eval on DUSZ",Adam,N/M,N/M,N/M,N/M,MSE,,N/M,N/M,"Sensitivity
Specificity",N/M,,N/M,"CNN + LSTM gave the best results.

TUSZ   -   Sensitivity: 30.83%   |   Specificity: 96.86%
DUSZ   -   Sensitivity: 33.71%   |   Specificity: 70.72%","They compared 6 architectures. (their own)
They compared 7 Optimizer Methods. (e.g. Adam, SGD, etc.)
They compared 6 Activation Functions. (e.g. Tanh, Sigmoid, etc.)
CNN + LSTM, Adam, ELU is the best combinaison",DL,,N/M,This is a significant finding because the Duke corpus was collected with different instrumentation and at different hospitals. Our work shows that deep learning architectures that integrate spatial and temporal contexts are critical to achieving state of the art performance and will enable a new generation of clinically-acceptable technology.,Access to labeled data and $ to label the data and make it public.,No,Yes,"I love these guys' architecture graphs! They have one for all of their difference approaches!

If only they'd have their code open source, they'd be stealing the show!",,Yannick,[TBD],
,Neonatal Seizure Detection using Convolutional Neural Networks,2017,"O'Shea, Lightbody, Boylan, Temko",IEEE 27th International Workshop on Machine Learning for Signal Processing,Yes,"Irish Centre for Fetal and Neonatal Translational Research, University College Cork",6,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach,CNN on (preprocessed) raw EEG for epilepsy classification,"Ongoing EEG recording, with and without seizures.","CNN works well on audio signal, why not on EEG.",,N/M,No,Seizure,Internal Recordings,Private,18,8,256,N/M,,,"Band-pass filter: 0.5 - 12.8Hz
Down sampled: 32Hz
EEG Split into 8s windows (50% overlap)",,Raw EEG,Raw EEG,N/A,,Keras,1D - CNN,CNN,"Conv - Batch Norm. - Pooling
Output Layer: GAP (not dense)","""...1D CNNs wide convolutional filters (1-4s, 32-128 samples) significantly improved the performance"". Sample size filters were used. In contrast to larger filter lengths allow the learning the various filters in a hierarchical manner [21].",Yes,"256x1
(1s x 1 channel)",6,RELU,Batch Norm,,,"2
(Seizure vs Non-seizure)","16,930",N/M,SGD,"LR: 0.003
LR -= 10% every 
20 iterations
Nesterov Momentum: 0.9",2048,N/M,"""Each input window is shifted by 1 second, which can be seen as a data augmentation step""",Categorical Cross-Entropy,,"Leave-one-subject-out
(LOO)",N/M,AUC,N/M,,N/M,"AUC: 97.1%
AUC90: 82.9%",SVM,Traditional pipeline,,N/M,"""We have also tried max pooling, which led to slightly inferior results in our experiments.""
""Initially, the EEG was converted to time-frequency images (spectrograms) and 2D CNNs were utilized, adopted from the area of image processing [17] – this architecture proved unsuccessful in the seizure detection task.""",N/M,No,No,"No.
(YR to ask for their dataset!)",,Yannick,[TBD],
,Improving classification accuracy of feedforward neural networks for spiking neuromorphic chips,2017,"Yepes, Tang & Mashford",International Joint Conference on Artificial Intelligence,Yes,"IBM Research, VIC, Australia",7,,Other,Improvement of processing tools,Hardware optimization,Neuromorphic chips,,New Approach: Running DL on Neuromorphic Chips,"Compare constrained network for a neuromorphic chip on 2 datasets, vs unconstrained version of NN ","MNIST & EEG Data from Nurse et al., 2015 (BCI-MI)",Implement DL/DNNs on a chip.,,"N/M
(see dataset paper)",No,Motor Imagery,"Nurse et al., 2015",Public (open),5,N/M,"N/M

(1000Hz?)",1109,,,N/M,No,N/M,NS,"[0, 1]",,Matlab,"[Esser et al., 2015]",NS,"[Esser et al., 2015]","[Esser et al., 2015]",No,N/M,"Small Network: 3
Large Network: 4",N/M,N/M,,,2,N/M,N/M,N/M,LR: 0.1,25,N/M,Yes,N/M,,N/M,"Train: 480/468
Test: 66/95
(class1/class2)",Accuracy,"TrueNorth
(IBM Chip)",,(see paper),"EEG Data: 86%
MNIST: 98-99%","On the TrueNorth Chip (constrained)
vs
Traditional Methods (Unconstrained)",Traditional pipeline,,N/M,"Furthermore, analysis of the learnt parameters pro- vide insights that might complement hardware design, thus providing a more efficient deployment of the trained models. The trained models use a small portion of the TrueNorth chip (30 cores vs. 4096 avail- able in the current version of the chip), thus requiring a much less than 70mW to work, which makes these models suitable for portable autonomous devices with large autonomy.",N/M,No,No,IBM Research is really into porting DL on neuromorphic chips. They have a couple of papers on it.,,Yannick,[TBD],
,Automatic Analysis of EEGs Using Big Data and Hybrid Deep Learning Architectures,2017,"Golmohammadi, Hossein, Torbati, Lopez De Diego, Obeid & Picone",Arxiv,,"Temple University
Jibo, Inc., Redwood City",20,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach: Hybrid HMM & SdA for Epilepsy,"Using an Hybrid 3 Passes Model, combining HMM & Stacked Denoising AutoEncoders for Epilepsy classification","Ongoing EEG recording, with and without seizures.
(TUH Dataset)",Deep Learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction,,"Natus Medical Inc.’s
Nicolet",No,Seizure,TUH,Public (open),"Total: 16,000",[20-128],[250-1024],"30,000 sessions",,,PCA,No,Cepstral coefficient-based feature extraction approach based on Linear Frequency Cepstral Coefficients (LFCCs),Other,N/M,,Theano,3x Stacked denoising Autoencoders (SdA),AE,"3 Passes. 
(1) HMM -> (2) SdAs -> (3) NLP

(2) PCA -> Out of Sample -> 3 SdAs in parallel -> Enhancer (combining 3 SdAs)",Not you typical DL-EEG approach...,Yes,,3 [Nodes from 100-800],N/M,N/M,,,6 Classes,N/M,Training of these three SdA networks is done in two steps: pre-training and fine-tuning. Denoising autoencoders are stacked to form a deep network. The unsupervised pre-training of such an architecture is done one layer at a time.,Minibatch Stochastic Gradient Descent,LR: [0.1-0.5],[100-300],N/M,"For rare and localized events, which are in this case SPSW and EYEM, we use an out-of-sample technique to increase the number of training samples (van der Maaten, 2009).",Cross-Entropy,,N/M,"Train: 84,032
Test: 29,421","Sensitivity
Specificity",N/M,,N/M,"Pass: Sensitivity | Specificity
1 (HMM): 86.78 | 17.70
2 (SdA): 78.93 | 4.40
3 (SLM): 90.10 | 4.88",N/M,None,,N/M,A summary of the results for different stages of processing is shown in Table 12. The overall performance of the multi-pass hybrid HMM/deep learning classification system is promising: more than 90% sensitivity and less than 5% specificity.,N/M,No,No,A little uncommon.,,Yannick,[TBD],
,Multimodal deep learning approach for joint EEG-EMG data compression and classification,2017,"Ben Said, Mohamed, Elfouly, Harras & Wang",IEEE Wireless Communications and Networking Conference,,"Qatar University
Carnegie Melon University
University of British Columbia",6,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,New Approach: Compressing joint EEG-EMG with an autoencoder,Compression & Classification of joint EMG + EEG on DEAP dataset with SAE,"Watching music videos
(DEAP Dataset)",Deep learning approach has emerged as one of the possible techniques to exploit the correlation of the data from multiple modalities. Compression for mobile health data.,,N/M,No,Emotions,DEAP,Public (open),32,N/M,128Hz,"23040 Samples
(for both EMG & EEG)",,,"1) 6s Windows
2) Whitened
3) Normalized",,"Raw EEG + EMG
(None)",Raw EEG,z-score,,N/M,SAE,AE,N/M,Deep learning approach has emerged as one of the possible techniques to exploit the correlation ofthe data from multiple modalities,No,N/M,2 SAE,Sigmoid,"L2
(to be confirmed)",,,"N/M
1) Compressed data
2) Classification",N/M,Greedy-layer wise,N/M,N/M,N/M,N/M,"In practice, we add zeros values examples for one modality while keeping the original values for the other modality and vice-versa",Square Euclidean Distance,,N/M,"1) Compress: 50-50
2) Classif: 75-25","1) Compression: Distortion
2) Classification: Accuracy",N/M,,N/M,"1) [Compression] Distortion: EMG = 13.85% |  EEG = 12%
2) [Classification] Accuracy: 78.1%","Discrete Wavelet Transform (DWT) [26]
Compressed Sensing (CS) [27] (distortion: 22% | 17.21%)
2D compression approach which is based on SPIHT and FastICA [28]",Traditional pipeline,,N/M,"1) Compression: Distortion
2) Classification",N/M,No,No,-,,Yannick,[TBD],
,Deep Learning for Fatigue Estimation on the Basis of Multimodal Human-Machine Interactions,2017,"Gordienko, Stirenko, Kochura, Alienin, Novotarskiy & Gordienko",Arxiv,Yes,National Technical University of Ukraine,12,,Other,Classification of EEG signals,Monitoring,Physical,Exercise,New Approach,Multi-modal fatigue (and activity) estimation,Different activities (sports) while having different sensors,Use Multimodal Models. to combine different modalities with a NN.,,OpenBCI,No,Multimodal,Internal Recordings,Private,"Not clear.
(1 ?)","not clear
(OpenBCI?)",N/M,N/M,,,N/M,N/M,N/M,NS,N/M,,N/M,DNN,NS,N/M,N/M,No,N/M,N/M,N/M,N/M,,,N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,"Mean Residual Deviance (MRD) 
Mean Absolute Error (MAE)",,N/M,N/M,"Mean Residual Deviance (MRD) 
Mean Absolute Error (MAE)",N/M,,N/M,"See Paper
(not really relevant / meaningful for this paper)",N/M,None,,N/M,The main achievement is the multimodal data measured can be used as a training dataset for measuring and recognizing the intensity and physical load on the person by means of the machine learning approaches.,N/M,No,No,Terrible paper.,,Yannick,[TBD],
,Towards Deep Modeling of Music Semantics using EEG Regularizers,2017,"Raposo, Matos, Ribeiro, Tang & Yu",Arxiv,Yes,Universidade de Lisboa,5,,Other,Classification of EEG signals,Music semantics,,,Improve SOTA on music semantics,Modeling of music audio semantics,Listening to music,Previous success of CNNs in music audio modeling,,OpenBCI,No,None,Internal Recordings,Private,18,16,250Hz,N/M,,,"1) Highpass 0.5Hz 
2) Notch at 50Hz",Yes,Raw EEG + Audio embeddings,Raw EEG,"Rescaled [-1, 1]",,N/M,CNN,CNN,N/M,N/M,Yes,N/M,5,ReLU,No,,,128,N/M,"1) Train audio+lyrics embeddings model
2) Train audio embeddings+EEG embeddings model",N/M,N/M,102,N/M,N/M,CCA between embeddings,,5-fold,N/M,"Mean Reciprocal
Rank (MRR)",GeForce GTX 1080,,20 minutes,"Outperformed Spotfiy by ~1%, but did not perform better than the SOTA (by a small margin)",Spotify embeddings and current SOTA (Choi),DL & Trad.,,N/M,"Proposed approach did not outperformed SOTA but SOTA was trained on more
than 2083 hours of music, whereas the proposed method needs less than 3 hours of both music and EEG",N/M,No,No,Did not outperformed SOTA by a small margin and it seems there is a lot of room for improvement,,Isabela,[TBD],
,Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals,2017,"Acharya, Oh, Hagiwara, Tan & Adeli",Computers in Biology and Medicine,,"Ngee Ann Polytechnic, Singapore
SUSS University, Singapore
University of Malaya, Malaysia
The Ohio State University, US",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,"New Approach: CNN for Epilepsy
(claiming its a new approach, but it's not...)",13-Layers CNN for Epilepsy,"Ongoing EEG recording, with and without seizures.",To develop a computer-aided diagnosis (CAD) to classify EEG,,N/M,No,Seizures,Bonn University Dataset,Public (open),15,1,173.6,N/M,,,None,,Raw EEG,Raw EEG,z-score,,N/M,CNN,CNN,"1D CNN
Conv / Max Pooling",,Yes,4097x1,"1D CNN: 10
FC: 2",ReLU,"L1 ? 
(To be confirmed)",,,"3
(Softmax with 3 classes)",N/M,A conventional backpropagation (BP) [32] with a batch size of 3 is employed in this work to train CNN.,"The parameters used to train the CNN model are (i) lambda (regularization), (ii) learning rate, and (iii) momentum","Lambda: 0.7
LR: 1x10^-3
Momentum: 0.3",3,Trial and Error,"N/M
(future work: bagging)",N/M,,10-Fold CV,"Train: 90%
Test: 10%","Accuracy
Sensitivity
Sensibility","Intel Xeon 2.40 GHz (E5620)  
24 GB RAM",,"150 epochs
12.8s / epochs
=  32 min","Accuracy: 88.7% 
Sensitivity: 95% 
Specificity: 90%","Many other SOTA
(check paper)
They performed worse than most previous SOTA",Traditional pipeline,,N/M,"The advantage of the model presented in this paper, however, is separate steps of feature extraction and feature selection are not required in this work. Nevertheless, the main drawback of this work is the lack of huge EEG database",Amount of data,No,Yes,"Bad results compared to SOTA, but interesting...
13 layers would probably need more data.",,Yannick,[TBD],
,Electroencephalogram-based decoding cognitive states using convolutional neural network and likelihood ratio based score fusion,2017,"Zafar, Dass & Malik",Plos One,No,Universiti Teknologu PETRONAS,23,,General Cognitive,Classification of EEG signals,BCI,Reactive,RSVP,Improve SOTA,Decode seen images by extracting features with a CNN,Watching natural images from 5 classes,Features learned automatically can be more efficient,,EGI,No,None,Internal Recordings,Private,26 (30 initially),128,250,6760,,,"[Hardware: Bandpass from 0.1 to 100 Hz]
1) Bandpass from 0.3 to 30 Hz
2) Removal of eye artefacts",,Raw EEG,Raw EEG,N/M,,N/M,CNN,CNN,"Modified LeNet
CNN is *just* for feature extraction (feature selection and classification is done separately)",Temporal 1D conv in first layer,Yes,128 x 250,2,"Sigmoid, tanh",N/M,,,128 x 11 x 100,N/M,???,N/M,N/M,N/M,N/M,N/M,N/M,,Monte-Carlo 100-fold CV (sampled with replacement),"Train: 90%
Test: 10%","Accuracy
Sensitivity
Sensibility",N/M,,N/M,"Accuracy (across participants, 5-class): 40%",Discrete Wavelet Transform + SVM,Traditional pipeline,,NM,,Amount of data,No,No,"Very verbose. Actually only 2 layers.
They used a CNN to extract features, and applied feature selection and classification separately. I'm confused as to how they trained the CNN...",,Hubert,[TBD],
,Deep Convolutional Neural Network for Emotion Recognition Using EEG and Peripheral Physiological Signal,2017,"Lin, Li & Sun",International Conference on Image and Graphics,,"College of Computer Science of Zhejiang University, Hangzhou, China",,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA: AlexNet on DEAP,AlexNet on Images (Raw EEG + Freq Bands) + other physiological sensors,"Watching videos
(check out DEAP details)",Using AlexNet on DEAP,,N/M,No,Emotions,DEAP,Public (open),32,32,512,N/M,,,"1) Downsampling to 128Hz
2) Band-Pass Filter: 4.0 - 45Hz
3) Average to Common Reference* (?)",,"EEG -> 6 gray images (Raw EEG + Freq Bands)
+ 81 features from other physiological sensors",Frequency-domain,z-score,,N/M,CNN,CNN,AlexNet,"AlexNet is great for images, frequency bands can be converted to images...",Yes,6 Gray Images (2D),"5 CNN
1 FC (81+500)",N/M,N/M,,,"2
Softmax",N/M,-,SGD,"LR: 0.001
(decreases every 500 iterations)",200,Empirically,N/M,N/M,,10-Fold CV,N/M,"Accuracy
F1-Score",N/M,,N/M,"Arousal - Accuracy:  87.30%
Arousal - F1-Score:  78.24%
Valence - Accuracy:  85.50%
Valence - F1-Score:  80.06%","Many other SOTA
(check paper)
They outperform all others.",Traditional pipeline,,N/M,"To achieve better performances, data preprocessing of the original signal was also adopted. The provided experimental results prove the effectiveness and validate the proposed contributions of our method by achieving superior performance over the existing methods on DEAP Dataset.",N/M,No,No,Intriguing... I'll try to reproduce.,,Yannick,[TBD],
,Cross-subject recognition of operator functional states via EEG and switching deep belief networks with adaptive weights,2017,Yin & Zhang,Neurocomputing,No,University of Shanghai,18,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Mental workload & fatigue,Improve SOTA on cross-subject operator functional state recogntion ,"Exploit ""new"" improvements in deep learning",Cabin air management simulation,Using switching deep belief network with adaptive weights,,Nihon Kohden,No,None,Internal Recordings,Private,8,11,500Hz,8640,,,1) Adaptive exponential smooth (to remove outliers),Yes,"Centroid frequency, log-energy entropy, mean, five power components, Shannon entropy, sum of energy, variance, zero-crossing rate of each channel and power differences between channel pairs",Frequency-domain,z-score,,Matlab 2011b,DBN,DBN,One DBN per subject,N/M,Yes,152x1,4,Sigmoid,N/M,,,2,N/M,Unsupervised pre-training of DBNs to learn representation of features for each subject. Supervised fine-tuning of the complete model. ,N/M,"Pre-training: 0.1
Fine-tuning: 1",10,N/M,Yes (addiing Gaussian noise to feature values),N/M*,,Leave-one-subject out,N/M,"Accuracy
True positive
True negative
False positive
False negative","AMD4CPU 1.9GHz, 8G RAM",,N/M,"Mental workload: 77%
Mental fatigure: 68%
MW+MF: 54%","KNN, Naive Bayes, Logistic Regression, SVM, SAE, DBN (with and without PCA) ",DL & Trad.,,N/M,"Results of the proposed method outperform all baselines. When the number of subjects increases, the performance gap between SDBN and baselines increases, suggesting that the number of subjects plays a fundamental role. ",Number of subjects is crucial to obtain a good performance ,No,No,"Paper is really nice, though presentation of the proposed approach and results could be better (it is a bit messy).",,Isabela,[TBD],
,Vowel classification from imagined speech using sub-band EEG frequencies and deep belief networks,2017,Sree & Kavita,"IEEE International Conference on Signal Processing, Communications and Networking ",No,SSN College of Engineering,4,,General Cognitive,Classification of EEG signals,BCI,Active,Speech decoding,Improve SOTA on vowel classification,Use DBNs to extract EEG features,Speech imagery ,N/M,,RMS EEG-32 super spec,No,None,Internal Recordings,Private,5,32,128Hz,N/M,,,1) Band-pass 1-60Hz,No,"Energy features of Wavelet transform: Root Mean Square, Mean Absolute Value, Integrated EEG, Simple Square Integral, Variance of EEG, Average Amplitude Change",Frequency-domain,z-score,,N/M,DBN,DBN,N/M,N/M,No,N/M,7,N/M,N/M,,,N/M,N/M,N/M,N/M,LR: 0.002,N/M,N/M,N/M,Log-likelihood,,N/M,"Train: 80%
Test: 20%",Accuracy,N/M,,N/M,~87.5% (I believe this the average value for all vowels and EEG bands) ,No,None,,N/M,Vowels were more accurately classified in the theta and gamma bands,N/M,No,No,"Paper is limited, specially the results. Did not compared with other methods, which makes hard to analyze the extent of the contribution.",,Isabela,[TBD],
,Bullying incidences identification within an immersive environment using HD EEG-based analysis: A Swarm Decomposition and Deep Learning approach,2017,"Baltatzis, Bintsi, Apostolidis & Hadjileontiadis",Nature Scientific Reports,No,"Aristotle University of Thessaloniki, Khalifa University of Science and Technology",8,,General Cognitive,Classification of EEG signals,Monitoring,Affective,Bullying incidents,New task: classifying bullying stimuli,Classifying bullying stimuli in 2D or VR presentation,Watching stimuli (2D or in VR) of bullying situations,N/M,,Geodesics EEG 400,No,None,Internal Recordings,On request,17,256,250,510,,,"1) Bandpass 0.3-30 Hz
2) Artefact detection, bad channel replacement, baseline correction
3) Channel-wise normalization (- mean, / max)
4) Highpass @7Hz
5) Downsample to 128 Hz",Yes,"1) Swarm decomposition to get oscillatory modes
2) k-means clustering to re-order channels based on the respective distance to each other",Other,N/M,,N/M,CNN,CNN,N/M,N/M,Yes,256 x 128,2,ReLU,N/M,,,2 or 4,N/M,Standard optimization,N/M,N/M,N/M,N/M,N/M,"""Softmax""",,10-Fold CV,"Train: 90%
Test: 10%","Accuracy
Precision
Recall
AUC",N/M,,N/M,"2-class:
Accuracy, precision, recall, AUC (test): 0.937, 0.9403, 0.9395, 0.9869
4-class:
Accuracy, precision, recall, AUC (test): 0.8858, 0.8775. 0.87475, 0.975","No Swarm decomposition or clustering
Just clustering
Just Swarm decomposition",Traditional pipeline,,N/M,"Swarm Decomposition was an important step in getting high accuracy.
Withouth k-means clustering the network was overfitting.",Larger nets take more resources,No,No,"Interesting task. Although the use a CNN, it's not really deep, and it relies on substantial signal processing before being fed into the net.",,Hubert,[TBD],
,Classification and discrimination of focal and non-focal EEG signals based on deep neural network,2017,"Taqi, Al-Azzo, Mariofanna & Al-Saadi",International Conference on Current Research in Computer Science and Information Technology (ICCIT),,"University of Arkansas at Little Rock
Asiacell Company for Telecommunication, Iraq",7,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA,"Detecting Focal vs Non-Focal Seizures with existing Deep Nets: AlexNet, LeNet, GoogleNet",Seizures (Bern-Barcelona Dataset),"deep neural network (DNN) is a high-res model that get sophisticated hierarchical features. (e.g. AlexNet, LeNet, GoogleNet)",,"N/M
(see dataset paper)",No,Seizures,Bern-Barcelona EEG Database,Public (open),5,N/M,256,300 of each class,,,None,No,"None
(Raw EEG)",Raw EEG,N/M,,Caffe,"N/M
(pre-trained models)",NS,"N/M
(pre-trained models)","Using SOTA Networks in Vision/Images for EEG.
(AlexNet, LeNet, GoogleNet)",No,256x256 (images),"N/M
(pre-trained models)","N/M
(pre-trained models)","N/M
(pre-trained models)",,,2,N/M,"pre-trained models
(AlexNet, LeNet, GoogleNet)","N/M
(pre-trained models)",N/M,N/M,N/M,N/M,N/M,,N/M,"Train: 75%
Test: 25%",Accuracy,NVidia GPUs,,N/M,"LeNet, AlexNet, GoogleNet
100%  (with different numbers of TEs)

LeNet is the best compromise","Anindya et al., 2016 : 89.4%
(EMD-DWT domain, K-nearest neighbor classifier)
R. Sharma et al.,2015 : 84%
(DWT domain, KNN, PNN, fuzzy and LS-SVM)
R. Sharma et al.,2014 : 85%
(EMD domain, LS-SVM classifier)",Traditional pipeline,,N/M,"As a future task, we are looking forward to investigating approaches for EEG signals classification of other diseases, drunk people, or ECG signals classification",N/M,No,No,"Not a very good paper. From the language, to the wording...",,Yannick,[TBD],
,Deep Transfer Learning for Cross-subject and Cross-experiment Prediction of Image Rapid Serial Visual Presentation Events from EEG Data,2017,"Hajinoroozi, Mao & Lin",Augmented Cognition. Neurocognition and Machine Learning ,,"University of Texas at San Antonio
National Sun Yat-sen University, Tawain",11,,BCI,Classification of EEG signals,BCI,Reactive,RSVP,Novel Approach: Transfer Learning,"Transfer learning on RSVP task with CNN on Raw EEG:
(1) Cross-Suject 
(2) Cross-Experiment","RSVP (3 datasets from 1990, 1999, 2013)",Transfer learning has a lot of potential for BCI training.,,Biosemi,No,RSVP,"1) USA DoD (1999)
2) USA Army (1990)
3) Touryan et al. (2013)","TBD*
(check references)
DS from 1990's","1) 15
2) 16
3) 10","1) 64
2) 64
3) 256","1) 512
3) 512
3) 512","1) 65,831
2) 62,553
3) 21,680",,,"1) Bandpass filter: 0.1 - 55 Hz
2) Downsampled to 128 Hz
3) Epoching: 1s window",No,"None
(Raw EEG)",Raw EEG,N/M,,N/M,"STCNN
(Spatial-Temporal CNN)",CNN,"Pretty much a CNN with a fancy name.
2 Conv Layers + 3 FC
with dropout",Trying to capture Spatial and Temporal information from Raw EEG,Yes,64x128,"CNN: 2
FC: 3",ReLU,Dropout,,,"2
Target / Non-Target
(softmax)",N/M,"The paper is about transfer learning.
Training on 1 dataset, then fine-tuning (or not) on the other.",N/M,N/M,N/M,N/M,N/M,N/M,,10x 10-Fold CV,N/M,AUC,N/M,,N/M,"Ranging from 73-77%, depending on source / target datasets and transfer type (Cross-Subject or Cross-Experiment)","Bagging, XLDA, LDA",Traditional pipeline,,"Yes (read paper for full description)
All Layers: Subject Specific Info.
CNN Layers: Mostly Subj. Specific Info.
All Layers: General Info as well.",This study represents the first comprehensive investigation of CNN transferability for EEG based classification and our results provide important information that will guide the design of more sophisticated deep transfer learning algorithms for EEG based classifications in BCI applications.,N/M,No,No,"Very interesting paper on transfer learning!
You need to ""fine-tune"" to get good results on new data, otherwise the more layers the less transfer.",,Yannick,[TBD],
,Transformation of EEG Signal for Emotion Analysis and Dataset Construction for DNN Learning,2017,"Kwon, Nan, & Shin Dug",Advances in Computer Science and Ubiquitous Computing ,,Yonsei University,6,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Use DNN on Frequency features for emotion classification,Watching Videos (not much details on the videos),DNN shows strong modeling ability for more complex cases,,EPOC,No,"Emotions
(PSD)",Internal Recordings,Private,N/M,14,128,,Offline,,"1) Remove DC offset
2) High-pass filter: 4Hz",No,Frequency Bands,Frequency-domain,N/M,,N/M,DNN,NS,N/M,N/M,Yes,"9
(not sure why 9...)","2
(100 and 50 nodes)",N/M,N/M,2,"Happy, Neutral",2,N/M,N/M,N/M,N/M,396,N/M,N/M,N/M,N/M,N/M,N/M,Accuracy,N/M,,N/M,"Stacking each row: 92%  (after ~3000 epochs)
Batch size 396: 86.5% (after 50000 epochs)",N/M,None,N/M,N/M,"We have found that the placement of the input data is as important as the preprocessing of the raw data. In our emotion classification experiment, we showed superior performances when we learn by stacking one row at a time than learning happy data matrix and neutral data matrix sequentially",N/M,No,No,"Not a good paper. Very little information. Not even the number of participants nor the length of the session, unless the 5 minutes is the full duration including both classes... Which is very little data.",,Yannick,[TBD],
,The Analysis and Classify of Sleep Stage Using Deep Learning Network from Single-Channel EEG Signal,2017,"Xie, Li, Xie, Wang & Duan",Neural Information Processing,,"Northwestern Polytechnical University, China",7,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use CNN on Frequency features for sleep stage classification,Sleep (Sleep-EDF dataset),CNN has been proved to be very good at discovering the intricate structures in complex data.,,"N/M
(see dataset paper)",No,Sleep,Sleep-EDF,Public (open),11,1,"N/M
(see dataset paper)",N/M,,,"1) Bandpass filter: 1 - 40 Hz
2) Epoch of 30s windows
3) Epochs with artifacts removed
4) STFT for Freq Band Features",Yes,Frequency,Frequency-domain,z-score,,N/M,CNN,CNN,"Pooling ""layers""",CNN for Time-Frequency Image,Yes,"20x40 pixels
(Time-Frequency Image)",2,Sigmoid,N/M,,,"4
(4 Sleep Stages)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,,Leave-one-out,N/M,"Accuracy
Sensitivity
Specificity",N/M,,N/M,"Accuracy: 
Specificity: 
Sensitivity: ","MI+SOM: ~70%
PSS+ANN: ~81%
SF+AdaBoost: ~82%",Traditional pipeline,,N/M,"In comparison with several recently available methods on the single channel classification of sleep stages, the present study has certain advantages with 88.83% in terms of the accuracy.",N/M,No,No,Very short paper. Not much details,,Yannick,[TBD],
,Deep Models for Engagement Assessment With Scarce Label Information,2017,"Li, Zhang, Wang, Xu, Schnell, Wen, McKenzie & Li",IEEE Transaction on Human-Machine Systems,,"Old Dominion University, Norfolk, VA
Intelligent Automation, Inc., Rockville, MD
University of Iowa, Iowa
Georgia Institute of Technology, Atlanta, GA",8,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Engagement,Improve SOTA,Use Deep Classifier & Deep Autoencoder on a Flight Simulator task for engagement classification,Flight Simulator (4h flight) with specific and controlled events,Unsupervised and semisupervised algorithms can utilize unlabeled data for training and thus improve the generalization capability of the model [15]–[17].,,ActiCap,No,"Engagement
(via PSD)",Internal Recordings,Private,15,"8
(out of 32)",200,"10 min of Engaged 
+ 10 min of Disengaged 
x 15 pilots",,,"1) Visual Inspection & Artifact Removal
2) High-Pass filter: 0.5Hz
3) Notch filter: 60Hz
4) Wavelet-based method to remove physiological noise",Yes,1-Hz bin PSDs,Frequency-domain,N/M,,N/M,RBM,RBM,"We used Gaussian–Bernoulli RBMs for training the first layer that contains real-valued visible units [34]. 
We utilized Bernoulli–Bernoulli RBMs for training higher layers that contain binary visible and hidden units.",N/M,Yes,"312 Features
(39 Freq Bins * 8 Channels)",2,Sigmoid,Dropout,,,"1
Engaged / Disengaged
(SVM)",N/M,Pre-training,N/M,N/M,N/M,Tested different hyperparameters by performing fivefold CV and compared performance results from these combinations.,N/M,not clear,,5-Fold CV,not clear,Accuracy,"HP Z800 Workstation
2x Intel Xeon x5660
48Go Ram
GeForce GTX 780",,10 min / subject,Accuracy: 97.53%,"Compared 10 Methods + 3 other papers
Shen et al., 2008 (SVM)
Trejo et al., 2007
Lan et al., 2003",Traditional pipeline,,N/M,"This paper has studied engagement assessment of pilots under com- plex tasks with limited labeled EEG data. We developed deep learning models that were able to learn valuable high-level features by taking advantage of both unlabeled and labeled data. Two deep models (a deep classifier and a deep autoencoder) have been studied, and both models outperformed two traditional methods when label information was limited for training.","1) We did not study the physiological significance of the learned high-level representations.
2) We did not address the in-dividual variations among subjects
(We have developed systematic methods to handle the issue, and a separate paper is under preparation)",No,Yes,A little hard to follow.,,Yannick,[TBD],
,Deep Learning Representation from Electroencephalography of Early-Stage Creutzfeldt-Jakob Disease and Features for Differentiation from Rapidly Progressive Dementia,2017,"Morabito, Campolo, Mammone, Versaci, Franceschetti, Tagliavini, Sofia, Fatuzzo, Gambardella, Labate, Mumoli, Tripodi, Gasparini, Cianci, Sueri, Ferlazzo & Aguglia",International Journal of Neural Systems,No,"University Mediterranea of Reggio Calabria, Italy
Neurologic Institute “Carlo Besta”, Milan, Italy
Institute of Neurology, University of Catania, Italy
Magna Græcia University, Catanzaro, Italy
Bianchi-Melacrino-Morelli Hospital Reggio Calabria",15,,Other Pathology*,Classification of EEG signals,Clinical,Dementia,,Novel Approach,"Use DL for Creutzfeldt-Jakob Disease.
3 binary classifications on 4 classes using SAE+MLP",EEG Recording of Patients with different diagnosis related to Creutzfeldt-Jakob.,"Hierarchical network models, such as the DL transform observed variables (input of the procedure) in latent variables, which express both the relevant aspects of the given data and the underlying feature-generation process.",,N/M,No,"Raw EEG
(looking for changes in time-freq power)",Interlan Recordings,Private,76,19,N/M,N/M,,,"1) High-pass filter: 0.5Hz
2) Low-pass filter: 70Hz
3) Notch filter: 50Hz
4) Visual Inspection and removal of artifacts
5) Windows of 5s",Yes,"Time-Frequency 
(CWT)",Frequency-domain,N/M,,"Matlab
NeuralWorks Professional II Plus, NeuralWare","Stacked AE
+ MLP or SVM",AE,"Contractive Encodings (?)
AE reducing features to 20 ""super features"" in an unsupervised fashion","Although the averaging step reduces the impact of local (time) distribution of frequencies, so partially limiting the usefulness of the same time-freq analysis, the availability of the three estimated statistical quantities gives synthetic information on the underlying probabilistic distribution.",Yes,"12 x 19
(Features x Channels)","SAE: 2
FC: 2 ",Sigmoid,L2,,,"2
(3x Binary Comp. for 4 classes)
",N/M,"1) SAE (Unsupervised)
2) Fine-tune for MLP on Top of Encoder (Supervised)",N/M,Annealing procedure for the learning rates that basically starts from high values (0.1) to reach very small values (0.01),N/M,Trial-and-Error,N/M,RMS,,Leave-one-out,"Train: 75%
Test: 25%","Accuracy
Sensitivity
Specificity",N/M,,N/M,"                                   Acc | Sens | Spec
CJD versus RPD:      89  |   92   |  89 
CJD versus AD:        88  |   94   |  85
CJD versus HC:        87  |   86   |  84","SVM (on top of AE)
                                   Acc | Sens | Spec
CJD versus RPD:      77  |   76   |  81 
CJD versus AD:        83  |   93   |  73
CJD versus HC:        76  |   74   |  72",Traditional pipeline,,N/M,"The unsupervised training of the auto-encoder has the additional advantage of simplifying the train- ing of the full DL scheme, since it moves the weights of the representation to a region more related to the actual inputs: in other words, the “gradient dilu- tion” effect, often met during training of deep many- layered NN, is largely reduced","1) One of the limitations of the presented DL approach is that the “super-features” identified as output of the two-layer auto-encoder are difficult to be used in clinical settings, being a nonlinear combination of averaged time-frequency quantities.
2) Small dataset",No,Yes,"It would be nice to have access to the dataset! 
Overall good paper, good description...",,Yannick,[TBD],
,SGDR: Stochastic Gradient Descent with Warm Restarts,2017,Loshchilov & Hutter,International Conference on Learning Representations  2017,Yes,University of Freiburg,16,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use SGD with warm restarts to for 2-classes motor imagery classification,Motor imagery,Automatic feature learning,,N/M,No,None,N/M,Public (account),14,"N/M
(see dataset paper)","N/M
(see dataset paper)",14*1000,,,N/M,N/M,Raw EEG,Raw EEG,N/M,,Lasagne,CNN,CNN,N/M,Used same architecture as Schirrmeister et al. ,No,N/M,N/M,N/M,N/M,,,N/M,N/M,"When 30 epochs were considered, lr is dropped by a factor of 10 at epoch indexes 10, 15 and 20",SGD with warm restarts,lr=0.025 and 0.05,N/M,N/M,N/M,N/M,,N/M,N/M,Accuracy,N/M,,N/M,Improvement of 1-2% and 2-3%,Schirrmeister et al.,DL,,No,SGDR provides a similar final performance w.r.t a budget proportional schedule while having a better anytime performance without defining the total budget of epochs beforehand,N/M,Yes,No,This paper mostly provides an improvement to SGD and uses a 2-classes motor imagery in one of the experiments. Re-used the architecture of Schirrmeister et al. (people from the same university). ,,Isabela,[TBD],
,Deep Learning Human Mind for Automated Visual Classification,2017,"Spampinato, Palazzo, Kavasidis, Giordano, Souly & Shah",IEEE Conference on Computer Vision and Pattern Recognition (CVPR),Yes,"PeRCeiVe Lab Viale Andrea Doria, Italy
University of Central Florida",9,,Other,Classification of EEG signals,BCI,Reactive,RSVP,Novel Approach - Vision,"Identify Image Class from brain responses.
Using DL on EEG while watching images from ImageNet",Looking at Images from ImageNet while recording EEG,"Deep learning performs well for computer vision, but could we use the human brain instead, leveraging DL on EEG + Images",,"ActiCap
(Brainvision)",No,Raw EEG,Internal Recordings,Public (open),6,128,1000,"12,000",,,"1) Notch filter: 49 - 51 Hz
2) Band-pass (2nd Order Butterworth): 14 - 71 Hz",No,"None
(Raw EEG)",Raw EEG,z-score,,"Torch
Caffe",LSTM + CNN,CNN+RNN,"Yes.
Combined network for: EEG + Image
2 classifications
(See Figure 2 for more details)","LSTM: Temporal Dynamics
CNN: To capture the Image features from both the Image and the EEG feature space (from LSTM)",Yes,"128x440
(channels x time)",(not clear),ReLU,N/M,,,"Not clear. 
Should be 40 classes (softmax)",N/M,"1) End-to-End
2) Deep feature extraction followed by regressor training",N/M,N/M,N/M,N/M,N/M,N/M,,N/M,"Train: 80%
Valid: 10%
Test: 10%","Accuracy
MSE",NVidia Titan X,,N/M,"RNN Part: 83%
CNN Part: (Not clear, using MSE as metric)
Combined Part: 89%
(wtf, these can't be on 40 classes...) ","Kaneshiro et al., 2015  (29% over 12 classes)",DL,,No,"As future work, we plan a) to develop more complex deep learning approaches for distinguishing brain signals generated from a larger number of image classes, and b) to interpret/decode EEG-learned features in order to identify brain activation areas, band frequencies, and other relevant information necessary to uncover human neural underpinnings involved in the visual classification",N/M,Yes,No,"Awesome webpage explaining the paper, access to the data, the code, the pretrained models... That's where we need to go as a field! 
The results can't be on 40 classes of images...",,Yannick,[TBD],
,Deep Learning Using EEG Data in Time and Frequency Domains for Sleep Stage Classification,2017,"Manzano, Guillén, Rojas & Herrera",Advances in Neural Networks – ISNN,,University of Granada,10,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use CNN on Time domain and DNN on Frequency domain for Seep Stage classification on a single channel,Sleep (ongoing Polysomnography),Novel and interesting,,"N/M
(see dataset paper)",No,"Raw EEG
(Sleep)",St. Vincent's University Hospital / University College Dublin Sleep Apnea Database,Public (open),25,1,128,"20075 (total)
(173.2h; ~6.9h/subject)",Offline,,"1) Notch filter: 50Hz
2) High-pass filter: 0.3Hz
3) Downsampled to 64Hz",No,"(1) Raw EEG
(2) Frequencies",Raw EEG,N/M,,N/M,"1) CNN
2) NN",CNN,N/M,N/M,Yes,Not sure they mention it,"CNN: 2
FC: 1",N/M,"Dropout
(0.5)",5,Sleep Stages,5,N/M,N/M,N/M,LR: 0.01,512,Trial and Error,N/M,N/M,Inter,"Leave-one-out
(LOO)",N/M,"Accuracy
F1-Measure",N/M,,N/M,"                                       Accuracy  |  F1-measure
Time domain:           68.6%   |   54% 
Frequency Domain:    68.9%   |   57.5%","Tsinalis et al., 2016 : 74%
Zhang et al., 2015 : 91%",DL,N/M,N/M,68.9% obtained in patient-cross-validation is considered very promising taking into account that it uses a single EEG channel with no more information,N/M,No,No,"Below other results, but mention that others are using more data, more chanels, etc. It makes it hard to compare, at least having all the results next to one another online will help. But even then, the leaderboard won't be perfect...",,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,EEG-based prediction of driver's cognitive performance by deep convolutional neural network,2016,"Hajinoroozi, Mao, Jung, Lin & Huang",Signal Processing: Image Communication,,"University of Texas at San Antonio
UCSD
National Chiao Tung University",,,Transportation,Classification of EEG signals,Monitoring,Cognitive,Fatigue,"New Approach: CCNN & CCNN-R
CCNN:      Channel-wise CNN
CCNN-R:  Channel-wise CNN + RBM",,Driving Simulation,,,Neuroscan EEG Headset (30 channels),,Raw EEG,Internal Recordings,Private,37,30,250,"Good Driving: 35 000
Bad Driving: 25 000",,,"1) Downsampled to 250Hz
2) Band-Pass filter (FIR): 1-50Hz",,"1) Raw EEG (30 channels)
2) ICAs (30 ICs)",Raw EEG,,,"Caffe, MATLAB","CCNN
CCNN-R",CNN,"Activation Function: Sigmoid
Kernel Size (conv): 1x250",,,[read me again],"1 Conv
2 FC",,,,,[read me again],N/M*,,"CCNN: Drop-out 50%
CCNN-R: Drop-out 90%",,,,N/M*,N/M*,,,,,,,N/M*,"[Within-subject] CCNN: 86.08%      |      CCNN-R: 80.67%
[Cross-subject] CCNN: 63.39%      |      CCNN-R: 76.72%","LDA, SVM, PCA+LDA, PCA+SVM, PSD SVM, PCA+DNN, CSP+DNN, XDAWN+DNN, DNN, CNN",DL & Trad.,,,,,No,No,,,Yannick,[TBD],
,Wearable seizure detection using convolutional neural networks with transfer learning,2016,"Page, Shea & Mohsenin",IEEE International Symposion on Circuits and Systems,,"University of Maryland, Baltimore County (UMBC)",4,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Prediction,Improve state-of-the-art,Using CNN for seizure prediction,Seizure detection,Exploring Max-Pooling CNN with end-to-end training for seizure prediction and measure computer power required. (to make low power devices),,"N/M
(see dataset paper)",No,Seizures,CHB-MIT,Public (open),23,23,256,"N/M
(see dataset)",,,"1) Downsampling to 64Hz
2) Filtering Line Noise (freq N/M)",No,Raw EEG,Raw EEG,N/A,,N/M,CNN,CNN,Max Pooling,N/M,No,"N/M

15s time windows 
(raw EEG)","CNN: [1-3]
FC: [1-3]",N/M,Dropout,,,"1
(Softmax)",N/M,"For HM: Secondly, during training only the last 1-2 fully connected layers’ weights are adjusted",N/M,N/M,"Yes
(# N/M)",Random Hyperparam selection,"To improve performance, the data is augmented by both randomly mirroring left-to-right the channel data and injecting Gaussian noise into each channel.",N/M,,"GM: Leave-one-patient-out
PM: Leave-one-record-out
HM: Leave-one-record-out","Train: 75%
Test: 25%","Onset Sensitivity
False Alarm Rate
Latency",NVIDIA Jetson TK1,,N/M,"GM: [AUC] 0.926 | [FAR] 9 /day | [Onset Sens.] Failed for 3 subjects
PM: [AUC] 0.946 | [FAR] 6 /day | [Onset Sens.] 100%
HM: [AUC] 0.967 | [FAR] 3 /day | [Onset Sens.] 100%","Nothing external. Only their own approaches:
PM vs GM vs HM",Traditional pipeline,,N/M,The plots reveal that HM generally requires less training data to perform well and with less variance.,N/M,No,Yes,"Transfer learning, but within the same dataset. Would have been nice to see across datasets...",,Yannick,[TBD],
,Learning robust features using deep learning for automatic seizure detection,2016,"Thodoroff, Pineau & Lim",1st Machine Learning for Healthcare Conference,Yes,"McGill, UofT",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,New Approach: Using a Recurrent CNN with Image Based Features. (based on Bashivan et al. (2016) model),"Using Recurrent CNN on images (RGB 16x16 pixel, reprensenting spatial & frequency) for Epilepsy",Seizure detection,Using Bashivan et al. (2016) approach for epilepsy,,"N/M
(see dataset paper)",No,Seizures,CHB-MIT,Public (open),22,23,256,"N/M
(see dataset)",, ,"1) 3D Coordinates to 2D (Polar Projection)
2) FFT for 3 Freq Bands",,"3 Frequency Bands to RGB 16x16 pixels
(0-7Hz, 7-14Hz, 14-49Hz)
Bashivan et al. (2016)",Frequency-domain,N/A,,N/M,CNN-R,CNN,Recurrent convolutional neural network using image-based representation of EEG,"3D Electodes to 2D Plan
3 Frequency Bands to R,G,B",Yes,"3x16x16
(RGB Image 16x16 pixel)","CNN: 4
LSTM: 128 HU
FC: 1 (512 HU)",N/M,N/A,,,1,N/M,"Pre-training
1) Trained CNN Layers alone
2) Then trained full network
3) Using transfer learning, train on a specific subject
4) Use Ensemble with 3 identical network with different initialization",RMSProp,"Dropout = False
LR = 0.001",128,Sampled uniformly randomly over the hyper-parameter space to optimize the parameters of the model,"N/M
(subsampling to balance classes)",N/M,,Leave-one-out,N/A,"Sensitivity
False Positive",N/M,,N/M,"Avg. Sensitivity: 85%
False Positive: 0.8/h","Patient Specific: Shoeb (2009) detector
Across Patients: REVEAL (Wilson et al., 2004)
REVEAL is a commercial algo",Traditional pipeline,,N/M,"Another advantage of this architecture lies in its ability to detect where a seizure is happening in the brain. Indeed, by occluding part of the image and testing the model’s ability to predict the correct label we can define which area of the brain is responsible for the activation.
However, our neural model turns out to be significantly more robust to missing channel as observed in Figure 6.","Amount of Data and Seizures
(despite using the largest publci dataset)",No,Yes,"Nice description of Epilepsy
Nice Graphs
Compared with results from 2009...
I'm he could have compared with more recent",,Yannick,[TBD],
,Single-trial EEG RSVP classification using convolutional neural networks,2016,"Shamwell, Lee, Kwon, Marathe, Lawhern & Nothwang","Proc. SPIE 9836, Micro- and Nanotechnology Sensors, Systems and Applications",,"Army Research Laboratory, USA",10,,BCI,Classification of EEG signals,BCI,Active,RSVP,Improve state-of-the-art,Using CNN for Single-Trial RSVP from raw EEG,RSVP blocks of 5 images and the participant press a button if an image is part of a specific class,"Low SNR + High Dimensionality, Deep Learning with Large Dataset can find patterns. As opposed to pre-defined ones.",,Biosemi,No,"Raw EEG
(RSVP)",Internal Recordings,Private,18,"64
(out of 256)",1024,N/M,,,"1) Downsampled to 256Hz
2) Bandpass filter: 0.5 - 50Hz",No,None,Raw EEG,N/M,,N/M,CNN,CNN,Local response normalization (LRN) layers are included after each convolutional layer to normalize each layer’s filter responses.,"1) The first layer was thus chosen to span a 250 ms window to allow the network to learn feature maps over an extended temporal window
2) 2nd conv layer is another a temporal filter
3) 3rd conv layer computes spatial filters across
4) Final conv layer is a filter over the spatiotemporal responses",Yes,"250ms window
(raw EEG)","CNN: 4
FC: 2",ReLU,Dropout,,,"2
(softmax)",N/M,"We followed (Krizhevsky et al., 2012) by monitoring the network loss and lowering the learning rate whenever the loss began to flatten. However we instead lowered the learning rate by a factor of 5 instead of 10.",SGD,LR,N/M,,Downsampling the larger non-target class to balance classes,Cross-Entropy,,N/M,"Train: 50%
Test: 50%

First half of the experiment for all subjects / second half for all subjects.",AUC,N/M,,N/M,AUC: 0.7252,"CSP: 0.6261 *
HDCA: 0.66 *
XD+BLDA: 0.7151 *
CNN: 0.7252

* Trained and Tested per subject, not across subjects.",DL & Trad.,,Yes,"We found that stochastic gradient descent (SGD) does not perform well with class imbalances. With greatly imbalanced numbers of target and non-target, SGD may result in the network learning the distribution over the number of targets versus non-targets rather than the true desired distribution over targets versus non-targets.",N/M,No,No,-,,Yannick,[TBD],
,Affective states classification using EEG and semi-supervised deep learning approaches,2016,"Xu, Plataniotis",18th IEEE International Workshop on Multimedia Signal Processing (MMSP),,University of Toronto,,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,Improve state-of-the-art,,Affective States (Arousal/Valence/Liking) on DEAP,,,N/M*,,PSD,DEAP,Public (open),32,32,512Hz,N/M*,,,"1) Re-reference: Common Average.
2) Downsampled to 256Hz
3) Band-Pass filter: 4-45Hz",,"PSD
15 narrow-bands",Frequency-domain,,,N/M*,"SDAE
BDN",AE,[read comments],,,"480x1
(32 channels x 15 bands)","SDAE: 2
BDN: 3",,,,,3 (softmax),N/M*,,N/M*,,,,N/M*,"SDAE: RMSE
BDN: Cross-Entropy",,5:1 Training:Validation,,,,,N/M*,"[Arousal]  DBN: 86.67%   |   SDAE: ~81% 
[Valence]  DBN: 86.60%   |   SDAE: ~82% 
[Liking States]  DBN: 86.69%   |   SDAE: ~81% ",SVM,Traditional pipeline,,,[...] With only less than 15% of the input data were labeled,,No,No,,,Yannick,[TBD],
,Automatic Sleep Stage Scoring with Single-Channel EEG Using Convolutional Neural Networks,2016,"Tsinalis, Matthews, Guo, Zafeiriou",Arxiv,Yes,Imperial College London,12,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve state-of-the-art,Automatic sleep scoring using single channel EEG,Sleep (PSG),,,N/M*,No,Raw EEG,Sleep EDF,Public (open),20,1,100Hz,N/M*,,,None,,Raw EEG,Raw EEG,N/M,,Theano+Lasagne,CNN,CNN,Stacking (reshaping) layer between 1st and 2nd conv layer ,N/M,Yes,15000x1,"Conv: 2
FC: 2
Stacking: 1 ",ReLU,L2,,,5 (softmax),N/M,N/M,SGD,N/M,N/M,N/M,N/M,Categorical cross-entropy,,20-fold,"Train: 19 subjects
Test: 1 subject","Overal accuracy 
Per-stage accuracy 
F1-score
Precision
Sensitivity",N/M,,N/M,"Stage N3 presented highest accuracy (~90%).
When comparing to the baselines, there is not much improvement in terms of accuracy, sensitivity, and precision.
",Previous work (CNN with Morlet wavelets as input and stacked autoencoder with hand-engineered features as input),DL,,Yes,"""However, we observe that the 95% confidence intervals across subjects
overlap across the three models, across almost all of
the metrics"". 
""[...] hand-engineering of features based on the AASM manual (SAE model) may have better performance than automatic filter learning (CNN model)"".",,No,No,"Paper is nice (cool analysis of learned parameters), but proposed method doesn't bring too much novelty or improvement to SOTA obtained by the same group.",,Isabela,[TBD],
,Mental State Recognition via Wearable EEG,2016,"Bashivan, Rish & Heisig",Arxiv,Yes,University of Memphis,10,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive vs. Affective,,Proof-of-concept,Monitor mental states using a wearable device,EEG recording while subjects watched movies,,,Muse,No,Raw EEG,Internal Recordings,Private,13,4,220Hz,N/M,,,None,Yes,Spectral power and connectivity (correlation between power in different bands),Frequency-domain,N/M,,N/M,DBN,DBN,-,N/M,No,N/M*,3,N/M,L1,,,2 (softmax),N/M, Parameters of each layer of DBN were greedily pre-trained,SGD,N/M,N/M,N/M,N/M,N/M,,"2-fold
Leave-one subject-out (13-fold)",N/M,"False-negative rate
False-positive rate
Combined error rates",N/M,,N/M,"Intra-subject: SVM was the best (FPR: 31.5%, FNR:
19.8%)
Inter-suject: DBN (FPR:38.3%, FNR:6.2%) and LR (FPR: 27.9%, FNR: 23.3%) were the best.","Logistic regression, SVM, Random Forest",Traditional pipeline,,No,"Surprisingly, the logistic regression model preferred connectivity features instead of spectral ones. ",N/M,No,No,Paper is very preliminar. The focus is more in showing that it is possible to classify mental states with data from a wearable devices than in neural networks. Discussion and analysis focused on feature engineering aspects.,,Isabela,[TBD],
,Neural networks based EEG-Speech Models,2016,Sun & Qin,Arxiv,Yes,Southern Illinois University Carbondale,10,,Other,Classification of EEG signals,BCI,Active,Speech decoding,Novel Approach - Speech,Classify Speech from EEG,"3 modalities (EEG, face tracking, and audio) during imagined and vocalized phonemic and single-word prompts. Looking a the monitor, participants were asked to do the phonemes as instructed. (imagined and/or spoken)",To better model the non-linearity between the brain signals and speech,,Neuroscan Quick-Cap,No,Speech,KARA ONE,Public (open),14,64,N/M,132 / participant,,,"1) ICA for ocular artifacts
2) Band-pass filter: 1 - 200 Hz
3) Mean value substracted for the signal
4) Epoched
5) Normalized",Yes,"None
(Raw EEG)",Raw EEG,z-score,,Matlab,"1) NES-I
2) NES-B
3) NES-G
(RBM based models)",RBM,"(read paper for more info, lots of maths)","(read paper for more info, lots of maths)",No,"62/10 x ?

They try with 62 and 10 channels",(not clear),Sigmoid,N/M,,,"2 or 11
(softmax)",N/M,N/M,"N/M
(but has momentum, wd, lr)","Weigh Decay: 0.0001
LR: 0.1
Momentum: 0.5",2000,N/M,N/M,N/M,,N/M,N/M,Accuracy,N/M,,N/M,"Binary Classif : C/V | Nasal | Bilab | /iy | /uw/      
               INES: 0.25 | 0.47 | 0.53 | 0.53 | 0.74 
        IANES-B: 0.27 | 0.59 | 0.52 | 0.62 | 0.78
        IANES-G: 0.41 | 0.74 | 0.71 | 0.76 | 0.87
[All Phonemes] Mean Accuracy: 41.5%  (11 classes!)","SVM: 0.18 | 0.64 | 0.57 | 0.59 | 0.79   (Zhao et al., 2015)
DBN: 0.87 |  − −  |  − −  |  − −  | 0.82   (Zhao et al., 2015)",DL & Trad.,,No,"The EEG based speech classification results indicate that the proposed NES models outperform a baseline method SVMmulti for 11 phonological categories. In the binary classification task, the proposed NES-G model overall achieves the best performance than nonlinear SVM classifier.",N/M,No,No,Not super clear in term of the EEG signal -> input. (dimensionality wise),,Yannick,[TBD],
,Combining Generative and Discriminative Neural Networks for Sleep Stages Classification,2016,"Giri, Fanany & Arymurthy",Arxiv,Yes,"Universitas Indonesia
Bogor Agricultural University",13,,Sleep,Classification of EEG signals,Clinical,Sleep,Staging,Improve SOTA,Use DBN + LSTM for sleep stage classification,Sleep,Combining the power of generative and discriminative DL models.,,N/M,No,Sleep Stages,"1) Benchmark Dataset 
(not clear)
2) MKG Dataset (can't find)",Public (open),"N/M

(10 night sleep)",N/M,N/M,N/M,,,"N/M

(probably same as Langkvist et al., 2012)","N/M

(probably same as Langkvist et al., 2012)","28 features

(Langkvist et al., 2012)",Other,N/M,,"Matlab
Python
Keras
Tensorflow",DBN + LSTM,RNN,-,The main idea is to fuse generative ability on DBN to extract multi-level hierarchical features and determine the final label of class prediction using the time series discrimination capability of LSTM.,Yes,28 Features,"DBN: 2
LSTM: 5",N/M,N/M,,,"5
(softmax)
(Sleep Stages)",N/M,"(Pre)Train DBN first, then LSTM",RMSProp,Epoch 100,500,N/M,N/M,Categorical Cross-Entropy,,Leave-one-out CV,"5:1

(I think that like many people, we confuse Validation and Test)","Accuracy
F1-Score","- (DBN) -
Intel i7-4700HQ
2.6 GHz
4 GB
- (LSTM) -
4x NVidia GTX Titan
128GB",,"Yes, nice explanation and graphs.
LSTM = Fast
DBN = Slow (17h on the full MKG dataset)","REM (99.63%) 
WAKE (98.64%)
SWS (98.27%)
S1 (98.24%)
S2 (97.69%)","[Internal]              DBN
[Internal]   DBN+HMM
[Internal]            LSTM
 [Internal]  DBN+LSTM*

Zhang et al., 2015 (supposed to be SOTA)  [External]",DL,,,"Our experiments showed that the combination of DBN with LSTM gives better overall accuracy 98.75% (Fscore=0.9875) for benchmark dataset and 98.94% (Fscore=0.9894) for MKG dataset. This result is better than the state of the art of sleep stages classification that was 91.31%.
From it, we can conclude DBN successfully boost the accuracy level for LSTM, because when the LSTM not using DBN, we only get the accuracy value on 0.636 (F-score 0.655). On the other hand, if we use only DBN the accuracy just 0.515.","Our model still needs input in the form of ”handcrafted” feature extraction procedure. On the other hand, the state of the art directly using raw data so that the flexibility of state of the art may be better than our proposed DBN+LSTM model.",No,No,"Nice description of the ""time"" to run these algos.",,Yannick,[TBD],
,Multimodal Emotion Recognition Using Multimodal Deep Learning,2016,"Liu, Zheng & Lu",International Conference on Neural Information Processing,Yes,Shanghai Jiao Tong University,7,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Use multimodal deep learning algorithms,Watching video clips,,,N/M,No,None,DEAP and SEED,Public (account),"32
15","32
62","1000Hz
250Hz",N/M*,,,"DEAP: same as DEAP paper
SEED: None",No,"None
PSD and differential entropy",Raw EEG,min-max,,N/M,AE,AE,"When eye-tracking data is available, a bi-modal AE was used",N/M,Yes,N/M,3,N/M,N/M,,,N/M,N/M,"First, a RBM was trained and its weights were used as initialization for the AE ",N/M,N/M,N/M,N/M,N/M,N/M,,N/M,N/M,Accuracy ,N/M,,N/M,"DEAP:  85.2% (valence), 80.5% (arousal), 84.9% (dominance), 82.4% (liking) 
SEED: 89.94%",Two previous works (didn't mentioned if those were SOTA),Traditional pipeline,,No,Using the bi-modal AE provided better results even when no eye-tracking data was available,N/M,No,No,I found the paper a bit confusing. Results are messy and apparently no cross-validation was used. ,,Isabela,[TBD],
,Interpretable Deep Neural Networks for Single-Trial EEG Classification,2016,"Sturm, Bach, Samek & Müller",Arxiv,Yes,"Berlin Institute of Technology
Fraunhofer Heinrich Hertz Institute
Korea University",5,,Other,Improvement of processing tools,Model interpretability,Model visualization,,Novel Approach,Introducing Layer-wise Relevance Propagation (LRP) for DL-EEG (vizualisation),Demonstrated on the BCI-MI Competition III dataset IVa,"DNN are black boxes, but with this approach, we could see what features they are learning.",,"N/M
(see dataset paper)",No,Motor Imagery,"BCI Competition III
dataset IVa",Public (open),5+5,"N/M
(see dataset paper)","N/M
(see dataset paper)","N/M
(see dataset paper)",,,"1) Downsampled to 100Hz
2) Bandpass filter: 9-13Hz",No,"None
(Raw EEG)",Raw EEG,N/M,,N/M,DNN,NS,"(basic DNN, but the network itself is not relevant, the paper is about LPR)",N/M,No,"301x118
(time points x channels)",2,N/M,N/M,,,"2
(right/left hand)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,,Leave-one-out,N/M,Accuracy,N/M,,N/M,"Mean Accuracy: 71.6%  (DS #1)
Mean Accuracy: 78.2%  (DS #2)
(not very relevant as the paper is not about the model, but LPR)","CSP-LDA
(didn't do better on average, but did better on low performing subjects)",Traditional pipeline,,No,"For instance, this substantially increased classification accuracy in a subject with particularly low accuracy. This is a first hint that DNN technology may be beneficial for subject-to-subject transfer of learned neural rep- resentations, and, ultimately, may advance subject-independent zero training strategies in BCI [18].",N/M,No,No,"Didn't really explained the LPR. I will investigate more, but it seems quite interesting!",,Yannick,[TBD],
,Ischemic stroke identification based on EEG and EOG using ID convolutional neural network and batch normalization,2016,"Giri, Fanany, Arymurthy",IEEE International Conference on Advanced Computer Science and Information Systems ,Yes,"Bogor Agricultural University
Universitas Indonesia",8,,Other Pathology*,Classification of EEG signals,Clinical,Ischemic stroke,,Improve SOTA,Use DL for Stroke classification,On going EEG recording: Stroke Patients vs Healthy Patients,"Other ML approaches have been tried and show encouraging results, but yet nothing good enough to be used reliably",,Xltek & Biologic,No,"Lowering of Frequencies
(due to stroke)",Internal Recordings,Private,"32 Stroke
30 Healthy","EEG: 2 (out of 33)
EOG: 2",512 & 256,15 min / subject,,,1) Downsample to 64Hz,No,"24 Handcraft features
(relative power band frequency, variance, correlation aspect, kurtosis, entropy, spectral mean, and exponent of fractal)",Other,N/M,,"Keras, Theano, Python",1D CNN,CNN,Batch norm,1D conv. operation is useful to extract the important local feature in between neighbouring element value of feature vector.,Yes,"62x24
(? x Features)","1DCNN: 2
FC: 1",N/M,N/M,,,2,N/M,Early stopping,N/M,N/M,N/M,N/M,N/M,N/M,,Leave-one-out,N/M,"Accuracy, Sensitivity, Specificity, F1-Score, Precision, Recall",Quad Core i7 CPU 2.4GHz with 4GB of RAM,,N/M,"Accuracy: 0.861, F1-Score: 0.861
Sensitivity: 0.861, Specificity: 0.865
Precision: 0.870, Recall: 0.861","NB, CT, RF, NN, kNN, Logreg",Traditional pipeline,,No,"In this study, we apply early stopping and Batch Normalization techniques to accelerate training process of our classification model. The results of the experiment show that deep learning approach IDCNN has managed to be the best model to distinguishing task between EEG stroke data to the EEG.",N/M,No,No,-,,Yannick,[TBD],
,Deep convolutional neural networks for classification of mild cognitive impaired and Alzheimer's disease patients from scalp EEG recordings,2016,"Morabito, Campolo, Ieracitano, Ebadi, Bonanno, Bramanti, De Salvo, Mammone & Bramanti  ",2nd IEEE International Forum on Research and Technologies for Society and Industry Leveraging a better tomorrow,No,"Mediterranean University of Reggio Calabria
Chabahar Maritime University
Centro Neurolesi Bonino-Pulejo",6,,Other Pathology*,Classification of EEG signals,Clinical,Alzheimer's disease,,Extraction of features that can be used for Alzheimer's early diagnosis,Distinguish Alzheimer's disease from mild cognitive impairment and healty patients,Resting state,Latent feature learning + analysis of big amount of data,,N/M,No,None,Internal Recordings,Private,119,19,1024Hz,N/M*,,,"1) Notch at 50Hz
2) Band-pass 0.1-30Hz",No,Time-frequency representation,Frequency-domain,N/M,,N/M,"CNN
AE
MLP",CNN,N/A,N/M,Yes,228*,"Conv: 2
FC: 1",Sigmoid,N/M,,,3 (softmax),N/M,AE's bottleneck is used as input for the classification stage ,N/M,N/M,N/M,N/M,N/M,N/M,,4-fold,N/M,"Accuracy
Sensitivity
Specificity",N/M,,N/M,"AD-MCI-HC (acc, sens, spec): 82%, 83%, 75%
MCI-HC (acc, sens, spec): 85%, 84%, 81%
AD-HC (acc, sens, spec): 85%, 85%, 82%
MCI-AD (acc, sens, spec): 78%, 78%, 75%",No,None,,No,"As expected, the proposed model achieves better results when trying to disguinsh AD from healthy condition. Worst accuracy is obtained when classifying AD vs MCI ","""An ongoing effort is carried out within our research groups to generate a large database for both MCI and AD patients, also adding a similar number of HC.""",No,Yes,"There was no comparison with other methods, not even a linear model.",,Isabela,[TBD],
,EEG Based Eye State Classification using Deep Belief Network and Stacked AutoEncoder,2016,"Narejo, Pasero & Kulsoom",International Journal of Electrical and Computer Engineering,No,"Politecnico Di Torino, University of Pavia",11,,Cleaning EEG Signals,Classification of EEG signals,Monitoring,Cognitive,Eyes closed/open,Improve SOTA,Classify eye movements with a DBN and SAE,"Eye movement (""state"") classification: eyes open vs. eyes closed",It works well on other stuff,,Emotiv,No,None,EEG Eye State,Public (open),1,14,128,1,,,?,Yes,Discrete Wavelet Transform,Frequency-domain,N/M,,N/M,"1. DBN
2. SAE",DBN,N/A,N/M,Yes,70,"1) 4
2) 4","1) Sigmoid
2) logsig and linear","1) N/M
2) L2 and ""sparsity regularization""",,,2,N/M,Layer-wise training,N/M,1) learning rate: 0.01,1) 2,N/M,N/M,1) cross-entropy for fine-tuning,,N/M,N/M,"Accuracy
Sensitivity
Specificity",N/M,,N/M,"DBN (acc, spec, sens): 97.1, 0.99, 0.89
SAE (acc, spec, sens): 98.9, 0.94, 0.99","LDA + SAE
K*+Regularized Random Forest
K*
Neuro-fuzzy",Traditional pipeline,,N/M,Next steps are implementing Denoising/Contrastive AEs.,N/M,No,No,"Basic paper, some missing information.",,Hubert,[TBD],
,Removal of EOG artifacts from EEG using a cascade of sparse autoencoder and recursive least squares adaptive filter,2016,"Yang, Duan & Zhang",Neurocomputing,No,Shanghai University,8,,Cleaning EEG Signals,Improvement of processing tools,Signal cleaning,Artifact handling,,Novel approach from removing EOG artifacts,Remove EOG from EEG data,Motor imagery,Auto-encoders have shown to be able to extract powerful features from other modalities,,N/M,No,None,BCI competion IV,Public (open),9,3,250,N/M,,,1) Band-pass 0.5-100 Hz,No,None,Raw EEG,min-max,,Matlab 2013,Sparse AE,AE,N/A,N/A,Yes,1000,3,N/M,Sparsity penalty,,,1000,N/M,Train sparse AE on EOG data (offline) and then use EEG data as input ,N/M,N/M,N/M,N/M,N/M,N/M,,N/M,N/M,Accuracy,"Intel Core i3-4130
CPU3.4 GHz processor, 3 GB RAM",,N/M,SAE+adaptive filter outperformed ICA by 8% and ICA+adaptive filter by 5.8%,"ICA
ICA+adaptive filter",Traditional pipeline,,No,"The proposed method performs better, is more efficient and need less to channels to work properly.",NM,No,No,The deep neural network here is used to learn a representation of EOG that is used to clean EEG,,Isabela,[TBD],
,Recognition of Cognitive Task Load levels using single channel EEG and Stacked Denoising Autoencoder,2016,Yin & Zhang,Proceedings of the 35th chinese control conference,,University of Shanghai for Science and Technology,6,,General Cognitive,Classification of EEG signals,Monitoring,Cognitive,Mental workload,Improve SOTA,Use DL (sdAE) on single channel EEG for workload classification (low/high),Automation-Enhanced Cabin Air Management System (aCAMS),Deep architectures appear to be fit for representing stable higher-level abstractions,,N/M,No,Raw EEG,Internal Recordings,Private,8,11,500,"100 min / session
(2 sessions per subject)",,,"1) Band-pass 1.5 - 40 Hz
2) ICA for EOG Artifacts
3) 2s window
4) FFT for Freq Features",Yes,80 Power Features for each channel,Frequency-domain,N/M,,N/M,Stacked Denoising AE,AE,N/M,N/M,Yes,"80x1
(80 Freq Features)",5,Sigmoid,,,,"2
(High/Low CTL)",N/M,(Greedy Search for structure),N/M,N/M,N/M,Greedy Search,N/M,N/M,,N/M,N/M,"Sensitivity, Specificity, Precision, Accuracy, Kappa, 
Negative Predictive Value",N/M,,N/M,"Mean Accuracy: 0.7429 | Mean Kappa: 0.5418
Mean Sensitivity: 0.6104 | Mean Specificity: 0.8754
Mean Precision: 0.8236 | Mean NPV: 0.7070",N/M,None,,NM,NM,NM,No,No,"Average results, as it's to be expected with their own internal recordings on 8 subjects.",,Yannick,[TBD],
,Hand motion identification of grasp-and-lift task from electroencephalography recordings using recurrent neural networks,2016,An & Cho,IEEE International Conference on Big Data and Smart Computing,,Seoul National University,3,,BCI,Classification of EEG signals,BCI,Active,Grasp and lift,Improve SOTA,Use RNNs for BCI classification (Grasp-and-Lift task),Grasp-and-Lift BCI,"DL gave rise to an end-to-end framework, incorporating automatic feature extraction",,"N/M
(see dataset paper)",No,Raw EEG,WAY-EEG-GAL,Public (open),12,32,500,298 trials per subjects,,,1) Bandpass 1 - 30 Hz,No,"None
(Raw EEG)",Raw EEG,N/M,,N/M,"MUT
RNN from 
(Jozefowicz et al., 2015)",RNN,N/M,"For consistent and smooth predictions of phases during transitions, we used moving averages of predictions instead of using just the prediction for one point",Yes,32,"RNN: 2
FC: 1",N/M,Dropout,,,"6
(softmax)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,,N/M,"Train: 200
Valid: 44
Test: 54",Accuracy,N/M,,N/M,"LSTM  |  GRU  |  MUT1  |  MUT2  |  MUT3
87.98% | 88.6% | 86.54% | 88.21% | 88.82%","LSTM, GRU, MUT1, MUT2, MUT3",DL,,N/M,"Dropout improved performance of RNNs by an average of 4 percentage point. Smoothing the predictions with moving average helped making consistent
predictions, eliminating abrupt and incongruous prediction errors.",N/M,No,No,"Short paper, but most important infrmation is there...",,Yannick,[TBD],
,Decoding EEG and LFP signals using deep learning: heading TrueNorth,2016,"Nurse, Mashford, Yepes, Kiral-Kornek, Harrer & Freestone",ACM International Conference on Computing Frontiers,No,"University of Melbourne, IBM Research Australia",8,,BCI,Improvement of processing tools,Hardware optimization,Neuromorphic chips,,Improve SOTA,Performing decoding on a neuromorphic chip,"Self-paced hand squeeze task, left vs. right",Learns on its own a good description,,SynAmps2,No,None,Internal Recordings,Public (open),1 (picked out of 5),46,1000,1109,,,"1) Bandpass 0.1-100 Hz
2) Notch filter @50 Hz
3) Downsample to 250 Hz",Yes?,None,Raw EEG,N/M,,Caffe,CNN,CNN,N/A,N/M,Yes,46 x 46,3,N/M,N/M,,,2,N/M,Standard optimization,Stochastic gradient descent,learning rate: 0.01,N/M,N/M,N/M,N/M,,N/M,"Train: 86.9%
Validation: 13.1%",Accuracy,TrueNorth,,N/M,76%,"N/M
(previous paper on same dataset: 86%)",None,,Visualization of learned filters,"Accuracy not as good as previous paper, but there was extensive hyperparams search in previous paper.
Need more data and training.",Not enough data,No,Yes,"The DL side is a bit limited, as if they decided their first try was good enough?",,Hubert,[TBD],
,A novel deep learning approach for classifcation of EEG motor imagery signals,2016,Tabar & Halici,Journal of Neural Engineering,,"Middle East Technical University, Ankara, Turkey",11,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,"Exploring CNN, SAE & Combined CNN-SAE on BCI-MI Datasets",Motor Imagery (BCI Competition datasets),"""deep learning methods are known to provide better classification performance by increasing the size of training data""",,"N/M
(see dataset paper)",No,Motor Imagery,"BCI Competition II dataset III
BCI Competition IV dataset 2b",Public (open),"1) 1
2) 9",3,"1) 128
2) 250","1) 280
2) 400",,,"Short time Fourier transform (STFT)
Extracted: 6-13Hz and 17-30Hz",No,"Frequencies
6-13Hz & 17-30Hz",Frequency-domain,N/M,,"Matlab
Deep Learning Toolbox","1) CNN
2) SAE
3) CNN + SAE",CNN,"1D Filters
Max pooling","In our data, frequency, time and electrode 
location information are used together",Yes,"93x32
31 (freq) x 3 (channels) 
x 32 (time)","CNN: 1
SAE: 6
FC: 2",ReLU,N/M,,,2,N/M,"Each AE layer is trained separately in an unsupervised manner. After this pre-training step, supervised fine-tuning step is applied to the whole network",N/M,N/M,50,N/M,N/M,N/M,,"10x10 Cross-Validation
(10-Fold CV on 10 Subjects)","Train: 90%
Test: 10%","Kappa
Accuracy",4.00 GHz Core i7 PC with 16 GB of RAM,,1157s,"[DS #1] CNN: 72.4 | SAE: 70.3 | CNN-SAE: 75.1  (Accuracy)
[DS #2] CNN: 89.3 | SAE: 60.0 | CNN-SAE 90.0  (Accuracy)
[DS #2] (Lemm et al., 2004): 89.3 | (Ren et al., 2014): 88.2 (Accuracy)
[DS #2] CNN: 0.786 | SAE: 0.20 | CNN-SAE 0.80  (Kappa)
[DS #2] (Lemm et al., 2004): 0.783 | (Ren et al., 2014): 0.764 (Kappa)","(Lemm et al., 2004) - Winner of Competition
(Ren et al., 2014) - DL
",DL & Trad.,,Filters learned in CNN takes into account the activation in the neighboring regions but CNN does not provide any information on which filter contributes to classification performance more than the others.,"(1) We designed a new input form by using time, frequency and location information of EEG signals. (2) To our knowledge, our approach yields the best accuracy performance on BCI competition IV dataset 2b. The accuracy result of the CNN-SAE on dataset III is 90.0% that is higher than the winner algorithm. (3) The effect of filter size was investigated and Nh × 3 filter yielded the best perf. Also, the best value for epoch size was found as 300.",The result of our proposed system can be improved by using large datasets in such BCI system. We used only one convolution and one pooling layer. The performance may be increased if further convolution-pooling layers are used.,No,Yes,Seems reproducable. Nothing too fancy. Public data.,,Yannick,[TBD],
,Semi-automated Annotation of Signal Events in Clinical EEG Data,2016,"Yang, Golmohammadi, Obeid & Picone",IEEE Signal Processing in Medicine and Biology Symposium,,Temple University,5,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Event annotation,New Approach,To developed a self-training approach to iteratively annotate a large EEG corpus,Epilepsy data (ongoing EEG),To explore semi-supervised learning methods such as self-training [3] and active learning [4].,,N/M,No,Seizures,TUH,Public (open),"N/M
(see dataset info)","N/M
(see dataset info)","N/M
(see dataset info)","N/M
(see dataset info)",,,"See Harati et al., 2015 
(their previous paper)","(Harati et al., 2015)","See Harati et al., 2015 
(their previous paper)",NS,N/M,,N/M,"See Harati et al., 2015 
(their previous paper)",NS,"See Harati et al., 2015 
(their previous paper)","See Harati et al., 2015 
(their previous paper)",Yes,"See Harati et al., 2015 
(their previous paper)","See Harati et al., 2015 
(their previous paper)",N/M,"See Harati et al., 2015 
(their previous paper)",,,"See Harati et al., 2015 
(their previous paper)","See Harati et al., 2015 
(their previous paper)","The whole paper is kinda about ""training"" in the sense that they are training/retraining on the data until they get high level of confidence.","See Harati et al., 2015 
(their previous paper)",N/M,N/M,N/M,"Yes, the whole paper is kinda about data augmentation in the sense that they are training/retraining on the data until they get high level of confidence.",N/M,,N/M,N/M,Sensitivity,N/M,,N/M,"GPED: 52.8% ->  56.5%
PLED: 54.2%  60.4%
SPSW: 41.6%  49.6%
EYEM: 81.8% -> 82.1%
BCKG: 72.1% -> 71.2%
ARTF: 41.2% -> 39.1%","Before and After
(no benchmark)",None,,N/M,"The proposed method is based on a limited amount of manually annotated data and updates the training models by iteratively re-training and re-decoding. This pilot study shows after a few iterations we are able to not only label more EEG signals (about 30,000 new SPSW labels) but also improve recognition accuracy about 2%.",Number of label samples,No,No,"Very different paper. Using a previous DL model (Harati et al., 2015) this paper is all about self-training to automatically label the data.",,Yannick,[TBD],
,Learning representations from EEG with deep recurrent-convolutional neural networks,2016,"Bashivan, Rish, Yeason & Codella",International Conference on Learning Representations 2016,Yes,University of Memphis,15,,General Cognitive,Improvement of processing tools,Feature learning,,,Finding robust (inter-subject) representations from EEG data,Map EEG time-series to images and use CNNs as they work well for image classification ,Mental load (working memory) levels,CNNs presented good results for image classification,,N/M,No,None,"Internal Recordings
(from them, 2014)",Private,13,64,500Hz,3120*,,,"Mapping of EEG time series to images (spectral topography maps).
1) Calculate PSD on theta, alpha, beta
2) Project electrodes 3D position to a 2D mesh
3) Using each frequency band as a color channel, plot PSD as color intensity",,EEG spectral topography maps ,Frequency-domain,N/M,,Theano+Lasagne,"Single frame: CNN with different kernel sizes 
Multi-frame: A,B) CNN
 C,D) CNN+LSTM",CNN,"A) Max-pooling across time frames
B) Temporal convolution (1D conv in time)
C) LSTM 
D) Temporal convolution + LSTM",,Yes,"Single-frame: 32 x 32 x 3
Multi-frame: #frames x 32 x 32 x 3","Conv: 7
LSTM: 2
FC: 1",Sigmoid*,"50% dropout on FC layers
Early stopping",,,4,10k - 1.62 million,Standard,Adam,"lr=0.001
Beta1 = 0.9
Beta2 = 0.999",20,N/M,Yes (Adding noise to input. It didn't improve results),Categorical cross-entropy,,Leave-subject-out,"Train/Valid: 12 subjects (randomly selected samples from this set for validation)
Test: 1 subject",Test error,N/M,,N/M,"Single-frame: best model (D) improved 0.8% w.r.t. best baseline (DBN)
Multi-frames: best model (D) improved ~6% w.r.t. best baseline (DBN)","SVM, Random Forest, Logisitic regression, Deep belief network",DL & Trad.,,Yes,"""When trained on a pool of data containing multiple individuals, the network extracts features that are maximally informative considering the variability in the training set.""",,Yes,Yes,This paper is really nice. The scheme for mapping EEG time-series to image was applied in many posterior works.,,Isabela,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Investigating Critical Frequency Bands and Channels for EEG-Based Emotion Recognition with Deep Neural Networks,2015,Zheng & Lu,IEEE Transactions on Autonomous Mental Development,,Shanghai Jiao Tong University,14,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,New approach,"Using DBN to classify emotions (Positive / Neutral / Negative)
And exploring the relevant frequencies and channels",Watching Movies (emotions),Semi-Supervised DBN can learn from unlabeled data,,NeuroScan System,No,Differential Entropy from multichannel EEG,Internal Recordings,Public (open),15,62,1000,"3300 x 1s epochs per exp.
2 exp. / subject

(6600 epochs total)",Offline,,"1) Downsampled to 200Hz
2) VI: EMG (too much) contamined channels removed
3) Band-Pass filter: 0.3-50Hz
4) Epoching (lenght of a movie)",Yes,"Differential Entropy (DE)
DASM, RASM",Other,N/M,,MATLAB,BDN,DBN,N/M,To leverage unlabeled data with unsupervised learning,No,"not clear
(the features)",2,Sigmoid,N/M,3,"Positive
Neutral
Negative",3,N/M,"1) unsupervised pretraining of each layer; (greedy layer-wise)
2) unsupervised fine-tuning of all layers with backpropagation; 
3) supervised fine-tuning of all layers with backpropagation",N/M,"Momentum: 0.1
LR (Unsup): 0.5
LR (Sup): 0.6",201,search optimal number of neurons at the first and second layer in the ranges [200:500] and [150:500] with step of 50,N/M,N/M,Intra,N/M,"Train: 9 sessions
Test: 6 sessions",Accuracy,N/M,,N/M,"Mean Accuracy: 86.08%

Lots of results reported (for each feature categories)
(see paper for full details)","Mean Accuracy

KNN: 72.60%
LR: 82.70%
SVM: 83.99%",Traditional pipeline,No,"Yes
Frequencies and Electrodes 
contributing.","(1) Given that DBNs can also learn models in an unsupervised way, the large amounts of unlabeled EEG data may also be conductive to the semi-supervised DBN training paradigm and allow it to learn more sophisticated models than other traditional supervised learners. (2) There is still a lack of publicly available emotional EEG datasets. (3) In our studies, we propose a novel critical channels and frequency bands selection method through the weight distributions learned by deep belief networks.",Emotion Classes is limited to 3 in the study,"No
but they shared 
their data!!!",Yes,"They acknowledge the lack of public datasets for EEG emotions, and they shared their data <3",,Yannick,[TBD],
,Deep feature learning for EEG recordings,2015,"Stober, Sternin, Owen & Grahn",Arxiv,Yes,University of Western Ontario,24,,General Cognitive,Improvement of processing tools,Feature learning,,,Improve SOTA,Automatic feature learning using autoencoders,Music listening or imagery,Use of deep learning achieved good results in other domains ,,BioSemi Active-Two,No,None,OpenMIIR dataset,Public (open),10,66,512,60 trials/sub,Offline,,"1) Removed and interpolated bad EEG channels
2) Bandpass: 0.5-30 Hz",Yes,Raw EEG,Raw EEG,"[-1,1] 
0 mean",,Theano+Pylearn,Autoencoders,AE,N/M,N/M,No,N/M,N/M,Sigmoid,"Dropout, L1",12,12 music styles (see Table 2),12,N/M,Standard,SGD,N/M,128,Bayesian optimization,N/M,Hinge loss,Inter-subject,9-fold,"Train: 8 subs
Valid: 1 sub
Test: 3rd block of each sub",Accuracy,N/M,,N/M,"SVM: 14.8%, CNN: 18.5%, 26.9%
SVM: 14.8%, CNN: 18.5%, 19.4% 
SVM: 17.6%, CNN: 17.6%, 18.5% 
SVM: 19.4%, CNN: 20.4%, 20.4%
SVM: 16.7%, CNN: 20.4%, 19.4%
SVM: 23.1%, CNN: 23.1%, 22.2%
SVM 20.4%, CNN: 22.2%, 22.2%
SVM: 20.4%, CNN: 25.0%, 27.8%
SVM: 24.1%, CNN: 20.4%, 18.5%
SVM: 22.2%, CNN: 22.2%, 23.1%
SVM: 23.1%, CNN: 27.8%, 26.9%",SVM,Traditional pipeline,"Yes ( Significance values were determined by using the cumulative binomial distribution to estimate the likelihood of observing
a given classification rate by chance)",Yes (visualization of learned convolutional filters),"CNNs outperformed or were equally good as SVM for 10/11 cases. 
""Learned features are
also still simple enough to allow interpretation by domain experts such as cognitive neuroscientists."" ",N/M,Yes,No,"The paper is very relevant as they focus on learning good features for different trials. However, I find it a little bit disorganized. One good point about the paper is that they analyzed whether the cost of using high-sampling rate EEG is worth. ",,Isabela,[TBD],
,Convolutional neural network for multi-category rapid serial visual presentation BCI,2015,Manor & Geva,Frontiers in Computational Neuroscience,,Ben-Gurion University,12,,BCI,Classification of EEG signals,BCI,Reactive,RSVP,New approach,New spatio-temporal regularization for CNN on RSVP (or P300) BCI,RSVP (5 classes of images),Deep neural networks have shown state of the art performance in computer vision and speech recognition and thus have great promise for other learning tasks.,,BioSemi Active-Two,No,ERPs (P300),"1) Internal Recording
2) BCI Competition III Dataset IIb",Private,"12 
(out of 15)",64,"256
+ online low-pass 51Hz ","4 Blocks (with diff target)
of 6525 images
(20% were targets)",Offline,,"1) High-Pass filter: 0.1Hz
2) 1s window around image stimuli (100ms before)
3) Blinks removed based on VEOG",Yes,Raw EEG,Raw EEG,z-score,,Caffe,"CNN
+ Spatio-Temporal Regularization",CNN,"Spatio-Temporal Regularization
The penalty term regularizes the spatial filters such that the filters activations will be smooth. Penalizes the higher frequencies and fast changes.","The first convolutional layer performs a spatial convolution by using filters of size 64×1, learning features which represent a spatial distribution across the scalp. The second conv layer captures the temporal information.",Yes,"64x64
(electrodes by 
time samples)","CNN: 3
FC: 2",ReLU,"Dropout
Spatio-Temporal 
(their own regul)",2,"Target
Non Target","2
(softmax)",N/M,N/M,SGD,"LR: 0.001
Momentum: 0.9",No,Empirically,"Bootstrapped the target class
(for umbalanced class problem, 
1 target for 9 non-tragets)",Multinomial Logistic Regression,Intra,Random CV,"Train: 80%
Test: 20%","Accuracy (balanced)
AUC
Correct, Hits, False Alarms",NVidia GTX 650,,N/M,"(Mean) Balanced Accuracy: 70±4.86
(Mean) AUC: 0.77±0.05
(Mean) Correct: 75±4.4 || Hits: 64.4±5.47 || False Alarms: 23.7±4.36",SWFP algorithm,Traditional pipeline,No,Yes,"We showed that DNN models are an effective tool for single trial P300 classification. Even for a difficult RSVP task with five categories, we achieve impressive classification performance that surpasses our earlier work. The NN model is regularized with a novel spatio-temporal regularizer, which encourages the network to learn smooth features and thus reduces overfitting to noisy samples.",N/M,No,Yes,"They conclude with: ""Therefore, we should look at building large data sets for EEG which will allow to explore larger and deeper models""",,Yannick,[TBD],
,Parallel convolutional-linear neural network for motor imagery classifcation,2015,"Sakhavi, Guan & Yan",European Signal Processing Conference,,"BCI Lab, Singapore
National University of Singapore",5,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,New approach,Use DL for 4-class motor imagery using dynamic energy,Motor imagery,"Because traditional classifications, such as SVM, cannot handle this dynamical property, we proposed an architecture that inputs a dynamic energy representation of EEG data and utilizes convolutional neural networks for classification",,"N/M
(see dataset paper)",No,Motor imagery,BCI Competition IV Dataset IIa,Public (open),9,22,250,"144 samples per class
(train:72 and test:72)",Offline,,"1) Filter-Bank CSP (FBCSP)
9 filters from 4 to 40Hz",No,FBCSP,Frequency-domain,N/M,,"MATLAB
Torch","Parallel 1D-CNNs
+ MLP",CNN,Parallel convolutional layers with a one dimensional kernel in time. ,"Average pooling. In CNN architectures for images, max pooling is used because of its spatial invariance-inducing property. But training the EEG data with max pooling re- sulted in poor results. Therefore, average pooling is used.",Yes,"8
? (to be confirmed)",4x 2 CNN + MLP,ReLU,Dropout,4,"Left Hand
Right Hand
Feet
Tongue",4,N/M,N/M,SGD,N/M,N/M,N/M,N/M,"Negative 
Log-Likelihood",Intra,N/M,"Train: 50%
Test: 50%",Accuracy,N/M,,N/M,70%,SVM,Traditional pipeline,"Yes
(Wilcoxon signed-rank test)
CNN vs SVM vs MLP",Yes,"(1) Furthermore, deep architectures, due to there high learning capacity, have gained their success by being trained on large amounts of data. Unfortunately, limitation on gathering data for individual subjects is a barrier in EEG research. (2) Classification aside, there is one other element in BCI research that is valuable: interpretability of learned algorithms.","Our algorithm is not perfect in several aspects and can be improved: heavy pre-processing of data, choice of architecture and network parameters.",No,Yes,-,,Yannick,[TBD],
,Deep learning of EEG signals for emotion recognition,2015,"Gao, Lee & Mehmood",IEEE International Conference on Multimedia & Expo Workshops (ICMEW),,"Chonbuk National University, Korea",5,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,Improve SOTA,Use DL (RBMs) for emotion classification,"Not clear...
(4 classes emotions)",To learn features from the data.,,"EPOC?
(not clear)",No,"Raw EEG
(Emotions)",Internal Recordings,Private,21,14,N/M,"180 epochs / subject
45 for each of the 4 classes",Offline,,"1) Manual artifact removal with EEGLAB
2) Filtering  (they don't mention what/how)
3) Epochs Selection
4) Signal Averaging",Yes,Raw EEG,Raw EEG,N/M,,EEGLAB,RBM,RBM,N/M,Pre-training on all subjects with unlabeled data and fine-tuning on individual subject for intra subject classification with labeled data,Yes,192x14,RBM: 3,N/M,N/M,4,"Happy
Calm
Sad
Scared",4,N/M,"(1) Pre-Training across subject 
(unlabeled data)
(2) Fine-Tuning per subject 
(labeled data - backprop)",N/M,N/M,N/M,N/M,N/M,N/M,Intra,"Average of 10 times:  
Train: 160 (random)
Test : 20 (random)
per subject","Train: 160 epochs/subject
Test: 20 epochs/subject",Accuracy,N/M,,N/M,"Subject United: 28.6 %
Subject Tied: 68.4 % 
Channel Selection: 57.2 %","KNN: 51.3 %
SVM: 60.8 %
ANN: 60 %",Traditional pipeline,N/M,No,It differs from the conventional methods as we apply deep learning on the raw signal without hand-crafted feature extraction.,N/M,No,No,Not much data for deep learning.,,Yannick,[TBD],
,Feature learning from incomplete EEG with denoising autoencoder,2015,"Li, Struzik, Zhang & Cichocki",Neurocomputing,,"Riken, Japan
Shainghai Jiao Tong University, China
Polish Academy of Sciences, Poland",9,,Generating EEG Signals,Improvement of processing tools,Feature learning,,,New approach,Use DAE or SVM on Lomb–Scargle periodograms for Motor Imagery with missing data (e.g. after artefact removal),Motor imagery,Deep learning is a promising and burgeoning method.,,N/M,No,Motor imagery,Internal Recordings,Private,3,14,250,"15 trials (of 4s) / session
4 sessions / subject",Offline,,N/M,"No
(the paper is about 'dealing' with this)","Lomb–Scargle periodograms
(Freq Bands Power)",Frequency-domain,N/M,,N/M,DAE,AE,N/M,N/M,Yes,56x1,3,Sigmoid,N/M,2,"Right Hand
Left Hand",2,N/M,N/M,N/M,"LR (Pre-Training): 0.9
LR(Fine-Tuning): 0.9",25,"Trial and Error*
(assumed, not mentioned)","N/M
(they have 87.5% overlap
 in their windows)",MSE,Intra,N/M,N/M,Accuracy,N/M,,N/M,"See papers, it shows results per subject, per session, 
with 10% to 80% of missing data.
Roughly ~60-8X% accuracy","DAE vs SVM
(on Lomb–Scargle periodogram, no real benchmark)",DL & Trad.,No,No,"Therefore, the classification performance using the proposed method for incomplete segments is acceptable for a BCI application system. This means that the segment with noise contamination can still be utilized to output commands after only removing the noisy portion, instead of discarding the whole segment, as is conventionally done in BCI systems.",N/M,No,No,-,,Yannick,[TBD],
,Superchords: the atoms of thought,2015,Normand & Ferreira,Arxiv,Yes, University of Lisbon,5,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,New approach: Brain Orchestra Approach (BOA),"Use DL (H2O) to classify Motor Imagery, using existing dataset ",Motor imagery,"Explore H2O and their BOA. 
The concept of superchords",,"N/M
(see dataset paper)",No,Motor imagery,eegmmidb,Public (open),109,64,160,N/M,Offline,,1) Splitting each class in 10 datasets (10 to 160 first superchords),"N/M
(see H2O)",Superchords,Other,N/M,,R / R Studio,H2O,NS,N/M,N/M,No,not clear,"N/M
(see H2O)","N/M
(see H2O)","N/M
(see H2O)",5,"Left Hand
Right Hand
Both Hands
Feet
Rest","5 ?
(N/M)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,Intra,N/M,"Train: 50%
Validation: 50%","Accuracy
Error = wrong preds / nb preds",N/M,,N/M,> 80% Accuracy ( < 20% Errors),No,None,No,No,"there are positive indications that superchords are singular to each motor task present on the dataset. The authors do believe it would be possible to expand the concept of singular superchord to other mental activities, like reactions to faces or words.","1) Anticipation (Chavarriaga, 2012)
2) Quality of recordings
3) Sample representativity
4) Paradigm type",No,No,"They conclude by inviting people who'd like to apply/explore that approach to collaborate
Very very short paper, not much info",,Yannick,[TBD],
,On the use of convolutional neural networks and augmented CSP features for multi-class motor imagery of EEG signals classification,2015,"Yang, Sakhavi, Ang & Guan",IEEE Internation Conference in Medicine and Biology,No,"Agency for Science, Technology and Research (A*STAR)",4,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve state-of-the-art,Use CSP + CNN for 5-class motor imagery classification ,Motor imagery,Replace hand-crafted feature selection methods with CNNs to learn structure from CSP features,,"N/M
(see dataset paper)",No,Motor imagery,BCI competition IV dataset IIa,Public (open),9,22,250,N/M,,,None,,Augmented CSP,Frequency-domain,N/M,,N/M,CNN,CNN,"Pooling layers also sub-sampled features maps (the intention was to select features).
3 methods to select features maps were proposed: random, all, and frequency complementary map selection (see paper) ",,Yes,60 x 48 x 1,"Conv: 2
FC: 1",N/M,N/M,,,N/M,N/M,Standard,SGD,lr=0.5,38,N/M,N/M,MSE,,K-fold*,5-fold*,Accuracy,N/M,,N/M,"Random selection of feature maps accuracy was smaller than baseline.
All feature maps and frequency complementary selection improved accuracy in ~1.5% and ~2.5%.
",Filter-bank CSP,Traditional pipeline,,No,There was no significant improvement between frequency complementary selection and using all feature maps.,,No,No,"Main contribution of the paper relies on the proposed feature map selection scheme. However, statistical testing showed that this method has not improved results w.r.t. using all feature maps.",,Isabela,[TBD],
,Prediction of driver's drowsy and alert states from EEG signals with deep learning,2015,"Hajinoroozi, Mao & Huang",International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP),No,University of Texas at San Antonio,4,,Other,Classification of EEG signals,Monitoring,Cognitive,Drowsiness,Prediction of driver’s cognitive states,Predict drowsiness or alert states,Driving in a virtual reality environment,Explore DL for assessing driver's cognitive state,,N/M,No,None,"1) Metev & Veiko (1998)
2) Lin et al. (2005)
3) Correa et al. (2014)",Private,37,30,250,35074,,,1) ICA,,Raw EEG,Raw EEG,N/M,,N/M,CNN +RBM,RBM,"1) CNN with all channels concatenated in a long vector
2) CNN for 2D inputs with one channel
3) CNN with 1D inputs and 30 channels
4) CNN with 1D inputs and 30 channels and RBM for feature extraction ",,Yes,"7500 x 1 x 1 (W x H x N channels)
250 x 30 x 1 
250 x 1 x 30","Conv: 2
FC: 1",Sigmoid,N/M,,,1,N/M,Standard,GD,N/M,N/M,N/M,N/M,Binary cross-entropy,,Train-valid-test split,"Train: 50 sections
Validation: 10
Test: 10",AUC,N/M,,N/M,"All DNNs outperformed baseline methods with and without ICA.
AUC improvement w.r.t. baselines of ~27%",LDA and SVM on raw EEG,Traditional pipeline,,No,CNN-3 presented better results in comparison to other DNNs. ICA decreased the performance of all methods.,,No,No,Comparison with baselines was not super fair IMO (LDA and SVM with raw EEG),,Isabela,[TBD],
,Deep Extreme Learning Machine and Its Application in EEG Classification,2015,"Ding, Zhang, Xu, Guo & Zhang",Mathematical Problems in Engineering,No,"China University of Mining and Technology
Chinese Academy of Sciences",11,,BCI,Classification of EEG signals,BCI,Active,Slow cortical potentials,New Approach: DELM for EEG-BCI,"Explore ELM, KELM and DELM for EEG-based BCIs using existing datasets.","BCI Competition II Datasets IA et IB
Slow Coritcal Potentials",Not only does MLELM approximate the complicated function but it also does not need to iterate during the training process.,,N/M,No,(see dataset),"1) BCI competition II dataset IA
2) BCI competition II dataset IB",Public (open),"N/M
(see dataset paper)","N/M
(see dataset paper)",256,"1) 561
2) 380",,,"N/M
(they say they used ""preprocessed EEG"")",No,Raw EEG,Raw EEG,N/M,,Matlab,"DELM
(Deep Extreme Learning Machine)",NS,"not clear
(to be reviewed)",N/M,Yes,"not clear
(to be reviewed)","not clear
(to be reviewed)","Sigmoid
+ Kernel Functions: Gaussian",N/M,,,"not clear
(to be reviewed)",N/M,"not clear
(to be reviewed)",N/M,N/M,N/M,N/M,N/M,N/M,,N/M,"1) Train: 268 | Test: 293
2) Train: 200 | Test: 180","Accuracy
Training Time
Testing Time",N/M,,"1) 6.7s
2) 8.9s","1) [Average] Training:  0.7515  |  Testing:  0.8650
1) [Best] Training:  0.7873  |  Testing:  0.9181
2) [Average] Training:  0.7151  |  Testing:  0.5211
2) [Best] Training:  0.8450  |  Testing:  0.6056",ELM vs KELM vs ML-ELM vs DELM,Traditional pipeline,,No,"In this paper, DELM is used to classify preprocessed EEG data and the feature attributes of preprocessed EEG are not extracted, which has certain effects on the experimental results. Future research is to combine the EEG feature extraction methods and DELM, which will be applied to the EEG classification.",N/M,No,No,"Hard to find information...
Still not sur I fully understand... (YR)
Someone else should read it and fill the information.",,Yannick,[TBD],
,Emotional Affect Estimation Using Video and EEG Data in Deep Neural Networks,2015,Frydenlund & Rudzicz,Advances in Artificial Intelligence,,University of Toronto,8,,General Affective,Classification of EEG signals,Monitoring,Affective,Emotion,"New Approach: Reusing downsampling ""wasted"" data for data augmentation","Reusing downsampling ""wasted"" data for data augmentation in a valence/arousal/dominance regression scale on DEAP dataset",Emotion Scale Regression (Arousal/Valence/Dominance) on DEAP ,Not much explanation. Probably for the multimodal aspect.,,"N/M
(see dataset paper)",No,"Emotions
(PSD)",DEAP,Public (open),22,32,"512 (original)
DS to 1/5 (~102)","N/M
(see dataset paper)",Offline,,"1) Downsampled to 1/5
2) ICA -> Ocular Artifacts removal",Yes,"Frequency Bands 
(Theta, Slow Alpha, Alpha, Beta, Gamma)",Frequency-domain,z-score,,"EEGLAB
Deep Learning Toolbox [11]
Spearmint [15]
modified SPN code from [12]",NN,FC,N/M,N/M,No,"N/M
(multimodal)",2,"Sigmoid (layers)
Softmax (output)",N/M,N/A,"N/A
Regression ""Scale""","Scale [1-9] or [0-1]
(regression)",N/M,N/M,N/M,N/M,N/M,N/M,"Yes, when downsampling, they use the ""throw away"" data. Downsampling 1/5 gives you 5x number of epochs.
* Main Contribution of the paper *",N/M,Inter*,Leave-two-out,N/M,RMSE,N/M,,N/M,"Arousal:   [1-9] 1.5778 ± 0.5301  ||   [0-1]  0.1972 ± 0.0663
Valence:  [1-9]  1.5396 ± 0.8797  ||   [0-1]  0.1925 ± 0.1100
Dominance:  [1-9]  0.1925 ± 0.1100  ||   [0-1]   0.2523 ± 0.0561 
Favourability:  [1-9]  2.2366 ± 0.5975  ||   [0-1]  0.2796 ± 0.0747   
Familiarity:  [1-9]  2.0432 ± 0.4010  ||   [0-1]  0.5108 ± 0.1002","Baseline
Linear Regression",Traditional pipeline,"Yes, 1-sided t-test
(NN vs Baseline)",No,"This work acts as a feasibility study for our ‘downsampling extension’ scheme, and further work needs to be done to examine its affect. Feature selection is another possible line of inquiry, since we have selected features based on linear relations, where non-linear relations may be more appropriate for DNNs.",N/M,No,No,"Interesting approach on ""reusing"" downsampling wasted data... Other studies with more ""comparisons"" are required...",,Yannick,[TBD],
,Detecting Epileptic Seizures from EEG Data using Neural Networks,2015,"Pramod, Page, Mohsenin & Oates",Arxiv,Yes,"University of Maryland, Baltimore County",,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,Improve SOTA: Using Dropout in NN for Seizure Detection,Using Dropout in NN for Seizure Detection,"Ongoing EEG recording, with and without seizures.",Use Dropout on NN for Epilepsy EEG,,"N/M
(see dataset paper)",No,Seizures,CHB-MIT,Public (open),22,23,256,"N/M
(see dataset paper)",,,1) 1s windows,,"Area, Normalized Decay, Line Length, Mean Energy,Average Peak Amplitude, Average Valley Amplitude, Normalized Peak Number, Peak Variation, and Root Mean Square",Other,z-score,,N/M,"NN*
(FC I suppose)",FC,N/M,N/M,No,"126 features
(9 features x 14 channels)

(1s windows)","[2, 5]",ReLU,"L1
Dropout
([0.2, 0.5])",,,"1
(Softmax)",N/M,Gradient Descent with Early Stopping,N/M,"LR: [0.01, 0.1]",N/M,"Manually, by trying different things","N/M
(they actually reduced the data by not selecting everything to balance classes and avoid skew)",N/M,,Leave-one-out,N/M,"Sensitivity
Specificity
Precision
F-Score",N/M,,N/M,"Mean Sensitivity: 0.9806  (STD: 0.078)
Mean Specificity: 0.9929  (STD: 0.023)
Mean Precision: 0.7329  (STD: 0.33)
 Mean F-Score: 0.7816  (STD: 0.29)",This is an improvement on the most recently reported results on this database by Pinho et al. (2014),Traditional pipeline,,N/M,"Much remains to be improved in terms of precision of the classifier. Also, using the proposed classi- fier to detect seizure onsets is still a work in progress, where such a technique involves aggregating classifier outputs on multiple contiguous segments to achieve higher sensitivity and specificity.",N/M,No,No,"Among the first DL for Epilepsy. It shows.
The way people report now is way better.",,Yannick,[TBD],
,Adaptive Recurrent Neural Network For Reduction Of Noise And Estimation Of Source From Recorded EEG Signals,2015," Pardede, Turnip, Manalu & Turnip",ARPN Journal of Engineering and Applied Sciences,No," Institut Teknologi Nasional, Indonesia",5,,Cleaning EEG Signals,Improvement of processing tools,Signal cleaning,Artifact handling,,New approach for removing noise and locating brain activity sources,Use an adaptive RNN for cleaning EEG,"""Normal conditions"", eyes closed, and blinking",N/M,,Emotiv,No,None,Internal Recordings,Private,8,6,128Hz,N/M,,,1) Band-pass 0.5-49Hz,No,Raw EEG,Raw EEG,N/A,,N/M,RNN,RNN,N/M,N/M,No,N/M,N/M,N/M,N/M,,,N/M,N/M,Standard*,SGD,N/M,N/M,N/M,N/M,Minimum entropy,,N/M,N/M,Performance factor defined in the paper,N/M,,N/M,Curves are shown in the paper.,N/M,None,,N/M,The proposed method outperforms baselines for 6 out of 8 subjects.,N/M,No,No,Terrible paper. For me it is not clear if and how they used a neural network. ,,Isabela,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,EEG-based emotion classification using deep belief networks,2014,"Zheng, Zhu, Peng & Lu",IEEE International Conference on Multimedia and Expo,,"Shanghai Jiao Tong University, China",6,,General Affective,Classification of EEG signals,Monitoring,Affective,TBD,Improve SOTA,Use DBN and DBN+HMM on DE features for emotion classification (2 classes: Positive/Negative),Short Movie Clips eliciting positive/negative emotions,The efficiency of DBN model can combine feature ex- traction and feature selection when doing unsupervised and supervised learning.,,"ESI NeuroScan 
System",No,"Emotions
(PSD)",Internal Recordings,Private,6,62,1000,"2 sessions x 12 clips x 4 min
per subject",Offline,,"1) Downsampled to 200Hz
2) Pass-band filter: 0.3 - 50Hz
3) Short-Time FT with 1s Hanning Window -> 5 Freq Bands
4) Differential Entropy for each band",No,"Differential Entropy (DE) of 5 F. Bands (D,T,A,B,G)
62 channels * 5 bands = 310 features
Smoothed with linear dynamic system (LDS)",,z-score,,N/M,DBN-HMM,,DBN + HMM after,"Combining DBN and HMM can help bridge the gap between static and sequence pattern recognition, which has been successfully used in sleep stage classification using EEG [4]",No,310 x 1,2,N/M,N/M,2,"Positive Emotion
Negative Emotion",2,N/M,An efficient greedy layer-wise algorithm is used to pre-train each layer of networks,N/M,LR: 0.05,200,N/M,N/M,"Energy Function
(see paper)",Intra,N/M,N/M,Accuracy,N/M,,N/M,"                      Delta | Theta | Alpha |  Beta  | Gamma | Total
   DBN-HMM:   61.45 | 58.39 | 71.57 | 85.45  |  87.33  |  87.62 
   DBN:             61.98 | 58.36 | 69.22 | 85.96  |  88.40  |  86.91 ","                Delta | Theta | Alpha |  Beta  | Gamma | Total
   GELM:   68.37 | 61.63 | 70.88 | 84.60 |  87.99  |  85.67 
     SVM:    56.43 | 59.57 | 66.59 | 82.97 |  85.86  |  84.08  ",,N/M,"No*
(they talk about what frequencies contribute most...)","In this paper, the experiment results show that high frequency-band (beta and gamma) features are more related to emotion recognition, which is consistent with previous work, proposing higher frequency brain activity reflecting emotional and cognitive processes [8] [9].",N/M,No,No,"They used the different frequency bands, but they would need to combine them (i.e. ratios), not just ""as is"", individually...",,Yannick,[TBD],
,Deep learning of multifractal attributes from motor imagery induced EEG,2014,Li & Cichocki,International Conference on Neural Information Processing,,"Riken, Japan",8,,BCI,Classification of EEG signals,BCI,Active,Motor imagery,Improve SOTA,Use DAE + DNN on multifractal features for Motor Imagery,Motor Imagery,N/M,,N/M,No,Motor Imagery,Internal Recordings,Private,3,14,N/M,"4 sessions x 15 trials x 4s
per subject",Offline,,"1) Notch Filter: 50Hz
2) Multifractral Feature Extraction",No,"Multifractal Features 
(based on wavelet leaders)
Discrete Wavelet Transform",,N/M,,N/M,DAE + DNN,,Using Stacked DAE to learn initial weights for (FC) DNN,N/M,Yes,12,"SDAE: 3
DNN (FC): 3",Sigmoid,N/M,2,"Left Hand
Right Hand",2,N/M,Stacked DAE layers are trained sequentially with a stop criterion of 30 epochs. Then DNN is fine-tuned in a supervised way with a stop of 50 epochs,N/M,"SDAE LR: 0.5
DNN: LR: 0.2",SDAE: 75,N/M,N/M,MSE,Intra,N/M,N/M,Accuracy,N/M,,N/M,"S1: 90.93 | 85.87 | 93.07
S2: 57.60 51.47 70.93
S3: 63.20 68.27 83.47",N/M,,N/M,N/M,"We explored multifractal attributes for motor imagery EEG, and found that characte- ristics of multifractal spectrum D(h) and the statistics cp based on cumulants are dif- ferent between left and right motor imageries. Then, a deep network was built to learn the extracted multifractal attributes.",N/M,No,No,---,,Yannick,[TBD],
,EEG-based emotion recognition using deep learning network with principal component based covariate shift adaptation,2014,"Jirayucharoensak, Pan-Ngum & Israsena",The Scientific World Journal,No,Chulalongkorn University,10,,General Affective,Classification of EEG signals,Monitoring,Affective,TBD,Improve state-of-the-art,,Emotion Classification on DEAP ,Discover unknown feature correlation between input,,N/M,No,PSD,DEAP,Public (account),32,32,512Hz,N/M*,,,1) Downsampling to 128Hz,No,PSD,,"1) Subtract baseline
2) Rescale to [0.1,0.9]",,N/M,Stacked autoencoder + MLP,,Stacked autoencoder layers are used for feature extraction. Two softmax layers are used: one for arousal classification and other for valence,N/M,Yes,230 x 1,3,N/M*,L2,,,3,N/M,"Stacked autoencoder layers are trained sequentially for 400 iterations, then the softmax layer is trained for 100 iterations. At last, the whole model is fine-tuned for 200 iterations. ",L-BFGS,N/M,N/M,N/M*,No,MSE,,Leave-one-subject-out,N/M,Accuracy,CPU with RAM 8 GB,,20-25 minutes,"In terms of average accuracy, the model with PCA + covariate shift adaption performed better then the other proposed models and the two baselines for both arousal and valence.",SVM and Naive Bayes,,,No,"The covariate shift adaptation is able to handle nonstationary on EEG signals, but high variability across subjects is still an issue.","""One of the major limitations for performing EEG-based emotion recognition algorithm is dealing with the problem of intersubject variations in their EEG signals""",No,No,I like the covariate-shift adaptation idea. It would be nice to have something like this in a layer/weight/batch-normalization style. ,,Isabela,[TBD],
,A deep learning method for classification of EEG data based on motor imagery,2014,"An, Kuang, Guo, Zhao & He",International Conference on Intelligent Computing in Bioinformatics,,"Tongji University, Shanghai, China",8,,BCI,Classification of EEG signals,BCI,Active,TBD,Improve SOTA,Use DBN + Ada-boost for Motor Imagery,Motor Imagery,DBN can learn the advanced abstract representation from unlabeled data.,,N/M,No,Motor Imagery,Internal Recordings,Private,4,1,250,"30 LH + 30 RH
per subject",Offline,,"1) EOG artifact removal (Neuroscan)
2) Band-pass filter: 8 - 30Hz  (elliptic filter)",Yes,"PSD
(FFT)",,N/M,,Neuroscan,"DBN
+ Ada-boost",,"Single Channel
Tested [4-16] layers. 8-9 layers give the best performances",N/M,"Yes
(very bad one)",N/M,8,Sigmoid,N/M,2,"Left Hand
Right Hand","N/M
(2 ?)",N/M,Contrastive Divergence (CD),N/M,"LR: 0.07
Weight Decay: 0.002
Momentum: 0.5",N/M,N/M,N/M,N/M,Intra,"Yes
(no detail)",Train: 20 / 60,Accuracy,N/M,,N/M,"With 8 Layers for the 4 sujbects:
85% 65% 77% 95%",SVM,,N/M,No,"Our study suggests that DBN has great potential to be a powerful tool for the BCI research. For the next stage, we’ll try to employ this algorithm into classification of Multi-class based on EEG data, and merge more channels in order to take full use of the EEG data information to achieve better recognition results.",N/M,No,No,---,,Yannick,[TBD],
,Single-trial classification of ERPs in rapid serial visual presentation tasks using supervised spatial filtering,2014,"Cecotti, Eckstein & Giesbecht",IEEE Transactions on Neural Networks and Learning Systems,,"University of California, Santa Barbara, USA
University of Ulster, UK",13,,BCI,Classification of EEG signals,BCI,Reactive,TBD,Improve SOTA,Use CNN with training based on the maximization of the AUC for single-trial detection of ERP in three RSVP tasks.,RSVP,CNN's first layer act as a spatial filter,,Biosemi,No,RSVP,Internal Recordings,Private,8 + 10,32,512,12000 + 10000 + 4000,Offline,,"1) Band-pass filter: 1 - 10.66Hz
2) Downsampled to 32Hz",No,Raw EEG,,N/M,,C++,CNN,,"Different Combinasions of 
Spatial Filter + Classifier
SP: xDAWN, CSP, CNN
Classifier: BLDA, MLP, SVM","Spatially, could (should) be stationary",No,"4 x 26 = 104
(channels x time points)",2,"Sigmoid
Hyperbolic Tan (L1)
Logistic (L2, Lout)",N/M,2,"Target
Non-Target",2,"4414 to 33402
(depending on the model)",N/M,N/M,N/M,N/M,N/M,N/M,"Max AUC
Min MSE",Intra,5-Fold CV,"N/M
(TBC)",AUC,N/M,,N/M,"                            CNN | xDAWN | CSP | T
[AUC] Exp #1 (MLP): 0.932 | 0.910 | 0.822 | 0.917
[AUC] Exp #2 (MLP): 0.845 | 0.865 | 0.720 | 0.809
[AUC] Exp #2 (MLP): 0.816 | 0.845 | 0.728 | 0.810","SVM
Baysian LDA",,"Yes
(Friedman’s test, Wilcoxon sign rank test, t-test, Anova)",No,"After Wilcoxon sign rank tests, CNN was the best preprocessing step, followed successively by xDAWN, the absence of spatial filtering, and CSP ( p < 10e − 4). For classifiers, MLP was better than both SVM (p < 10e−5) and BLDA (p < 10e − 5), and there was no difference between SVM and BLDA.",N/M,No,No,In depth on spatial filtering. Good paper for that. Stays high-level for deep learning stuff however. They had 3 experiments and good comparison with SOTA spatial filtering and classifier.,,Yannick,[TBD],
,Using convolutional neural networks to recognize rhythm stimuli from EEG recordings,2014,"Stober, Cameron & Grahn",Advances in Neural Information Processing Systems,No,Western University,9,,Other,Classification of EEG signals,TBD,TBD,TBD,Classify 24 different rhythmic stimuli,Use DNN to a 24-classes classification task,Rhythmic stimili,,,Grass EEG,No,None,Internal Recordings,Private,13,14,400Hz,N/M*,,,1) Removed bad channels for each subject,No,Raw EEG and spectrum,,N/A,,"Theano
Pylearn2",CNN,,Used a DLSVM output layer,N/M,Yes,N/M*,Conv: 1 and 2,ReLU,Dropout,,,24,N/M,,SGD + Momentum,"lr: [0.001, 0.01]
lr decay: [1, 1.1]",100,Bayesian optimization,N/M,Hinge loss,,Train-validation-test,N/M,Accuracy and mean reciprocal rank,Tesla C2075 and a Quadro 2000.,,N/M,Proposed method in all configurations outperformed the baseline. CNNs with a single layer were as good as CNNs with 2 layers. ,SVM,,,No,"""The results reported here still need to be taken with a grain of salt. Because of the study design, there is only one trial session (of 32 seconds) per stimulus for each subject. Thus, there is the chance that the neural networks learned to identify the individual trials and not the stimuli based on artifacts in the recordings that only occurred sporadically throughout the experiment.""",Only a single trial per stimuli,Yes,Yes,,,Isabela,[TBD],
,Deep Belief Networks used on High Resolution Multichannel Electroencephalography Data for Seizure Detection,2014,"Turner, Page, Mohsenin & Oates",AAAI Spring Symposium,Yes,"University of Maryland, Baltimore County",7,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,TBD,Improve State of the Art,Use DBN for Seizure Prediction,"Ongoing EEG recording, with and without seizures.",Ubiquitous bio-sensing for personalized health monitoring is slowly becoming a reality,,N/M,No,Seizures,CHB-MIT,Public (open),10/22,23,256,"N/M
(see dataset paper)",,,None,No,"Area, Normalized Decay, Line Length, Mean Energy, Average Peak Amplitude, Average Valley Amplitude, Normalized Peak Number, Peak Variation, Root Mean Square",,z-score,,Theano,DBN,,N/M,Layered learning approaches such as DBN excel in such context,Yes,"23 x 9
(channels x features)","2
(500 nodes)",N/M,N/M,,,"2
(seizure, non-seizure)",N/M,"Training deep belief networks is best done one layer at a time, in a layerwise manner (Bengio et al. 2007).
After the pretraining process of abstraction was completed (without the usage of class la- bels), the logistic regression layer was trained in the finetun- ing process. 16 iterations of finetuning were completed, with a learning rate α = .1",N/M,"lr: 0.001
25 epochs",N/M,N/M,N/M,N/M,,10-Fold CV,"Train: 71.4%
Valid: 14.2% 
Test:14.2%","Precision
Recall
F-Measure (F1)","Dell Precision M4700
Intel i7-3940XM
16 GB 
 NVIDIA Quadro K2000M",,N/M,(check graphs for each patients - no results in numbers...),"KNN
SVM
Log. Reg.",,,No,"Dealing in the domain of using models of other patients to represent a different patient being tested upon (as was the case in the leave one out training and in real situations), deep belief networks often outperformed the logistic regression algorithm using the same feature set.","Although these are good numbers, it may not always be feasible to have hours of trained data about a patient to use as a model. The more realistic clinical study is the study, where the patients tests were done without any previous knowledge of the patient being tested on.",No,No,-,,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Affective state recognition from EEG with deep belief networks,2013,"Li, Li, Zhang, Zhang",IEEE International Conference on Bioinformatics and Biomedicine,,"State University of New York at Buffalo
Beijing University of Technology",6,,General Affective,Classification of EEG signals,Monitoring,Affective,TBD,Improve State of the Art,,"Emotion Classification on DEAP 
(Like or Dislike video)",,,N/M*,No,PSD,DEAP,Public (open),32,32,[DEAP],N/M*,,,"Same as DEAP:
1) Re-reference Common Avg.
2) Downsampled to 256Hz
3) High-Pass Filter: 2Hz
4) Eye artifacts removed with EEGLab AAR",,"PSD?
",,,,N/M*,DBN + RBM,,"DBN for channel selection
then RBM for prediction",,,,,,,,,"2
Like or Dislike",N/M*,,N/M*,,,,N/M*,N/M*,,N/M*,,,,,N/M*,~75%,"SVM,  PCA + SVM, SVM + Fisher, PCA + Fisher + SVM, DBN + Fisher + RBM",,,,"Moreover, to handle the small sample problem, the proposed method utilizes the DBN to reduce the dimensionality of the data in each channel while preserving their characteristics.",,No,Yes,Try to coin: Supervised DBN based Affective State Recognition (SDA) model,,Yannick,[TBD],
,Automated Classification of L/R Hand Movement EEG Signals using Advanced Feature Extraction and Machine Learning,2013,"Alomari, Samaha & AlKamha",Arxiv,Yes,"Applied Science University, Jordan",6,,BCI,Classification of EEG signals,BCI,Active,TBD,Improve State of the Art,Use NN and SVM for BCI-MI,Motor Imagery (eegmmidb),None,,"N/M
(see eegmmidb info)",No,Motor Imagery,eegmmidb,Public (open),"6
(out of 108)","8
(out of 64)","N/M
(see eegmmidb info)","6x3x2 min
(subjects x sessions x time)",Offline,,"1) Band-pass filter: 0.5 to 90Hz
2) Notch filer: 50Hz
3) AAR - Artifact Removal Toolbox (EEGLAB)
4) Epoching
5) IIR Band-pass filter: 8 to 30Hz",Yes,"Power, Mean, Energy, Type, Side",,N/M,,"EEGLAB
MATLAB",NN,,N/M,N/M,No,108x26,"[3 - 15]
Best 4",N/M,N/M,2,"Left
Right",2,N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,Intra,N/M,N/M,Accuracy,N/M,,N/M,89.8 %,SVM (97.1%),,N/M,N/M,"Our methodology is not the best, but is somewhat a simplified efficient one that satisfies the needs for researchers in field of neuroscience.

(wow... :/)",N/M,No,No,Very ordinary paper...,,Yannick,[TBD],
,Energy Distribution of EEG Signals: EEG Signal Wavelet-Neural Network Classifier,2013,"Omerhodzic, Avdakovic, Nuhanovic & Dizdarevic",Arxiv,Yes,"Clinical Center University of Sarajevo, Bosnia
University of Tuzla, Bosnia",6,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,TBD,Improve State of the Art,Use WNN (Wavelet NN) for Epilepsy,"Ongoing EEG recording, with and without seizures.",None,,"N/M
(see dataset info)",No,Seizures,Bonn University Dataset,Public (open),5,1,173.61,3 (sets) x 100 x 23.6s,Offline,,None,No,"Wavelet
(6 decomposition levels)",,N/M,,Matlab,NN,,N/M,N/M,Yes - Table,"6
(Wavelet Energy Features)",3,Tangent Sigmoid,N/M,3,"Healthy
Epilepsy Syndrome
Seizure",1,N/M,N/M,"Levenberg-Marquard ??
(TBC)",LR: Levenberg-Marquard Backprop Learning Rule,N/M,Trial and Error,N/M,MSE,Inter,N/M,"Train: 250
Test: 50",Accuracy,N/M,,N/M,94%,N/M,,N/M,N/M,"The most important advantage of the proposed method is the reduction of data size as well indicating and recognizing the main characteristics of signal. Furthermore, it can reduce memory space, shorten pre-processing needs, the network size and increase computation speed for the classification of an EEG signal.",N/M,No,No,-,,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Sleep stage classification using unsupervised feature learning,2012,"Langkvist, Karlsson & Loutfi",Advanced Artificial Neural Systems,,"Orebro University, Sweden",9,,Sleep,Classification of EEG signals,Clinical,Sleep,TBD,New Approach: Explore DL & Unsupervised learning for Sleep Stage Scoring,Explore DL & Unsupervised learning for Sleep Stage Scoring,Sleep,Unsupervised learning for sleep stage scoring from raw EEG signal,,"1) N/M
2) Embla Titanium PSG",No,Sleep,"1) UCDDB
2) Internal Recordings",Public (open),"1) 25
2) 1","1) 1 (out of 2)
2) 8","1) 128
2) 256","1) avg of 6.9h / subject
2) ~60h",,,"1) Notch filter: 50Hz
2) Band-Pass filter: 0.3 - 32Hz
3) Downsampled to 64Hz",No,"Raw EEG for raw-DBN
28 Features for feat-DBN",,N/M,,Matlab,DBN,,N/M,N/M,Yes,"1x256 
(1s @ 256Hz)",2 (200 HU),N/M,N/M,,,"5 classes
(Softmax)",N/M,Unsupervised Greedy Layerwise training,N/M,N/M,N/M,N/M,N/M,RMSE,,25-Fold of Leave-one-out CV,"Train: ~250000 samples
Valid: ~50000 samples
Test: ?","Accuracy
F1-Score","Windows 7, 64-bit, quad-core Intel i5 3.1GHz,  nVIDIA GeForce GTX 470",,"10 min
1h
3h","Mean Accuracy Across Datasets
feat-GOHMM: 63.9 ± 10.8
feat-DBN: 72.2 ± 9.7
raw-DBN: 67.4 ± 12.9

F1-score raw-DBN: [A] 0.69 | [S1] 0.36 | [S2] 0.78 | [SWS] 0.83 | [REM] 0.58","feat-GOHMM vs feat-DBN vs raw-DBN

(all internal, not external comparison)",,,[image of features] It can be observed that the learned features are of various amplitudes and frequencies and some resemble known sleep events such as a K-complex or blink artifacts.,"(1) We also noticed a lower performance if sleep stages were not set to equal sizes in the training set. There was also a high variation in the accuracy between patients, even if they came from the same dataset. (2) It has been suggested for multimodal signals to train a separate DBN for each signal first and then train a top DBN with concatenated data [34]. This not only could improve classification accuracy, but also to single out which signal contains the anomalous signal.",N/M,Yes,No,They also have a paper from 2018. They've continued down the DL-Sleep road!,,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Convolutional neural networks for P300 detection with application to BCIs,2011,Cecotti & Graser,IEEE Transactions on Pattern Analysis and Machine Intelligence,,"University of Bremen, Germany",13,,BCI,Classification of EEG signals,BCI,Reactive,TBD,"Improve SOTA
(they say they are the first to do CNN on P300 speller)","Use CNN for P300 speller, using BCI Competition Datasets","P300 Speller, 6x6 Matrix.
BCI Competition III Dataset II",CNN seems to be a good approach for EEG classification as the signal to detect contains a lot of variations over time and persons,,"N/M
(see dataset info)",No,P300,BCI Competition III Dataset II,Public (open),2,64,240,85 x 2 x 15,Offline,,"0) Band-pass filtered from 0.160Hz (to 240Hz ?) - Hardware
1) Downsampled to 120Hz (1/2)
2) Band-pass filtered: 0.1 - 20 Hz
3) Signal Normalized",No,Raw EEG,,z-score,,N/M,CNN,,N/M,Each map of the first hidden layer is a channel combination. The second hidden layer subsamples and transforms the signal in the time domain.,Yes,"64 x 78
channels x ","
CNN: 2
FC: 1",Sigmoid,N/M,36,"Letters
(6x6 Matrix)","2
(P300 or not)","CNN1: 31,652",N/M,"Gradient Descent
(optimizer: N/M)",N/M,N/M,N/M,N/M,LSE,Intra,N/M,"Train: 2550 + 12750
Test: 3000 + 15000
(per subject)
(Train: 95% T + 5% Valid)","Accuracy (Recognition Rate)
Recal, Precision, Silence, Noise, Error, F-Measure","Core 2 Duo T7500 CPU
(no GPU)",,10 min,"Subject A: CNN-1: 70.37% | MCNN-1: 68.99%
Subject B: CNN-1: 78.19% | MCNN-1: 75.86%

(see all results in paper, for all metrics and all networks)","Compare different CNNs, with ESVM [16,40], LDA [42], mLVQ [42]
Yandong [40], Zongtan [40], Hoffman [40, 41]",,N/M,"Yes, in-depth analysis of the different CNNs, the topology, etc. 
(see paper for more)","Its accuracy is equivalent to the best current method on the Data set II of the third BCI competition [16]. It outperforms the best method in two situations: first, when the number of electrodes is restricted to 8; second, when the number of considered epochs is 10.",N/M,No,No,"Good paper, in-depth analysis of the field and their networks. Also talk about the importance of Datasets like BCI Competition to push the field further!",,Yannick,[TBD],
,Modeling EEG waveforms with semi-supervised deep belief nets: fast classification and anomaly measurement,2011,"Wulsin, Gupta, Mani, Blamco & Litt",Journal of Neural Engineering,,"University of Pennsylvania, USA",14,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,TBD,New Approach,Use DBN to detect EEG anomalies / rare events.,"Ongoing recording in a clinical settings 
(to record rare anormal events)",DBNs can learn from unlabeled data (more available and cheaper than labeled one),,N/M,No,"1) spike & sharp wave, 
2) GPED & Triphasic Waves, 
3)  PLEDs,
4) eye blink artifact,
 5) background activity",Internal Recordings,Private,11,17,256,13 x 2h blocks,Offline,,"None.
Only subsampled 1000 x 2 min window",No,"Diff. Exp.
1) Raw EEG
2) Features (Area, Norm. Decay, Mean Energy, ...)
3) PCA (20)",,z-score,,Matlab,DBN,,N/M,Using DBN / RBMs to learn from unlabeled data,Yes,"1) Raw 256x17 channels
2) Features 16x?
3) PCA 20x1 ",4,Sigmoid,N/M,5,"1) spike & sharp wave, 
2) GPED & Triphasic Waves, 
3)  PLEDs,
4) eye blink artifact,
 5) background activity",not clear,N/M,"3-Step Semi-Supervise Layerwise. 
(1) unsupervised layer-wise RBM training (2) fine-tuned the DBN with backprop on unlabeled data. (3) fine-tune DBN with backprop on labeled data",N/M,LR: 0.1,10,N/M,N/M,RMSE,Inter,10 Fold CV,"Train: 500k + 72,800 (lbl)
Valid: 100k + 14,500 (lbl)
Test: 100k + 14,500 (lbl)
Total: 700k (unlbl) + 
101.8k (lbl)","Sensititivity
Precision
F1-Measure",Mac OS X 10.5 array of 36 dual-core Intel Xeon CPUs (2.26–2.8 GHz),,N/M,"Reporting F1 on a graph. For: Raw256, Feat16, PCA20

We show that DBN, has comparable performance with SVM and KNN classifiers and has fast test time, even on high-dimensional raw data. We also show that using unpreprocessed, raw input data instead of features can yield comparable classification performance with greatly increased methodological elegance","Decisition Tree
SVM
KNN",,"Yes
Wilcoxon-Mann-Whitney test
(raw vs features)",N/M,"(1) We show that a relatively new type of neural network, the Deep Belief Net, has comparable performance with SVM and KNN classifiers and has fast test time, even on high-dimensional raw data. We also show that using unpreprocessed, raw input data instead of features can yield comparable classification performance with greatly increased methodological elegance. (2) As previously mentioned, we have found DBNs can be sensitive to heavy class-imbalance, which occurs in our dataset",Didn't consider the training time which takes a few days to more than a week.,No,No,---,,Yannick,[TBD],
,Single-trial EEG Discrimination between Wrist and Finger Movement Imagery and Execution in a Sensorimotor BCI,2011,"Mohamed, Marwala & John",Arxiv,,"University of Witwatersrand, South Africa
University of Johannesburg, South Africa
University of Cape Town, South Africa",5,,BCI,Classification of EEG signals,BCI,Active,TBD,"New Approach / Improve SOTA
(The combination of these five essential hand movements has not yet been explored in EEG-based BCI literature [9])",Explore BCI based on Motor (real & imagined) using finger vs wrist on the same hand,Motor Imagery & Real - Finger vs Wrist on the same hand,None,,EGI,No,"Motor
Imagery & Real",Internal Recordings,Private,5,128,200,400 trials / subject,Offline,,"1) Band-pass filter: 0.5 - 100Hz
2) Notch filter: 50Hz
3) Epoched in 7s windows
4) AAR (Automatic Artifact Removal) in EEGLAB
5) Band-pass filter: 8 - 30Hz (for mu and beta)
6) ICA (infomax) + Source Loc
7) Visual Inspection to select best ICs (8-12 / subject)",Yes,"1) FFT - 7 Freq Bands from Sources (ICA)
28 time windows * 7 bands * 8-12 ICs = ~2k features
2) Bhattacharyya Distance to select best 18 features
From Sources, not Electrodes. ",,N/M,,"EEGLAB
Matlab","NN
(MLP)",,N/M,N/M,No,"18
(18 best features from Bhattacharyya distance)","1
(24 nodes)",N/M,N/M,2,"Finger
Wrist",1,N/M,N/M,N/M,N/M,N/M,Trial and Error,N/M,N/M,Intra,N/M,N/M,"Accuracy
(they say they also check Specificity and Sensitivity, but nothing is reported)",N/M,,N/M,"Grand Average: 71%
Real - RH: [52-81 | AVG: 70], LH: [56-69 | AVG: 67]
Imaginery - RH: [61-82 | AVG: 73], LH: [67-72 | AVG: 69]","Mahalanobis Distance (MD)
Grand Average: 65%",,N/M,N/M,"Classification is slightly more successful for imagined movements than for real movements. This is contrary to the findings of other BCI studies [20], where classification results for real movements are superior due to real movements generating stronger motor neural activity [20].",N/M,No,No,"They say ""Multilayer perceptron artificial neural networks are used widely in BCI research"" citing Fabien Lotte ML Review on BCI, 2007. (are they?)
Lots of manual steps... not very much automated.",,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Analysis and classification of EEG signals using spectral analysis and recurrent neural networks,2010,Naderi & Mahdavi-Nasab,Iranian Conference of Biomedical Engineering,,Islamic Azad University,4,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,TBD,Improve SOTA,Using Elman RNN on Welch PSD on Bonn University Dataset,"On going EEG with and without seizures
(Bonn University Dataset)",Highly nonlinear dynamic mappings can be performed by RNNs and therefore have temporally extended application,,"N/M
(see dataset info)",No,Seizures,Bonn University Dataset,Public (open),"10
(5 healthy + 5 epileptic)",128,173.61,2 (sets) x 100 x 23.6s,Offline,,"0) Band-Pass filter: 0.53 - 40Hz  (hardware)
1) Visual Inspection + Removal of Artifacted Data",Yes,"Welch (129 features) +
Dimensionality Reduction Stats (129 --> 8 features)
(PSD)",,N/M,,Matlab,Elman RNN,,"Elman RNN to capture temporal information. Elman network has an explicit memory of one time lag with its 
""context layer""",Doing dimensionality reduction before the network to reduce parameters,Yes,"1 x 8
(assumed, not clear)","2
(assumed, not clear)",N/M,N/M,2,"Epileptic
Normal","N/M
(assuming 2)",N/M,N/M,"Levenberg-Marquard ??
(TBC)
(Gradient Descent)",N/M,N/M,N/M,N/M,LSE,Inter,N/M,"50/50
Train: 1600 (800 C1/C2)
Test: 1600 (800 C1/C2)","Accuracy
Specificity
Sensitivity",N/M,,N/M,"Specificity: 100%
Sensitivity: 100%
Accuracy: 100%","MLP - Specif: 99.75%, Sensitiv: 98.12%, Acc: 98.93%
(Ubbeyli, 2008) Acc: 94.83%
(Nigam & Graupe, 2004) Acc: 97.2%",,N/M,N/M,"We demonstrated that Welch method power spectrum density estimation provides very strong features which well represent EEG signals. The high dimension of feature vectors increases computations. To solve this problem, statistical features were obtained from extracted feature vectors and time series EEG segment. ",N/M,No,No,---,,Yannick,[TBD],
,EEG discrimination using wavelet packet transform and a reduced-dimensional recurrent neural network,2010,"Bu, Shima & Tsuji",IEEE International Conference on Information Technology and Applications in Biomedicine,,"Kumamoto National College of Technology, Japan",4,,BCI,Classification of EEG signals,BCI,TBD,TBD,New Approach: Dimensionality Reduction with RNN using Wavelet features,Using a RNN with dimensionality reduction on Wavelet features.,"Finger Taping. (BCI Motor Task, with real movement)","NN can approximate nonlinear mapping between input and output patterns, and they can be trained to adapt for variations among individuals.",,N/M,No,"Motor 
(real movement)",Internal Recordings,Private,4,9,1000,"4x3x30

4 subjects x 3 tasks x 30 trials",Offline,,"1) Spatial Filtering
2) Artifact Removal
3) Wavelet Transform
(they don't go in details)",Yes,"Wavelet
(7 Decomposition Levels)",,N/M,,N/M,"RNN
(R-LLGMN)",,Consists of a dimension-reducing stage and a time series pattern discrimination stage. This NN calculates posterior probabilities for multivariate time series patterns,N/M,Yes,"9 x t
(electrodes x time)",5,N/M,N/M,3,"Left Finger
Right Finger
Rest","1 ?
(not clear, but 1vs1 comparison)",N/M,"Two-Step Learning
(training the Dimension-reducing layers and Dimension-reducing
Time series pattern discrimination layers separately)",N/M,N/M,N/M,N/M,N/M,N/M,Intra,N/M,N/M,Accuracy,N/M,,N/M,"Subject A: 73.2 ± 5.8, 89.8 ± 8.0, 95.2 ± 3.2
Subject B: 94.5 ± 3.3, 93.9 ± 4.9, 85.9 ± 5.6
Subject C: 72.1 ± 7.1, 65.1 ± 10.4, 74.2 ± 9.5
Subject D: 70.4 ± 7.5, 71.3 ± 7.3, 57.3 ± 9.2",N/M,,N/M,N/M,an EEG discrimination method was developed based on the proposed NN and feature extraction using a spatial Laplacian filter and the wavelet packet transform.,N/M,No,No,---,,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,"[Some implications of the ""consciousness and brain"" problem]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Classification of patterns of EEG synchronization for seizure prediction,2009,"Mirowsky, Madhavan, LeCun & Kuzniecky",Clinical Neurophysiology,,"New York University
University of Nebraska Medical Center
New York University Comprehensive Epilepsy Center",,,Epilepsy,,,,,,,,"It has been suggested that interictal phases correspond to moderate synchronization within the brain at large frequency bands, and that there is a preictal decrease in the beta range synchronization between the epileptic focus and other brain areas.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Brain Machine Interface: Analysis of Segmented Eeg Signal Classification Using Short-Time Pca and Recurrent Neural Networks,2008,"Hema, Paulraj, Nagarajan, Yaacob & Adom",Iraq J. Electrical and Electronic Engineering,,"Northern Malaysia University College of Engineering Kangar, Perlis, Malaysia",9,,BCI,,,,,Improve SOTA,"Exploring Elman RNN with overlapping and non-overlapping signals for classification of 5 mental tasks. 
(binary classification, T1 vs T2, T2 vs T3, etc.)","5 Mental Tasks: (1) Baseline, (2) Complex Problem Solving, (3) Geometric Figure Rotation, (4) Mental Letter Composing, (5) Visual Counting",N/M,,Grass amplifier,No,"BCI Mental Commands
5 classes","Keirn and Aunon, 1990",?,2,6,250,"5x5x2x2 = 100
(5 tasks, 5 times each, 2 sessions, 2 subjects) ",,,"1) Band-Pass Filter: 0.5 - 40Hz
2) SVD-PCA to extract features",Yes,120 features are extracted for each subject per task pair combination per trial.,,N/M,,N/M,Elman RNN,,N/M,N/M,No,"1x120
(120 features)",Hidden Neurons 5/10,N/M,N/M,,,"1
0: Task 1
1: Task 2",N/M,Training is conducted until the average error falls below 0.0001 or reaches a maximum iteration limit of 10000. ,N/M,N/M,N/M,N/M,Overlapping segments,N/M,,N/M,"The NN is tested with 100% data samples for each task pair, 10 task pairs are trained for each subject.",Accuracy,N/M,,N/M,"Average classification accuracies are found to be in the range [70.5%, 97.5%]

Average classification accuracies are found to be in the range [75.5%, 100%] which is better than the previous algorithm (overlapping segments)",None,,,N/M,The results of the overlapping segment data show better performance. Future works will consider improving the classification time through other feature extraction techniques,N/M,No,No,Overlapping segments is a data augmentation technique. So they were pioneers I guess :p,,Yannick,[TBD],
,Comparing SVM and convolutional networks for epileptic seizure prediction from intracranial EEG,2008,"Mirowsky, Madhavan, LeCun & Kuzniecky",IEEE Workshop on Machine Learning for Signal Processing,,"New York University
University of Nebraska Medical Center
New York University Comprehensive Epilepsy Center",,,Epilepsy,,,,,Improve SOTA,"We compare L1-regularized logistic regression, convolutional networks, and support vector machines","Ongoing EEG recording, with and without seizures.",To use Modern Machine Learning on Epilepsy,,N/M,No,Seizures,Freiburg Dataset,$$$,21,6,256,N/M,,,"1) Band-Pass Filter (IIR): 49-51Hz (Power)
2) Low-Pass Filter: 120Hz (to remove aliasing)
3) High-Pass Filter: 0.5Hz (to remove DC)",,"""We concentrate on aggregated features that encode the relationship between pairs of EEG channels, such as cross-correlation, nonlinear interdependence, difference of Lyapunov exponents and wavelet analysis-based synchrony such as phase locking.""",,z-score,,"Matlab
LibSVM
Lush",CNN,,N/M,N/M,No,"Not clear...
Pairs of Channel x Freq Features x Time",5,N/M,L1,,,"2
1: preictal [-1,1]
2: interictal [-1,1]",N/M,N/M,N/M,N/M,N/M,N/M,N/M,MSE,,N/M,"Train: 66%
Test: 33%","Sensitivity
False Positive",N/M,,,"""we can claim that we obtain 100% sensitivity and no false positives on the full 88-seizure Freiburg dataset.""","Logistic Regression
SVM",,,N/M,-,N/A,No,,(a second read would help better understand the feature part...),,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Time-Delay Neural Networks and Independent Component Analysis for EEG-Based Prediction of Epileptic Seizures Propagation,2007,"Mirowski, Madhavan & Lecun",AAAI Conference on Artificial Intelligence,,New York University,,,Epilepsy,,,,,New Approach: TDNN for Epilepsy,Compare TDNN and ICA+TDNN for seizure detection,"Ongoing EEG recording, with and without seizures.",To create a generative model to simulate EEG...,,N/M,Yes,Seizures,Internal Recordings,Private,2,32,400,N/M,,,N/M,,Raw EEG,,z-score,,Lush,"1) TDNN
2) ICA+TDNN
(Time-Delayed NN)
",,N/M,N/M,Yes,800 EEG Frames x 32 channels,"Not clear...
8 + 17 ?",N/M,N/M,,,1 EEG Frame of 32 Channels,N/M,"""A 'serial' prediction training method was implemented""","SGD
(stochastic online gradient descent)","LR: 0.0001
Lambda: 0.0001",N/M,N/M,N/M,MSE,,N/M,N/M,"From the same patient, can it detect a similar seizure",N/M,,N/M,"Not clear... No %
However, ""TDNN failed to accurately reproduce the time-series of a similar seizure in the same patient""",TDNN vs ICA+TDNN,,,N/M,-,"Due to the limitations of the predictor because of accumulated error, only short epochs of EEG could be used as inputs, with 2-3 second output windows",No,,I'd love to know the number of parameters of that network!,,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,The Combined Technique for Detection of Artifacts in Clinical Electroencephalograms of Sleeping Newborns,2005,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,A Learning Algorithm for Evolving Cascade Neural Networks,2005,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Polynomial Neural Networks Learnt to Classify EEG Signals,2005,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Learning Multi-Class Neural-Network Models from Electroencephalograms,2005,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,An Evolving Cascade Neural Network Technique for Cleaning Sleep Electroencephalograms,2005,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,A Neural Network Decision Tree for Learning Concepts from EEG Data,2005,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Neural-Network Techniques for Visual Mining Clinical Electroencephalograms,2005,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Detecting Behavioral Microsleeps using EEG and LSTM Recurrent Neural Networks,2005,"Davidson, Jones & Peiris",IEEE Engineering in Medicine and Biology Conference,,"Van der Veer Institute for Parkinson's and Brain Research, Christchurch Hospital, University of Otago, University of Canterbury. (Christchurch, New Zealand)",4,,General Cognitive,,,,,New Approach,Using LSTM to detect microsleep lapses during a visumotor task,"Visuomotor Task
(you have to follow a target on the screen with the mouse. 1h long sessions)",Experiencing a lapse of this type while performing an important task can have catastrophic consequences. A warning system capable of reliably detecting patterns in EEG occurring before or during a lapse has the potential to save many lives.,,N/M,No,Microsleep lapses,Internal recordings,Private,8,"2
(recorded: 16)",256,N/M,,,Epochs exhibiting clear electrode pop were marked as artifact using a simple algorithm which detected a change of greater than 0.4 mV in EEG amplitude within a single sample,Yes,Log of mean power in 7 freq ranges.,,z-score,,N/M,LSTM,,We used a slightly modified version of the implementation included with PDP++ [21].,N/M,No,14 Features,"6 LSTM Blocks
with 3 memory cells each",N/M,N/M,,,"1
0: No Lapse
1: Lapse",N/M,N/M,N/M,"LR: 1x10-5
Momentum: 0.9",N/M,N/M,N/M,N/M,,"8-Fold Leave-one-out CV

(did it 5 times)",N/M,"Sensitivity
Specificity
Positive Predictive Value",N/M,,N/M,"Moderately Sensitive (mean sn = 0.48 ± 0.09, range 0.14 to 0.83)
Highly Specific (mean sp = 0.93 ± 0.02, range 0.80 to 0.99) 
Poor Positive Predictive Value (mean ppv = 0.39 ± 0.06, range 0.07 to 0.71)",None,,,N/M,"Our results show LSTM can be used to detect lapses, though the detector is not yet sufficiently reliable for general use. Some individual sessions showed reasonably good performance for reasons that are not clear. It could be that these sessions included a greater proportion of deep lapses, making them easier to detect.","Our results show LSTM can be used to detect lapses,
though the detector is not yet sufficiently reliable for general use.",No,No,Love the description of the DL part given that it's a paper from 2005,,Yannick,[TBD],
,[Progress in automatic detection of epilepsy based on EEG analysis],2005,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Pattern Discrimination of Time Series EEG Signals using a Recurrent Neural Network,2002,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,The automatic recognition of REM sleep: a challenge and some answers,2002,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Recurrent neural network based prediction of epileptic seizures in intra- and extracranial EEG,2000,"Petrosian, Prokhorov & Homan",Neurocomputing,,,,,Epilepsy,,,,,Novel Approach: RNN for Epilepsy data.,RNN on Raw EEG with and without Wavelet subsignals for Seizure detection,"Ongoing EEG recording, with and without seizures.",No one has used Raw EEG with a Neural Network for Epilepsy before,,"1) Stellate Monitoring System
2) TECA 1121 
(Vickers Medical)",Both,Seizures,Internal Recordings,Private,N/M,"1) 1 (out of 32)
2) 1",1) 200,"1) 4 Seizures
2) 6 Seizures
",,,N/M,,"1) Raw EEG
2) Wavelet Subsignals",,z-score,,N/M,RNN,,N/A,N/M,Yes,Not Clear,"1
(10-15 HU)",common bipolar sigmoid nonlinearity,N/M,,,1,N/M,We have used the multi-stream EKF-based training of RNN,N/M,N/M,N/M,N/M,N/M,MSE,,Leave-one-out,N/M,"% FP
% FN","Pentium II
200Hz",,2-3h,"6/6 Tests with Raw EEG + Wavelet subsignals
3/6 Tests with only Raw EEG",N/M,,,N/M,"In fact, we are unaware of any published results up to date with the use of neural networks trained on raw EEG data for long-term seizure prediction","Training and testing of RNNs will be required on larger cross-patient data sets of original EEG recordings, as well as on combinations of subsignals at di!erent levels obtained with various wavelet packet transforms",No,,"This is no ""big data"". Can't do deep learning like that on that amount of samples",,Yannick,[TBD],
,Early recognition of Alzheimer's disease in EEG using recurrent neural network and wavelet transform,2000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Recurrent neural network and wavelet transform based distinction between Alzheimer and control EEG,1999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,Dynamic EEG modeling and single-evoked potential extraction using real-time recurrent neural network,1998,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,DISCRIMINATING BETWEEN ALZHEIMER AND CONTROL PATIENT EEG: APPLICATION OF NEURAL NETWORK IN CONJUNCTION WITH SIGNAL WAVELET DECOMPOSITION: C106,1997,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Legend,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Arxiv preprint,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Journal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Conference,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Thesis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Github/Open source project,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Competition,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Studies to be excluded,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,(to be moved to #Excluded),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Inferring Clinical Correlations from EEG Reports with Deep Neural Learning,2017,Goodwin & Harabagiu,AMIA Annual Symposium,,University of Texas at Dallas,10,,Other,,,,,Novel Approach: NLP for EEG Reports,Using DL on EEG Reports for clinical correlations inference.,"Epilepsy, on-going recording.
They used the TUH datasets, not for the EEG data but for the EEG ""Reports"". (the text)",NLP can help reduce the errors in reporting,,N/M,No,"NLP
(not EEG)","TUH EEG Seizure Corpus 
(TUSZ)",Public (account),"N/A
(NLP not EEG)","N/A
(NLP not EEG)","N/A
(NLP not EEG)","N/A
(NLP not EEG)",,,N/A,N/A,N/A,,N/A,,"Tensorflow
OpenNLP
GENIA","Bidirectional
RNN",,With Attention,"N/A
(NLP)",Yes,Text (words),5,N/M,N/M,,,,N/M,N/M,Adam,LR: 0.001,10,Grid Search,N/M,Cross-Entropy,,N/M,"3:1:1
Train:Valid:Test",,N/M,,N/M,"BLEU-1: 0.6879  |   BLEU-2: 0.5468  |   BLEU-3:  0.4632

ROUGE-1:  0.6352  |   ROUGE-2: 0.5045  |   ROUGE-3:  0.4289

WER:  1.631","NN:Cosine
NN:LDA
DL:Attn-RNLM
DL:Basic-S2S
DSRM (best)",,,Yes,"Our evaluation on over 3,000 EEG reports revealed the promise of the DSRM: achieving an average of 17%improvement over the top-performing baseline. These promising results provide a foundation towards automatically identifying unusual, incorrect, or inconsistent clinical correlations from EEG reports in the future.",Immediate avenues for future work include (1) consideringmore sophisticated loss functions which incorporate contextual and semantic information and (2) an in-depth study and evaluation ofmetrics for qualifying the degree of disagreement between a given clinical correlation section and the inferred or expected clinical correlation section.,No,No,"Ambitious... It's more NLP than DL-EEG.
Should be excluded from the analysis, but mentioned in the paper",,Yannick,,
,A Generalised Seizure Prediction with Convolutional Neural Networks for Intracranial and Scalp Electroencephalogram Data Analysis,2017,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Deep neural networks on graph signals for brain imaging analysis,2017,"Guo, Nejati, Cheung",ICIP,Yes,Singapore University of Technology and Design,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Uses MEG, not EEG.",,Isabela,[TBD],
,Prediction of Brain States of Concentration and Relaxation in Real Time with Portable Electroencephalographs,2015,"Li, Xu & Zhu",Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Automated Classification of Hand-grip action on Objects using Machine Learning,2018,"Mishra, Sharma, Kumar, Ranjan & Ujlayan",Arxiv,,"Amity University, Oxford Brookes University, Gautam Buddha University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Neonatal EEG Interpretation and Decision Support Framework for Mobile Platforms,2018,"O'Sullivan, Gomez, O`Shea, Salgado, Huillca, Mathieson, Boylan, Popovici & Temko",Arxiv,,University College Cork,,,Epilepsy,,,,,,Increase number of physicians who can diagnose neonatal EEG,,,,OpenBCI ganglion,No,Raw EEG,Internal Recordings,Private,,1,200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Semi-automated Annotation of Signal Events in Clinical EEG Data,2018,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Deep learning with convolutional neural networks for decoding and visualization of EEG pathology,2017,,Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Objective evaluation metrics for automatic classification of EEG events,2017,"Ziyabari, Shah, Golmohammadi, Obeid & Picone",Arxiv,,"Temple University
BioSignal Analytics, Inc., Philadelphia",17,,Epilepsy,,,,,,,,,,,,,TUH,Public (open),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],,
,Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG,2017,"Schirrmeister, Springenberg, Fiederer, Glasstetter, Eggensperger, Tangermann, Hutter, Burgard & Ball",Arxiv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,"Single-trial P300 Classification using PCA with LDA, QDA and Neural Networks",2017,Sharma,Arxiv,Yes,Colorado State University,17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,A deep learning approach to EEG based epilepsy seizure determination,2016,Cilasun & Yalcin,Signal Processing and Communication Application Conference,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Evaluating Content-centric vs User-centric Ad Affect Recognition,2017,"Shukla, Gullapuram, Katti, Yadati, Kankanhalli & Subramanian","
19th ACM International Conference on Multimodal Interaction",Yes,"International Institute of Information Technology
Hyderabad, India, Indian Institute of Science Bangalore, India, Delft University of Technology, National University of Singapore, University of Glasgow Singapore",9,,General Affective,,,,,New Approach,Use CNN for Affect Recognition during Ads. (neuromarketing),Watching short ad videos.,,,Emotiv,No,"Emotions
(Via Freq Bands - Spectrograms)",Internal Recordings,Private,11,14,128,804,,,"1) Band-Pass filter: 0.1 - 45 Hz
2) ICA to remove artifacts",Yes,,,,,Caffe,Places205,,"""Domain Adaptation"" of Places205 pre-trained model via the LIRIS-ACCEDE movie dataset",,No,,"N/M
(see Khosla et al., 2013)",,,,,,,,,,,,,,,5-Fold CV,Test: 28/100 (??),,,,,,"Hanjalic et al., 2005",,,,"Experimental results showthat while the deep CNN framework outperforms the Han method, it nevertheless performs inferior to an SVM-based classifier trained on EEG epochs for asl and val recognition. Future work will focus on the development on effective alternative strategies to CAVVA for video-in-video advertising, as CAVVA is modeled on ad-hoc rules derived from consumer psychology literature.",,No,No,"They talk alot about the AR and high-level stuff, but very little about the actual DL. They just say that they fine-tuned the Places205 model, and sent spectrograms as inputs...",,Yannick,,
,Dropping Activation Outputs with Localized First-layer Deep Network for Enhancing User Privacy and Data Security,2017,"Dong, Wu, Wei & Guo",IEEE Transactions on Information Forensics and Security,No,Imperial College London,9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Not related to EEG,,Isabela,[TBD],
,A New Approach to Automated Epileptic Diagnosis Using EEG and Probabilistic Neural Network,2008,"Bao, Lie & Zhang",Arxiv,,Texas Tech University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Using Deep Learning Techniques to Analyze and Classify EEG Recordings,2014,,Computational Neuroscience Workshop at Unconventional Computation and Natural Computation Conference (UCNC'14),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,[The current situation and development of tremor signals analysis].,2007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,A framework for large-scale evaluation of deep learning for EEG,2018,"Heilmeyer, Schirrmeister, Fiederer, Völker, Behncke & Ball",Arxiv,,University of Freiburg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Using Convolutional Neural Networks to Automatically Detect Eye-Blink Artifacts in Magnetoencephalography Without Resorting to Electrooculography,2017,,MICCAI,,"UT Southwestern Medical Center (Dallas, USA)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Neural networks for EEG signal decomposition and classification,1995,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,A Neural-Network Technique to Learn Concepts from Electroencephalograms,2005,Schetinin & Schult,Theory in Biosciences,,"University of Exeter, UK
Friedrich-Schiller-University of Jena, Germany",12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Practical Riemannian Neural Networks,2016,,Arxiv,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Isabela,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Attention Monitoring with Electroencephalography and Artificial Neural Network,2015,Uduwila Arachchi Charitha Senarathne,Master's thesis,,University of Moratuwa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Studies on invasive data only,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Deep learning as a tool for neural data analysis: speech classification and cross-frequency coupling in human sensorimotor cortex,2018,"Livezey, Bouchard & Chang",Arxiv,Yes,"University of California, Berkeley
University of California, San Francisco",23,,BCI,BCI,Speech classification,,,Improve SOTA,"Speech decoding via sensorimotor cortex, up to 57 classes","Speech (read aloud consonant-vowel (CV) syllables composed of 19 consonants followed by one of three vowels (/a/, /i/ or /u/))",Because of the nonlinearity of speech processing in the brain. DL can capture that hierachical nonlinear model better than linear simpler ones.,,"N/M
(see paper cited)
(data recorded in a previous study)",Yes,Raw EEG,Internal Recordings,Private,4,"256 
(ECoG)",N/M,"S1 = 2572, S2 = 1563, S3 = 5207, and S4 = 1422",,,"1) Manual Inspection of Artifacts -> Rejection of channel
2) Common Average Reference.
3) Hilbert Transform (40 PB Filters) -> Freq Bands",Visual and quantitative inspection to reject bad channels,Frequency Bands (6),,z-score,,"Theano
Scikit-learn
Pylearn2",FC NN,FC,N/M,N/M,No,N/M,1 or 2,"ReLU, tanh or sigmoid","Dropout, weight decay, filter norm-clipping",3-57,The different types of consonant-vowel syllables,"Between 3 and 57 classes
(Softmax)",N/M,Standard optimization,SGD + Nesterov momentum,Initial momentum fraction=0.5,15-256,Random Search,N/M,N/M,Intra,10-Fold,"Train: 80%
Validation: 10%
Test: 10%",Accuracy,N/M,,N/M,"Deep network, 57 CV, single subj. = 38.3 ± 2.9%
Deep network, 57 CV, subj. average = 19.9 ± 12.6%
Deep network, 19 cons., single subj. = 44.9 ± 3.0%
Deep network, 19 cons., subj. average = 26.8 ± 12.6%
Deep network, 3 vowels, single subj. = 71.1 ± 1.9%
Deep network, 3 vowels, subj. average = 51.7 ± 12.1%","(Mugler, 2014) LDA, 24 cons., single subj. = 36.1%
(Mugler, 2014) LDA, 24 cons., subj. average = 20.4 ± 9.8%
(Mugler, 2014) LDA, 15 vowels, single subj. = 23.9%
(Mugler, 2014) LDA, 15 vowels, subj. average = 19.2 ± 3.7%
(Also, multinomial logistic regression) ",Traditional pipeline,Linear regression with t-tests on slopes,"Yes
(half the paper is on it, great analysis!)

High-Gamma frequency seems to contain most of the information for the classification.","When classifying syllables, deep networks achieved state-of-the-art accuracy and channel capacity: for the best subject, this was 38.3% and 3.09 bits per syllable. Studying how [deep networks] behave in an online BCI will be important step in integrating them into clinical settings. Although deep networks have shown the ability to maximize task performance across scientific and engineering fields, they are still largely black boxes [57]. In general, understanding the interaction between dataset structure and deep network training will make deep networks more broadly useful as a tool for data analytics in science.",N/M,No,No,"Great paper! (but quite long)
Statistical analysis on their results. Studied the impact of dataset size. Looked ar the learned features (in-depth; like 5 pages)

But they don't talk much about the neural network itself.",,Yannick,Hubert,
,Intracranial Error Detection via Deep Learning,2018,"Völker, Hammer, Schirrmeister, Behncke, Fiederer, Schulze-Bonhage, Marusič, Burgard & Ball",Arxiv,Yes,"Albert-Ludwigs-University
Motol University Hospital (Charles University)
Translational Neurotechnology Lab (University Medical Center Freiburg)",,,BCI,,,,,New Approach: Intracranial Error Detection via [insert],,Flanker Task,,,N/M*,Yes,Error-Related,Internal Recordings,Private,"24
(23 diff + 1 twice)",24,"N/M*
(re-sampled to 250Hz)","Single-Channel: 200 training epochs
All-Channels: 1000 training epochs",,,"1) Rereference bipolarly between neighbors
2) Downsampled to 250Hz",,Raw EEG,,,,"Python, BrainDecode","ResNet
EEGNet
Deep4Net
ShallowNet",CNN,N/M*,,No,"2s window x 
Single-Channel (1) 
and 
All-Channels (24)",up to 34,,,,,"1
(Error yes/no)",N/M*,,"AdamW w/ Cosine Annealing Weight Decay of 0.002
 Initial Learning Rate of 0.01",,,,"Brain-decode’s ClassBalancedBatchSizeIterator, which draws the training samples such that, in expectation, the same number of examples is drawn per class.",N/M*,,"Train: 60% of each recording
Test: 40% of each recording",,"Normalized Accuracy

(Also: specificity, precision, and the F1-score)",,,N/M*,"Deep4Net: 74.84%
ResNet: 72.67%
EEGNet: 69.37%
ShallowNet: 61.50%",N/M,None,,,"""When decoding on all channels, especially deeper networks strongly gained accuracy compared to single-channel decoding. One could thus speculate that deeper networks need a broader spectrum of data to perform reliably, while very shallow networks cannot cope with the amount of noise in all-channel decoding. [...] hinting towards the ability of CNNs to extract hidden connectivity features.""",,,,Important to note that the intracranial electrode postions vary quite a bit as opposed to 10-20 non-invasive EEG. That adds an additionnal challenge.,,Yannick,[TBD],
,Epileptic Seizure Prediction Using Big Data and Deep Learning: Toward a Mobile System,2017,"Kiral-Kornek, Roy, Nurse, Mashford, Karoly, Carroll, Payne, Saha, Baldassano, O'Brien, Grayden, Cook, Freestone & Harrer",EBioMedicine,,"IBM Research
The University of Melbourne",,,Epilepsy,,,,,New Approach: Embedded a DL on a low power chip - IBM TrueNorth.,,iEEG continuous recording,,,N/M*,Yes,Seizures,"Cook et al., 2013",[TBD],10,16,N/M*,N/M*,,,N/M*,,Spectrogram,,,,N/M*,"Deep Learning
(haha, they don't even describe their model!)",NS,N/M*,,No,N/M*,N/M*,,,,,N/M*,N/M*,,N/M*,,,,N/M*,N/M*,,N/M*,,"Sensitivity
(true positive seizure prediction rate)",,,N/M*,The prediction system achieved mean sensitivity of 69%,"Traditional pipelines
(Cook et al., 2013)
(Karoly et al., 2017)",Traditional pipeline,,,"We have demonstrated the feasibility of implementing a real-time and ultra-low power solution on the TrueNorth chip. TrueNorth, due to its unique capabilities – namely its neuromorphic architecture, small size, and low power consumption – could provide themobile processing power for awearable seizure prediction or intervention system.We have proposedadeeplearning approach to seizureprediction,which addresses many of the challenges identified from previous analyses using the same data (Freestone et al., 2017; Karoly et al., 2017).",,No,,"They don't even describe their model... They just say ""Deep Learning"". This paper was really just about their own chip. And not a real scientific contribution...",,Yannick,[TBD],
,Deep Learning with Edge Computing for Localization of Epileptogenicity Using Multimodal rs-fMRI and EEG Big Data,2017,"Hosseini, Tran, Pompili, Elisevich & Soltanian-Zadeh",IEEE International Conference on Autonomic Computing (ICAC),,"Rutgers University–New Brunswick, NJ, USA
Michigan State University, Grand Rapids, MI, USA
Spectrum Health, Grand Rapids, MI, USA
University of Tehran, Tehran, Iran
Henry Ford Health System, MI, USA",10,,Epilepsy,,,,,New Approach,"Leveraging the potential of autonomic edge computing in epilepsy, we develop and deploy both noninvasive and invasive methods for the monitoring, evaluation and regulation of the epileptic brain, with responsive neurostimulation (RNS; Neuropace).","Ongoing EEG recording, with and without seizures.","BCI for Epilepsy. Closed-Loop with brain stim. However we need an efficient ""monitoring"" system with good accuracy.",,N/M,Yes,Seizures,"U. Penn & Mayo Clinic
(seems like it's the Kaggle one... they cite: Stead et al., 2010)",TBD,8,N/M,500,N/M,,,"1) 4th Order Butterworth bandpass filter: 0.5-150 Hz
2) Notch filter: 50Hz
3) Phase distortion is canceled by using forward and backward filtering",No,"2 sets of features: (1) Raw EEG and (2)
Several time and frequency-related features have been extracted including com-plexity, mobility, energy, entropy, correlation coefficients, Fast Fourier Transform (FFT), variance, skewness, kurtosis, mean, fractal dimension, frequency band power, peak amplitude, zero crossing, average spectral power, line length, maximal and minimal values, sum absolute value and some others",,N/M,,N/M,CNN,CNN,"Conv + ReLU + Max Pooling
-> FC -> softmax -> SVM",N/M,Yes,"EEG/ECoG Data

(format N/M)","N/M

CNN & FC

More than 1...",ReLU,N/M,,,"1
0: non-preictal
1: preictal

(going to an SVM for EID vs non-EID)",N/M,N/M,N/M,N/M,N/M,N/M,N/M,N/M,,N/M,"Train: 70%
Test: 30% *

(* assumed)","Not Clear...

(to be reviewed)","N/M

(Cloud)",,N/M,"Not Clear...

(to be reviewed)",N/M,None,,N/M,"Based upon this preliminary assessment, definitive therapy
may be decided in the form of resective surgery or entirely discounted on the basis of multifocality suggesting greater than two sites of independent epileptogenicity",N/M,No,No,"Hard to analyze. They mix rs-fMRI and they stay high level...
(I hate that kind of paper)",,Yannick,[TBD],
,Optimized Deep Learning for EEG Big Data and Seizure Prediction BCI via Internet of Things,2017,"Hosseini, Pompili, Elisevich & Soltanian-Zadeh",IEEE Transactions on Big Data ,,"Rutgers University, New Brunswick, NJDepartment of Clinical Neurosciences, Spectrum Health, Grand Rapids, MIMedical Image Analysis Laboratory, Henry Ford Health System, Detroit, MI",13,,Epilepsy,,,,,New approach: using cloud computing for seizure prediction,"CNN & SAE on the cloud (""Internet of Things"") for epilepsy","Ongoing EEG recording, with and without seizures.",Cloud Computing,,N/M,Yes,Seizures,Internal recordings,Private,"1) 9
2) 2","1) 70 (intracran.)
2) 15 (intracran.)","1) 1000Hz
2) 5000Hz","1) 1755 
(585 / 585 / 585)
2) 390
(130 / 130 / 130)

(inter / ictal / pre)",,,"1) Bandpass (fourth-order Butterworth) filter: 0.5-150 Hz
2) Filter Notch filter: 50Hz
3) Wavelet and ICA",Yes,Output of Raw EEG -> PCA -> I-ICA -> DSA,,N/M,,"Python
Pytorch","CNN
SAE",CNN,"PCA + I-ICA + DSA
(optimization)",N/M,Yes,N/M,"CNN: N/M
SAE: A softmax layer as a gradient-log-normalizer of the categorical probability distribution is used in the last layer.",ReLU,"L2
Spasity*",,,"CNN: 2
(Softmax)

SAE: 1",N/M,"SAE: Hidden layers are trained individually in an unsupervised method.

** Therefore, in this study, instead of training a new network, fine-tuning of existing pretrained networks was undertaken for the seizure prediction task.",N/M,N/M,N/M,N/M,N/M,MSE,,Leave-one-out,N/M,"Accuracy
Sensibility
Sensitivity
FPR
FNR","HP laptop and Intel i5 processor, 8 GB RAM and battery capacity of 4,400 mAh
--
AWS Cloud EC2",,N/M,"Accuracy: [CNN]  0.96 |  0.94 [SAE]
Sensibility: [CNN]  0.97 |  0.95 [SAE] 
Sensitivity: [CNN]  0.97 |  0.95 [SAE]
FPR: [CNN]  0.05 |  0.06 [SAE]
FNR: [CNN]  0.03 |  0.05 [SAE]","Random Forest
Non-linear SVM
Linear SVM
MLP Neural Network

They outperform all of these",Traditional pipeline,,N/M,(1)The requirements for safe storage and high computational resources for processing such data must also take into account the large variety of patterns characterized by fluctu- ations of signal amplitude and frequency that create signifi- cant challenges for reliable feature extraction. (2) The developed deep-learning methods provide unsupervised feature extraction as a suitable substitute to manual feature-extraction techniques of classification through a hierarchical learning process that extracts high- level and complex abstractions for data representations.,N/M,No,No,Hard to follow sometimes...,,Yannick,[TBD],
,Deep learning for epileptic intracranial EEG data,2016,"Antoniades, Spyrou, Took & Sanei",IEEE International Workshop on Machine Learning for Signal Processing,,"University of Surrey, United Kingdom",,,Epilepsy,,,,,Improve state-of-the-art,Use CNN for Epilepsy,Seizure detection,Epilepsy problem is still unresolved and people use feature-driven approaches,,N/M,Yes,Seizures,Internal Recordings,Private,25,12,N/M,"IED: 7831
non-IED: 7831",,,None,No,Raw EEG,,N/A,,N/M,CNN,CNN,1D Conv,N/M,Yes,"12x65
(channels x samples)",2,tanh,N/M,,,,4540,N/M,N/M,N/M,N/M,N/M,N/M,Cross-Entropy,,Leave-one-out,N/M,Accuracy,N/M,,N/M*,Mean Accuracy: 87.51,"Time-Frequency Approach (Spyrou, 2016)",Traditional pipeline,,N/M,"""Making Sense of Epileptic EEG in Machine Learning"" To address the ‘black-box’ nature of neural networks, we now illustrate how the learning process of CNNs captures features of IEDs... (2) This again indicates that the epileptic patterns were successfully learnt by our proposed method. (3) Futureworks include deeper learning with additional hidden layers in CNNs and a closer examination of the differ- ent kinds of epileptic waveforms via neural network learning.","They talk the ""black box"" and how to understand what the network learns & means.",No,,"They also talk about the ""black box"" and try to understand what the network learnt.
They also say that the next step is deeper nets...",,Yannick,[TBD],
,Predicting seizures from electroencephalography recordings: A knowledge transfer strategy,2016,"Liand, Lu, Zhang & Wang",IEEE International Conference on Healthcare Informatics,,"Tsinghua University, China
Department of Healthcare Policy and Research Weill Cornell Medical College (NYC)",8,,Epilepsy,,,,,New Approach: Transfer learning for Epilepsy,"Using 6 publicly available, non-epilepsy, datasets to initialize the weights and leverage transfer learning for seizure detection",Seizure detection,Transfer Learning. Leveraging other datasets to boost / improve performance for a different paradigm.,,"N/M
(see dataset paper)",Yes,Seizures,"Kaggle
(American Epilepsy Society Seizure Prediction Challenge)",Public (open),2 + 5 dogs,[15-24],"1) 5000Hz
2) 400Hz",check paper - Table 1. - for exact number,,,"1) BandPass filter: 47 - 53Hz & 97 - 100Hz
2) High-Pass filter: 0.1Hz
3) Low-Pass filter: 200Hz
4) FFT -> Freq bands",No,"19 Frequency Bands
(multiple # of bands tested, best one is 19)",,N/M,,MATLAB,CNN,CNN,N/A,"According to [23], CNNs with one convolutional layer (which corresponds to one stage in [24]) is better than CNNs with two, thus we only adopted one stage in our CNN model.",Yes,"24x19x27
(channels x features x time)","CNN: 1
FC: 1

[double check me]",N/M,"Dropout
L2",,,"1
(Linear SVM)
-1 or 1",N/M,"Pre-Training on 6 other (publicly available) non-epilepsy datasets. Do 1 training epoch on each dataset and then use these weights as the starting point for the ""real"" dataset.

-- Transfer Learning --",SGD,"LR: 0.03 Without Decay
Weight Decay: 0.001
Max Epochs: 40
Witout Momentum",10,N/M,N/M,Linear SVM,,"Dogs: 4-Fold CV
Humans: 3-Fold CV","N/M

(Transfer Learning, suign 6 other dataset to initialize the weights)",AUC,N/M,,N/M,"(AUC score)
Random Forest:  0.63811
CNN + SVM:  0.68802
CNN + SVM with Pre-Train:  0.72401
CNN + MI-SVM:  0.68635 
CNN + MI-SVM with Pre-Train: 0.68892
CNN + mi-SVM: 0.61918
CNN + mi-SVM with Pre-Train: 0.62766
",Random Forrest (TreeBagger),Traditional pipeline,,N/M,"Such phenomena suggests that it is reasonable to cut frequency band into δ, θ,α,β and γ band to predict seizures.

Because of the limited training data, we propose a knowledge transfer strategy to effectively train the CNN model.",N/M,No,Yes,"Very interesting. Indeed if transfer learning works for EEG, it will be huge!",,Yannick,[TBD],
,Cloud-based Deep Learning of Big EEG Data for Epileptic Seizure Prediction,2016,"Hosseini, Soltanian-Zadeh, Elisevich & Pompili", 2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP),Yes,"Rutgers University–New Brunswick
Henry Ford Health System
University of Tehran
Spectrum Health System
Michigan State University",,,Epilepsy,,,,,Novel Approach: Real-Time Cloud-Based sAE for seizure detection with iEEG data,Explore Feasibility of Real-Time iEEG Seizure Detection with a Cloud-Based Deep Learning approach,"Ongoing EEG recording, with and without seizures.",Big Data + Cloud to handle iEEG huge amount of data in real-time,,N/M,Yes,Seizures,"iEEG Dataset from 
University of Pennsylvania
& the Mayo Clinic",Private,N/M,15,5000,"120*
Preictal: 60
Interictal: 60
(to be confirmed)",,,"1) PCA
2) I-ICA
(to reduce dimentionality, bandwith, computing power)",,"None
(Raw EEG - after PCA + I-ICA dim recuction)",,N/A,,N/M,sAE,AE,-,N/M,Yes,N/M,"AE: 2
Softmax: 1",N/M,L2,,,"1
(0: preictal, 1: interictal)",N/M,"Unsupervised Training for AE
Then, add Softmax layer and retrained on training data with labels",N/M,N/M,N/M,N/M,N/M,N/M,,Leave-one-out,N/M,"Accuracy
Precision
Sensitivity","Amazon HPC
(Cloud)",,N/M,"Accuracy: 0.94
Precision: 0.95
Sensitivity: 0.93","Random Forest
Linear SVM
Non-Linear SVM
MLP",Traditional pipeline,,N/M,A cloud-based deep-learning method that is able to perform seizure prediction under such circumstances has immediate applicability in the present day.,"Cloud Latency
Dimensionality of Data","No
(the pseudo-code yes)",,I feel like they would need more data...,,Yannick,[TBD],
,Early Seizure Detection with an Energy-Efficient Convolutional Neural Network on an Implantable Microcontroller,2018,"Hügle, Heller, Watter, Blum, Manzouri, Dümpelmann, Schulze-bonhage, Woias & Boedecker",Arxiv,Yes,University of Freiburg,,,Epilepsy,Classification of EEG signals,Clinical,Epilepsy,Detection,"New approach: SeizureNet, CNN but designed for implantable ultra-low power microcontroller",Design an ultra-low power deep learning network for implantable closed-loop device for seizure detection (and stimulation),(see dataset paper),Most seizure algorithms are not designed to have low computationally cost. (towards invasive closed-loop devices),,1) Ultra-Low Power MC: MSP430FR5994 (TI),Yes,Seizures,EPILEPSIAE,$$$,(see dataset details),"Recorded: 100
Selected: 4",256,N/M,,,"1) Notch-Filter: 50Hz (Power line)
2) High-Pass Filter: 0.1Hz (remove slow drift)
3) Rescaled by dividing through the rolling 10min STD 
(to account for non-stationarity in the source)",,"1s window raw EEG
(None)",Raw EEG,Rescaled (see preprocessing steps),,N/M,CNN,CNN,Batch norm,"by convolving over the electrodes and time, so that we can learn spatio-temporal patterns efficiently in one layer",Yes,"E x 256 x 1
(E = nb electrodes)",CNN: 5,"ReLU
Sigmoid",Dropout,,,"1
(ictal / interictal)
(sigmoid)","3,621",N/M,Adam,LR: 0.001,256,N/M,"To deal with the high imbalance of ictal and interictal samples, we use an oversampling technique.",Binary Cross-Entropy,,3-Fold Cross Validation,N/M,"Sensitivity
Detection Delay 
False Positive
AUC",,,N/M,"Median Sensitivity of 0.96
Median AUC Score of 0.89
Median Delay of 3.7s
10.1 False Positives per Hour","EEGNet, 2016
Kiral-Kornek et al., 2017
Acharya et al., 2017 
SVM",DL & Trad.,,-,"To the best of our knowledge, we have designed the first convolutional neural network for seizure detection specifically for an implantable ultra-low power microcontroller.",(1) It is non-trivial to evaluate a seizure detection system. (2) Tuning the networks to early and sensitive detection of electroencephalographic seizure patterns occurs at the cost of higher false positive rates.,No,,-,,Yannick,[TBD],
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Neural Networks with 1 hidden layer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Adaptive training using an artificial neural network and EEG metrics for within- and cross-task workload classification,2012,Baldwin & Penaranda,NeuroImage,,George Mason University,,,Education/Learning,,,,,Real-time classification of mental workload for learning & training.,,Mental workload,,,NeuroScan NuAmps & QuickCap,,,,,15,40,,,,,"1) Re-referenced: Avg left/right mastoid.
2) Filtered: 0.1Hz High-Pass + 70Hz Low-Pass
3) Visual Inspection: Removal of noisy channels
4) 5 Bands: Delta, Theta, Alpha, Beta, Gamma",,,,,,MATLAB & Neural Network Toolbox,MLP,,"Randomly-Initialized MLP
20 Nodes",,,"5 (bands) x 10 (channels)
(between 40-50, depending on (noisy) removed channels)",1,,,,,,,,,,,,,,,"50% training, 50% validation.",,,,,,"Within-task: M=87.1% and 85.3%, respectively. 
Cross-task: average 44.8%. (Below chance level!)",,,,,,,,,,,Yannick,,
,Classification of drowsiness in EEG records based on energy distribution and wavelet-neural network,2015,"Boonnak, Kamonsantiroj & Pipanmaekaporn",17th IEEE International Conference on Computational Science and Engineering,,King Mongkut's University of Technology North Bangkok,,,Transportation,,,,,Improve state-of-the-art,,Drowsiness vs Alert states while Driving,,,N/M*,,PSD,MIT-BIH Polysomnographic,Public (open),16,18,250Hz,N/M*,,,"1) Time Segmentation
2) Wavelet Transform",,"Energy Coefficients
Probability Distribution",,,,N/M*,ANFIS,,N/M*,,,"7x1
Energy Coefficients
of the bands ",N/M*,,,,,"2
Alert
Drowsiness",N/M*,,N/M*,,,,N/M*,N/M*,,"80% training, 20% validation.",,,,,N/M*,90.27%,,,,,"In this paper, we proposed a new method to improve wavelet coefficient of DWT for classification alert and drowsy stages of EEG signals. 
The energy conservation, Parseval's theorem and the lognormal distribution of the energy coefficient are applied.",,,,,,Yannick,,
,Classification of EEG based-mental fatigue using principal component analysis and Bayesian neural network,2016,"Chai, Tran, Naik, Nguyen, Ling, Craig, Nguyen",38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),,N/M*,,,General Cognitive,,,,,Improve state-of-the-art,,Mental Fatigue Pre/Post of 2-3h of Cognitively challenging Mental Tasks,,,Neuroscan Quick-Cap,,PSD,Internal Recordings,Private,65,26,500Hz,N/M*,,,1) PCA,,"PSD
D (0.5-3Hz), T (3.5-7.5Hz), A (8-13Hz), B (13.5-30Hz)",,,,N/M*,BNN,,N/M*,,,"24x1
6 PCs * 4 PSD Bands",1,,,,,,N/M*,,N/M*,,,,N/M*,N/M*,,N/M*,,,,,N/M*,75%,,,,,,,,,,,Yannick,,
,Identification of Mental Workload Using Imbalanced EEG Data and DySMOTE-based Neural Network Approach,2016,"Cui, Zhang & Wang","13th IFAC Symposium on Analysis, Design, and Evaluation of Human-Machine Systems",,East China University of Science and Technology,,,General Cognitive,,,,,New approach,,ACAMS (Automation-enhanced Cabin Air Management System),,,Nihon Kohden,,PSD,Internal Recordings,Private,8,11,500Hz,N/M*,,,"1) Band-Pass filter: 0-40Hz
2) Coherence method for EOG artifacts",,"PSD
D (0-4Hz), T (5-8Hz), A (9-12Hz), B (13-32Hz), G (33-40Hz)",,,,N/M*,"MLP
(+ DySMOTE)",,"""The parameters are set by experience as 200 for training epoch and 60 for hidden neuron nodes""",,,"56x1
55 EEG PSD Features
1 ECG",?,,,,,"5
CL: Base, Low, Normal, High, Very High",,,N/M*,,,,DySMOTE,,,10 times 5-fold cross validation are conducted on each dataset.,,,,,N/M*,"[It works slightly better than other Over/Under sampling methods]
Not only 1 result... and only graphs...
roughly 36% on a 5 classes","CSOS, CSUS, DyROS",,,,"The average classification accuracy of each class indicates that DySMOTE is effective in boosting the accuracy of each class ,especially for minority level class.",,,,Oversampling (DySMOTE) + MLP,,Yannick,,
,Detecting driver drowsiness based on single electroencephalography channel,2016,"Belakhdar, Kaaniche, Djmel & Ouni",13th International Multi-Conference on Systems,,"University of Monastir
University of Sousse
King Saud University",,,Transportation,,,,,Improve State-of-the-Art,,Driving,,,N/M*,,PSD,MIT-BIH Polysomnographic,Public (open),10,1,250Hz,"Drowsiness: 787
Alertness: 787",,,None,,"PSD
9 Bands & Ratio",,,,MATALB + NNTools,ANN,,Between 10 to 40 neurons,,,"9x1
PSD Features",1,,,,,"1
0: Alertness
1: Drowsiness",N/M*,,N/M*,,,,N/M*,N/M*,,N/M*,,,,,N/M*,"Drowsiness: 86.5%
Alertness: 83.5%","(A. Garces Correa et al., 2010)",,,,"[...] which proves that we have successfully developed a new approach more accurate than the already existing ones.
Limitations: data from polysomnographic studies.",,,,"Indeed, it might be a stretch from Sleep studies to Driver Drowsiness...",,Yannick,,
,"Classification of alcoholic EEG using wavelet packet decomposition, principal component analysis, and combination of genetic algorithm and neural network",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Neuronal Spectral Analysis of EEG and Expert Knowledge Integration for Automatic Classification of Sleep Stages,2005,"Kerkeni, Alexandre, Bedoui, Bougrain & Dogui",Arxiv,,"Cortex Team, LORIA, France
Medecine Faculty of Monastir, Tunisia
CHU Sahloul, Tunisia",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,